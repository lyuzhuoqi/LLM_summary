{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfd40bc",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0013e5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>llama4</th>\n",
       "      <th>gemma3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study reports on mtDNA variation in domes...</td>\n",
       "      <td>Reference 48 reports evidence for two independ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>The data also highlight the value of this reso...</td>\n",
       "      <td>Reference 37 demonstrates a hybrid origin of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This study combines two different methods used...</td>\n",
       "      <td>This reference reports fine-mapping of a QTL f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study examines the role of genetic drift ...</td>\n",
       "      <td>Reference 49 describes the use of LD mapping i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This study provides a comprehensive analysis o...</td>\n",
       "      <td>This study reports the identification of a maj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>These results have implications for future stu...</td>\n",
       "      <td>Reference 52 reports on the expansion of human...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that low dose IL-2 sel...</td>\n",
       "      <td>This short communication reports that low-dose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies a previously unrecognize...</td>\n",
       "      <td>This work reports that hybrid peptides generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study describes engineering of human cell...</td>\n",
       "      <td>This reference details a gene therapy approach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study is the first to identify and charac...</td>\n",
       "      <td>This reference characterizes human regulatory ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35621 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      This study reports on mtDNA variation in domes...   \n",
       "1      The data also highlight the value of this reso...   \n",
       "2      This study combines two different methods used...   \n",
       "3      This study examines the role of genetic drift ...   \n",
       "4      This study provides a comprehensive analysis o...   \n",
       "...                                                  ...   \n",
       "35631  These results have implications for future stu...   \n",
       "35632  This study demonstrates that low dose IL-2 sel...   \n",
       "35633  This study identifies a previously unrecognize...   \n",
       "35634  This study describes engineering of human cell...   \n",
       "35635  This study is the first to identify and charac...   \n",
       "\n",
       "                                                  gemma3  \n",
       "0      Reference 48 reports evidence for two independ...  \n",
       "1      Reference 37 demonstrates a hybrid origin of m...  \n",
       "2      This reference reports fine-mapping of a QTL f...  \n",
       "3      Reference 49 describes the use of LD mapping i...  \n",
       "4      This study reports the identification of a maj...  \n",
       "...                                                  ...  \n",
       "35631  Reference 52 reports on the expansion of human...  \n",
       "35632  This short communication reports that low-dose...  \n",
       "35633  This work reports that hybrid peptides generat...  \n",
       "35634  This reference details a gene therapy approach...  \n",
       "35635  This reference characterizes human regulatory ...  \n",
       "\n",
       "[35621 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "\n",
    "# models = ['qwen3', 'gemma3', 'llama4', 'qwq']\n",
    "models = ['llama4', 'gemma3']\n",
    "\n",
    "# suffixes = None\n",
    "# suffixes = '_sent_shuffle'\n",
    "suffixes = '_tail'\n",
    "\n",
    "if suffixes is not None:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}{suffixes}.txt' for model in models]\n",
    "else:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}.txt' for model in models]\n",
    "\n",
    "df = pd.read_csv(home / 'projects/TLDR/data/paper_html_10.1038/abs_annotation/test.tsv', sep='\\t')\n",
    "for model, csv_file in zip(models, csv_files):\n",
    "    single_df = pd.read_csv(csv_file, sep='\\t', header=None, names=[model])\n",
    "    df = df.join(single_df)\n",
    "\n",
    "for index in pd.read_csv(home / \"projects/TLDR/description/invalid_entry_in_test.txt\", sep='\\t', header=None).values.flatten().tolist():\n",
    "    df = df.drop(index-2)  # Adjusting for zero-based index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccece17",
   "metadata": {},
   "source": [
    "# Overlap-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73336b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "def evaluate_metrics(df, pred_col='prediction', ref_col='reference'):\n",
    "    references = df[ref_col].tolist()\n",
    "    predictions = df[pred_col].tolist()\n",
    "\n",
    "    # BLEU\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    bleu_result = bleu.compute(\n",
    "        predictions=predictions,                 # 每个元素是一个字符串\n",
    "        references=[[ref] for ref in references] # 每个元素是字符串列表\n",
    "    )\n",
    "\n",
    "    # METEOR\n",
    "    meteor = evaluate.load(\"meteor\")\n",
    "    meteor_result = meteor.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    rouge_result = rouge.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "    )\n",
    "\n",
    "    # 只返回需要的分数，便于后续统计平均\n",
    "    rouge_f = {rouge_type: rouge_result[rouge_type] if rouge_result is not None else None \n",
    "               for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]}\n",
    "\n",
    "    return {\n",
    "        'bleu': bleu_result[\"bleu\"] if bleu_result is not None else None,\n",
    "        'rouge': rouge_f,\n",
    "        'meteor': meteor_result[\"meteor\"] if meteor_result is not None else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2306e",
   "metadata": {},
   "source": [
    "## Human-written annotations as references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e2eb0a",
   "metadata": {},
   "source": [
    "### LLMs' performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8adbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.019887477342082245,\n",
       " 'rouge': {'rouge1': np.float64(0.24788200505452687),\n",
       "  'rouge2': np.float64(0.05090276476031293),\n",
       "  'rougeL': np.float64(0.19192940494990046)},\n",
       " 'meteor': np.float64(0.20307779408308785)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3392fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.018902567305634575,\n",
       " 'rouge': {'rouge1': np.float64(0.23938686971344814),\n",
       "  'rouge2': np.float64(0.0459321530817411),\n",
       "  'rougeL': np.float64(0.1819147074966649)},\n",
       " 'meteor': np.float64(0.1985158543224368)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567d7493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.011977842430480163,\n",
       " 'meteor': 0.2444276480952033,\n",
       " 'rouge': {'rouge1': 0.2209834534176697,\n",
       "  'rouge2': 0.04533792571342782,\n",
       "  'rougeL': 0.1550987958773836}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec01a63",
   "metadata": {},
   "source": [
    "### Multi-annotated abstracts as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d7760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of papers:  29356\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1083/jcb.153.2.397</td>\n",
       "      <td>58551536</td>\n",
       "      <td>The correct positioning of the nucleus is ofte...</td>\n",
       "      <td>Using live imaging and computer simulation the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1101/gad.14.6.690</td>\n",
       "      <td>131922988</td>\n",
       "      <td>E2F is a family of transcription factors that ...</td>\n",
       "      <td>Disruption of mouse E2f3 , but not E2f1 , redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.1101/gad.859201</td>\n",
       "      <td>18000382</td>\n",
       "      <td>Telomere shortening is the mechanism underlyin...</td>\n",
       "      <td>Growing primary human keratinocytes and mammar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/scitranslmed.aad4134</td>\n",
       "      <td>103721459</td>\n",
       "      <td>Autologous regulatory T cells can be expanded ...</td>\n",
       "      <td>First clinical trial demonstrating up to 1 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1084/jem.20040139</td>\n",
       "      <td>83080620</td>\n",
       "      <td>The low number of CD4+ CD25+ regulatory T cell...</td>\n",
       "      <td>Seminal study showing that antigen-specific T ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35637</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35638</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35640</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10304 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            abs_doi   paper_id  \\\n",
       "0            10.1073/pnas.91.7.2757  107202074   \n",
       "1       10.1093/genetics/154.4.1785   83366887   \n",
       "7             10.1083/jcb.153.2.397   58551536   \n",
       "8              10.1101/gad.14.6.690  131922988   \n",
       "10               10.1101/gad.859201   18000382   \n",
       "...                             ...        ...   \n",
       "35633  10.1126/scitranslmed.aad4134  103721459   \n",
       "35634          10.1084/jem.20040139   83080620   \n",
       "35637       10.1126/science.aar3246    4860145   \n",
       "35638       10.1126/science.aad2791   62290395   \n",
       "35640   10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "7      The correct positioning of the nucleus is ofte...   \n",
       "8      E2F is a family of transcription factors that ...   \n",
       "10     Telomere shortening is the mechanism underlyin...   \n",
       "...                                                  ...   \n",
       "35633  Autologous regulatory T cells can be expanded ...   \n",
       "35634  The low number of CD4+ CD25+ regulatory T cell...   \n",
       "35637  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35638  T cells target peptide combos One of the endur...   \n",
       "35640  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \n",
       "0      A demonstration that cattle have been domestic...  \n",
       "1      Evidence is presented for independent domestic...  \n",
       "7      Using live imaging and computer simulation the...  \n",
       "8      Disruption of mouse E2f3 , but not E2f1 , redu...  \n",
       "10     Growing primary human keratinocytes and mammar...  \n",
       "...                                                  ...  \n",
       "35633  First clinical trial demonstrating up to 1 yea...  \n",
       "35634  Seminal study showing that antigen-specific T ...  \n",
       "35637  This study reports the generation of an orthog...  \n",
       "35638  This article shows that some diabetogenic T ce...  \n",
       "35640  Together with Levings et al. (2001), Jonuleit ...  \n",
       "\n",
       "[10304 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4019 papers are annotated by multiple annotators\n"
     ]
    }
   ],
   "source": [
    "full = pd.read_csv(home / 'projects/TLDR/data/paper_html_10.1038/abs_annotation/abs_annotation.tsv', sep='\\t')\n",
    "print('# of papers: ', full['paper_id'].nunique())\n",
    "\n",
    "multi_annotated = full[full['paper_id'].isin(full['paper_id'].value_counts()[full['paper_id'].value_counts() > 1].index)]\n",
    "display(multi_annotated)\n",
    "print(multi_annotated['paper_id'].unique().shape[0], 'papers are annotated by multiple annotators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88517bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paper_id_counts = full['paper_id'].value_counts()\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.histplot(x=paper_id_counts, bins=30, stat='count', discrete=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Times of being annotated')\n",
    "plt.ylabel('# of paper')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a6668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paper_id_counts = multi_annotated['paper_id'].value_counts()\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.histplot(x=paper_id_counts, bins=30, stat='count', discrete=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Times of being annotated')\n",
    "plt.ylabel('# of paper')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                      | 0/10 [00:00<?, ?it/s][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 10%|████████████▌                                                                                                                 | 1/10 [00:12<01:50, 12.32s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 20%|█████████████████████████▏                                                                                                    | 2/10 [00:22<01:29, 11.15s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 30%|█████████████████████████████████████▊                                                                                        | 3/10 [00:33<01:15, 10.80s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 40%|██████████████████████████████████████████████████▍                                                                           | 4/10 [00:43<01:03, 10.56s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 50%|███████████████████████████████████████████████████████████████                                                               | 5/10 [00:53<00:53, 10.64s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 6/10 [01:04<00:42, 10.51s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 70%|████████████████████████████████████████████████████████████████████████████████████████▏                                     | 7/10 [01:14<00:31, 10.46s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 8/10 [01:25<00:20, 10.47s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 9/10 [01:35<00:10, 10.35s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:45<00:00, 10.51s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    scores = evaluate_metrics(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643069de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10次抽样平均 ===\n",
      "BLEU: 0.0452\n",
      "METEOR: 0.2159\n",
      "ROUGE (F):\n",
      "  ROUGE1: 0.2739\n",
      "  ROUGE2: 0.0679\n",
      "  ROUGEL: 0.2166\n"
     ]
    }
   ],
   "source": [
    "# 计算平均分\n",
    "bleu_avg = sum(s['bleu'] for s in all_scores) / n_sample\n",
    "meteor_avg = sum(s['meteor'] for s in all_scores) / n_sample\n",
    "rouge_avg = {}\n",
    "for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]:\n",
    "    rouge_avg[rouge_type] = sum(s['rouge'][rouge_type] for s in all_scores) / n_sample\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"BLEU: {:.4f}\".format(bleu_avg))\n",
    "print(\"METEOR: {:.4f}\".format(meteor_avg))\n",
    "print(\"ROUGE (F):\")\n",
    "for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]:\n",
    "    print(\"  {}: {:.4f}\".format(rouge_type.upper(), rouge_avg[rouge_type]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a796d6",
   "metadata": {},
   "source": [
    "## Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d1106a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0015324374033827534,\n",
       " 'rouge': {'rouge1': np.float64(0.178899423182238),\n",
       "  'rouge2': np.float64(0.0687364958628883),\n",
       "  'rougeL': np.float64(0.13063263718495793)},\n",
       " 'meteor': np.float64(0.0955440723649232)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62d6219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0012659313729019544,\n",
       " 'rouge': {'rouge1': np.float64(0.17266882832370087),\n",
       "  'rouge2': np.float64(0.05188857170643919),\n",
       "  'rougeL': np.float64(0.11733435621163343)},\n",
       " 'meteor': np.float64(0.08687230057524462)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f33d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.03319207318259169,\n",
       " 'meteor': np.float64(0.19749892250719794),\n",
       " 'rouge': {'rouge1': np.float64(0.3397127836850643),\n",
       "  'rouge2': np.float64(0.1271640602084576),\n",
       "  'rougeL': np.float64(0.20906792437643631)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc89e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.00014032267591655747,\n",
       " 'meteor': np.float64(0.06377415902193286),\n",
       " 'rouge': {'rouge1': np.float64(0.1408848000436993),\n",
       "  'rouge2': np.float64(0.03825775412279675),\n",
       "  'rougeL': np.float64(0.10050406185966701)}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='annotation', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee60430",
   "metadata": {},
   "source": [
    "# Simlarity-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b8949",
   "metadata": {},
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd5a5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "def evaluate_bertscore(df, pred_col='prediction', ref_col='reference'):\n",
    "    preds = df[pred_col].tolist()\n",
    "    refs = df[ref_col].tolist()\n",
    "\n",
    "    P, R, F1 = score(preds, refs, lang='en', \n",
    "                     use_fast_tokenizer=True,\n",
    "                     batch_size=32,\n",
    "                     verbose=True)  # 如果是中文，改为 lang='zh'\n",
    "    print(f\"BERTScore F1: {F1.mean().item():.4f}\")\n",
    "    return {\n",
    "        \"BERTScore_P\": P.mean().item(),\n",
    "        \"BERTScore_R\": R.mean().item(),\n",
    "        \"BERTScore_F1\": F1.mean().item()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869dcd26",
   "metadata": {},
   "source": [
    "### Human-wrtten annotations as references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de17ed",
   "metadata": {},
   "source": [
    "#### LLMs' performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f2a4590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c3a678d5fc4c1b9e270246d1ac1619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696f0ee9c9d94392969e4d5a91249dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 113.08 seconds, 315.00 sentences/sec\n",
      "BERTScore F1: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8760881423950195,\n",
       " 'BERTScore_R': 0.8838481307029724,\n",
       " 'BERTScore_F1': 0.879772961139679}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd7d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f67e102abcb48b0a94647a399f68c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c7ab642c9a49368a13a6c564225bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 116.39 seconds, 306.04 sentences/sec\n",
      "BERTScore F1: 0.8768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.874789297580719,\n",
       " 'BERTScore_R': 0.8792647123336792,\n",
       " 'BERTScore_F1': 0.8768314719200134}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68df66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02f85fdac874a13bb1b5d4e86f7230a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18cc9265aaa447c8f7ca0c3178349e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 564.50 seconds, 63.10 sentences/sec\n",
      "BERTScore F1: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8417383432388306,\n",
       " 'BERTScore_R': 0.8892121315002441,\n",
       " 'BERTScore_F1': 0.8646422624588013}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2d975",
   "metadata": {},
   "source": [
    "#### Multi-annotated papers as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fff830e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca48708fbdf74f9189b342e2672c3831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91929146b04f4492ad37cb3724ba49c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 1/10 [00:38<05:50, 39.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.19 seconds, 168.93 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c48c755134749c18147a4f25ad4a336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459bed1d8b1e4054828c5c916057f4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                            | 2/10 [01:16<05:04, 38.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.41 seconds, 167.90 sentences/sec\n",
      "BERTScore F1: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5772820aac5444f94d375533bff96ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e72dc098eb4cf0a1e194f6f728c83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 3/10 [01:55<04:28, 38.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.74 seconds, 166.45 sentences/sec\n",
      "BERTScore F1: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed4c9d63f7c4ffcbe2abed6a2189858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a90079173a34652bd983dc4b3ab6a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 4/10 [02:33<03:50, 38.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.65 seconds, 166.86 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5aca048be64898a71e98e08af6116b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a9bb69300e469d9143db66ac4e0d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████                                      | 5/10 [03:12<03:12, 38.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.83 seconds, 166.05 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33e34168bdf48c98655cbaa80117f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161bc74ea8b94c1ab8649478223452b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▌                              | 6/10 [03:50<02:33, 38.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.71 seconds, 166.58 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c98cd44d1a643d7bda38ea0ca71de87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6f66f705c641cbb8054a2ae29b943c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▏                      | 7/10 [04:28<01:55, 38.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.82 seconds, 166.09 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe77b56e4a54358b9cf37bb8ee328a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805759f302ac484b8a083df4baf1eddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▊               | 8/10 [05:07<01:16, 38.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.64 seconds, 166.84 sentences/sec\n",
      "BERTScore F1: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f267f3ad097e41518342f1a8c35cbfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6c72d5777c4f84b44d656c882458b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████▍       | 9/10 [05:45<00:38, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.64 seconds, 166.86 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50cbd3639e94398a3f1ee040592f84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b81b58e5734f53b123e32143e67880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10/10 [06:24<00:00, 38.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.97 seconds, 165.43 sentences/sec\n",
      "BERTScore F1: 0.8813\n",
      "=== 10次抽样平均 ===\n",
      "BERTScore: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    scores = evaluate_bertscore(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(scores)\n",
    "\n",
    "# 计算平均分\n",
    "bertscore_avg = sum(s['BERTScore_F1'] for s in all_scores) / n_sample\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"BERTScore: {:.4f}\".format(bertscore_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9edfd",
   "metadata": {},
   "source": [
    "### Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479664e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ce4557463a41768eccdc81bbf5b7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793bcf5afdb74f6899e3a3591214b5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 434.40 seconds, 82.00 sentences/sec\n",
      "BERTScore F1: 0.8607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8978897333145142,\n",
       " 'BERTScore_R': 0.8267492055892944,\n",
       " 'BERTScore_F1': 0.860707700252533}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e61a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174acdc986cc450b90c85875be10c0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ef2263d61148ab8f10a57a2d53ef6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 518.96 seconds, 68.64 sentences/sec\n",
      "BERTScore F1: 0.8527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8875752091407776,\n",
       " 'BERTScore_R': 0.82086181640625,\n",
       " 'BERTScore_F1': 0.8527042269706726}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a81c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [06:49<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:18<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 431.02 seconds, 82.64 sentences/sec\n",
      "BERTScore F1: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.89637291431427,\n",
       " 'BERTScore_R': 0.859321653842926,\n",
       " 'BERTScore_F1': 0.877304196357727}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02950398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [05:34<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:17<00:00, 31.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 354.50 seconds, 100.48 sentences/sec\n",
      "BERTScore F1: 0.8410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8739364147186279,\n",
       " 'BERTScore_R': 0.8107424378395081,\n",
       " 'BERTScore_F1': 0.840957522392273}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='annotation', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3351f35",
   "metadata": {},
   "source": [
    "## MoverScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0706f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "158947a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.model_max_length:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(home / 'projects/TLDR/evaluation/ref_based'))\n",
    "\n",
    "from moverscore_v2 import get_idf_dict, word_mover_score \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def evaluate_moverscore(df, pred_col='prediction', ref_col='reference'):\n",
    "    preds = df[pred_col].tolist()\n",
    "    refs = df[ref_col].tolist()\n",
    "\n",
    "    idf_dict_hyp = get_idf_dict(preds)\n",
    "    idf_dict_ref = get_idf_dict(refs)\n",
    "\n",
    "    scores = word_mover_score(refs, preds, idf_dict_ref, idf_dict_hyp, stop_words=stopwords.words('english'))\n",
    "    print(f'MoverScore: {np.mean(scores):.4f}')\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d26011",
   "metadata": {},
   "source": [
    "### Human-written annotations as references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fcb81",
   "metadata": {},
   "source": [
    "#### LLMs' performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "728a265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14975 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (81328 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|                                                                                                                    | 0/279 [00:00<?, ?it/s]DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14975 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [03:24<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5629107150349321)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dcc1e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [06:52<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5574020428751254)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "049ffff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (22174 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2481 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (38381 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|                                                                   | 0/279 [00:00<?, ?it/s]DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS:   5%|██▊                                                     | 14/279 [03:40<1:13:13, 16.58s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS: 100%|█████████████████████████████████████████████████████████| 279/279 [41:28<00:00,  8.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5512474859691321"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38c41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|████████████████████████████████████████████████████████| 279/279 [55:58<00:00, 12.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5462896681747191"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwq', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4688852c",
   "metadata": {},
   "source": [
    "#### Multi-annotated abstracts as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a052747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.08it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:43<00:00,  1.16it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:45<00:00,  1.10it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:47<00:00,  1.05it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:40<00:00,  1.23it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:38<00:00,  1.31it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:39<00:00,  1.26it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:39<00:00,  1.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10/10 [07:18<00:00, 43.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10次抽样平均 ===\n",
      "MoverScore: 0.5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    score = evaluate_moverscore(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(score)\n",
    "\n",
    "# 计算平均分\n",
    "moverscore_avg = np.mean(all_scores)\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"MoverScore: {:.4f}\".format(moverscore_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac24c13e",
   "metadata": {},
   "source": [
    "### Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f7a2f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [30:16<00:00,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5489216601395974)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f83c86bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [38:09<00:00,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5404280791106816)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b13164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [54:37<00:00, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5834857282245158)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05007b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|          | 0/279 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS: 100%|██████████| 279/279 [25:33<00:00,  5.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5301549328571855)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='annotation', ref_col='abstract')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
