{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfd40bc",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0013e5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>deepseek_v3</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>qwq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study examines mtDNA sequences from tauri...</td>\n",
       "      <td>Reference 14 reports phylogenetic analysis of ...</td>\n",
       "      <td>These authors investigated the evolutionary hi...</td>\n",
       "      <td>This study uses mitochondrial DNA sequencing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study provides molecular evidence for the...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>These findings indicate that there has been ge...</td>\n",
       "      <td>This study provides molecular evidence for int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This study reports the fine-mapping of a QTL a...</td>\n",
       "      <td>This paper reports the fine-mapping of a QTL a...</td>\n",
       "      <td>Fine mapping a QTL for milk fat percentage on ...</td>\n",
       "      <td>This study refines the mapping of a quantitati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study provides an early genome-wide analy...</td>\n",
       "      <td>This paper reports an extensive LD map in dair...</td>\n",
       "      <td>This study evaluates the potential of LD mappi...</td>\n",
       "      <td>This study investigates linkage disequilibrium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This study reports the mapping of a major quan...</td>\n",
       "      <td>This study identifies a major QTL on chromosom...</td>\n",
       "      <td>This study identifies a major locus on pig chr...</td>\n",
       "      <td>This study identifies a major quantitative tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This study demonstrates the feasibility of iso...</td>\n",
       "      <td>Reference 51 describes an optimized method for...</td>\n",
       "      <td>These studies demonstrate the feasibility of t...</td>\n",
       "      <td>This study evaluates the expansion and functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study describes the engineering of orthog...</td>\n",
       "      <td>Reference 54 reports the successful engineerin...</td>\n",
       "      <td>This study demonstrates that a synthetic IL-2:...</td>\n",
       "      <td>This study introduces engineered synthetic IL-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies hybrid insulin peptides ...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells isolated from the pancreatic islets of...</td>\n",
       "      <td>This study identifies that T cells in type 1 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study describes a multiplex genome-editin...</td>\n",
       "      <td>This work describes a new method to render all...</td>\n",
       "      <td>This study provides evidence for genome-edited...</td>\n",
       "      <td>This study presents a multiplex genome-editing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study identifies and characterizes human ...</td>\n",
       "      <td>References 18 and 19 report the existence of a...</td>\n",
       "      <td>These results identify a population of regulat...</td>\n",
       "      <td>This study identifies human CD4+CD25high regul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35621 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                             deepseek_v3  \\\n",
       "0      This study examines mtDNA sequences from tauri...   \n",
       "1      This study provides molecular evidence for the...   \n",
       "2      This study reports the fine-mapping of a QTL a...   \n",
       "3      This study provides an early genome-wide analy...   \n",
       "4      This study reports the mapping of a major quan...   \n",
       "...                                                  ...   \n",
       "35631  This study demonstrates the feasibility of iso...   \n",
       "35632  This study describes the engineering of orthog...   \n",
       "35633  This study identifies hybrid insulin peptides ...   \n",
       "35634  This study describes a multiplex genome-editin...   \n",
       "35635  This study identifies and characterizes human ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      Reference 14 reports phylogenetic analysis of ...   \n",
       "1      This study demonstrates independent domesticat...   \n",
       "2      This paper reports the fine-mapping of a QTL a...   \n",
       "3      This paper reports an extensive LD map in dair...   \n",
       "4      This study identifies a major QTL on chromosom...   \n",
       "...                                                  ...   \n",
       "35631  Reference 51 describes an optimized method for...   \n",
       "35632  Reference 54 reports the successful engineerin...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This work describes a new method to render all...   \n",
       "35635  References 18 and 19 report the existence of a...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      These authors investigated the evolutionary hi...   \n",
       "1      These findings indicate that there has been ge...   \n",
       "2      Fine mapping a QTL for milk fat percentage on ...   \n",
       "3      This study evaluates the potential of LD mappi...   \n",
       "4      This study identifies a major locus on pig chr...   \n",
       "...                                                  ...   \n",
       "35631  These studies demonstrate the feasibility of t...   \n",
       "35632  This study demonstrates that a synthetic IL-2:...   \n",
       "35633  T cells isolated from the pancreatic islets of...   \n",
       "35634  This study provides evidence for genome-edited...   \n",
       "35635  These results identify a population of regulat...   \n",
       "\n",
       "                                                     qwq  \n",
       "0      This study uses mitochondrial DNA sequencing t...  \n",
       "1      This study provides molecular evidence for int...  \n",
       "2      This study refines the mapping of a quantitati...  \n",
       "3      This study investigates linkage disequilibrium...  \n",
       "4      This study identifies a major quantitative tra...  \n",
       "...                                                  ...  \n",
       "35631  This study evaluates the expansion and functio...  \n",
       "35632  This study introduces engineered synthetic IL-...  \n",
       "35633  This study identifies that T cells in type 1 d...  \n",
       "35634  This study presents a multiplex genome-editing...  \n",
       "35635  This study identifies human CD4+CD25high regul...  \n",
       "\n",
       "[35621 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "\n",
    "# models = ['deepseek_v3', 'gemma3', 'llama4', 'qwq', 'qwen3']\n",
    "models = ['deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "\n",
    "# suffixes = None\n",
    "suffixes = '_sent_shuffle'\n",
    "# suffixes = '_tail'\n",
    "if suffixes is not None:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}_TLDR{suffixes}.txt' for model in models]\n",
    "else:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}_TLDR.txt' for model in models]\n",
    "\n",
    "df = pd.read_csv(home / 'projects/TLDR/data/paper_html_10.1038/abs_annotation/test.tsv', sep='\\t')\n",
    "for model, csv_file in zip(models, csv_files):\n",
    "    single_df = pd.read_csv(csv_file, sep='\\t', header=None, names=[model])\n",
    "    df = df.join(single_df)\n",
    "\n",
    "for index in pd.read_csv(home / \"projects/TLDR/description/invalid_entry_in_test.txt\", sep='\\t', header=None).values.flatten().tolist():\n",
    "    df = df.drop(index-2)  # Adjusting for zero-based index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccece17",
   "metadata": {},
   "source": [
    "# Overlap-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73336b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "def evaluate_metrics(df, pred_col='prediction', ref_col='reference'):\n",
    "    references = df[ref_col].tolist()\n",
    "    predictions = df[pred_col].tolist()\n",
    "\n",
    "    # BLEU\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    bleu_result = bleu.compute(\n",
    "        predictions=predictions,                 # 每个元素是一个字符串\n",
    "        references=[[ref] for ref in references] # 每个元素是字符串列表\n",
    "    )\n",
    "\n",
    "    # METEOR\n",
    "    meteor = evaluate.load(\"meteor\")\n",
    "    meteor_result = meteor.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    rouge_result = rouge.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "    )\n",
    "\n",
    "    # 只返回需要的分数，便于后续统计平均\n",
    "    rouge_f = {rouge_type: rouge_result[rouge_type] for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]}\n",
    "\n",
    "    return {\n",
    "        'bleu': bleu_result[\"bleu\"],\n",
    "        'meteor': meteor_result[\"meteor\"],\n",
    "        'rouge': rouge_f\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2306e",
   "metadata": {},
   "source": [
    "## Human-written annotations as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90df280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a422e9613739484b936f85f964179a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5901a4243f1645ceafb8c48fda30acbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.02179267092351488,\n",
       " 'meteor': 0.2563322425013617,\n",
       " 'rouge': {'rouge1': 0.2547144813701552,\n",
       "  'rouge2': 0.05767807133117349,\n",
       "  'rougeL': 0.1854361689950115}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='deepseek_v3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567d7493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.011977842430480163,\n",
       " 'meteor': 0.2444276480952033,\n",
       " 'rouge': {'rouge1': 0.2209834534176697,\n",
       "  'rouge2': 0.04533792571342782,\n",
       "  'rougeL': 0.1550987958773836}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8adbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.028354378785504456,\n",
       " 'meteor': 0.2255549493536052,\n",
       " 'rouge': {'rouge1': 0.2626882369362834,\n",
       "  'rouge2': 0.058558148680244365,\n",
       "  'rougeL': 0.20057745028537174}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3392fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.009904643788902805,\n",
       " 'meteor': 0.20799707466094394,\n",
       " 'rouge': {'rouge1': 0.24170650962713458,\n",
       "  'rouge2': 0.05085344815132424,\n",
       "  'rougeL': 0.18393278221885823}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e82d34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.01285771302581912,\n",
       " 'meteor': 0.2450748916074611,\n",
       " 'rouge': {'rouge1': 0.20656905858011987,\n",
       "  'rouge2': 0.04361105879283017,\n",
       "  'rougeL': 0.14461114502749456}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='qwq', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a796d6",
   "metadata": {},
   "source": [
    "## Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc89e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.00014032267591655747,\n",
       " 'meteor': np.float64(0.06377415902193286),\n",
       " 'rouge': {'rouge1': np.float64(0.14085859607012607),\n",
       "  'rouge2': np.float64(0.03824179502459642),\n",
       "  'rougeL': np.float64(0.10052529701258925)}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='annotation', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "608fe40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.00842050749244403,\n",
       " 'meteor': np.float64(0.14812199928907163),\n",
       " 'rouge': {'rouge1': np.float64(0.2740809317573329),\n",
       "  'rouge2': np.float64(0.09751437713848274),\n",
       "  'rougeL': np.float64(0.17701385090721455)}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='deepseek_v3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f33d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.03319207318259169,\n",
       " 'meteor': np.float64(0.19749892250719794),\n",
       " 'rouge': {'rouge1': np.float64(0.3397127836850643),\n",
       "  'rouge2': np.float64(0.1271640602084576),\n",
       "  'rougeL': np.float64(0.20906792437643631)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d1106a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0010656112738437911,\n",
       " 'meteor': np.float64(0.10773691656048064),\n",
       " 'rouge': {'rouge1': np.float64(0.20425126373918268),\n",
       "  'rouge2': np.float64(0.08153386518596661),\n",
       "  'rougeL': np.float64(0.14585628909336387)}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c62d6219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.019022986071808298,\n",
       " 'meteor': np.float64(0.10089574445128485),\n",
       " 'rouge': {'rouge1': np.float64(0.19638098124993508),\n",
       "  'rouge2': np.float64(0.06747216340315135),\n",
       "  'rougeL': np.float64(0.13168214142120832)}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3886e50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.053145877507336486,\n",
       " 'meteor': np.float64(0.25059843651245906),\n",
       " 'rouge': {'rouge1': np.float64(0.4034028101899118),\n",
       "  'rouge2': np.float64(0.16457917019185242),\n",
       "  'rougeL': np.float64(0.2571935840136871)}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='qwq', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7471a3",
   "metadata": {},
   "source": [
    "## Multi-annotated abstracts as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48870a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of papers:  29356\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1083/jcb.153.2.397</td>\n",
       "      <td>58551536</td>\n",
       "      <td>The correct positioning of the nucleus is ofte...</td>\n",
       "      <td>Using live imaging and computer simulation the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1101/gad.14.6.690</td>\n",
       "      <td>131922988</td>\n",
       "      <td>E2F is a family of transcription factors that ...</td>\n",
       "      <td>Disruption of mouse E2f3 , but not E2f1 , redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.1101/gad.859201</td>\n",
       "      <td>18000382</td>\n",
       "      <td>Telomere shortening is the mechanism underlyin...</td>\n",
       "      <td>Growing primary human keratinocytes and mammar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/scitranslmed.aad4134</td>\n",
       "      <td>103721459</td>\n",
       "      <td>Autologous regulatory T cells can be expanded ...</td>\n",
       "      <td>First clinical trial demonstrating up to 1 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1084/jem.20040139</td>\n",
       "      <td>83080620</td>\n",
       "      <td>The low number of CD4+ CD25+ regulatory T cell...</td>\n",
       "      <td>Seminal study showing that antigen-specific T ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35637</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35638</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35640</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10304 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            abs_doi   paper_id  \\\n",
       "0            10.1073/pnas.91.7.2757  107202074   \n",
       "1       10.1093/genetics/154.4.1785   83366887   \n",
       "7             10.1083/jcb.153.2.397   58551536   \n",
       "8              10.1101/gad.14.6.690  131922988   \n",
       "10               10.1101/gad.859201   18000382   \n",
       "...                             ...        ...   \n",
       "35633  10.1126/scitranslmed.aad4134  103721459   \n",
       "35634          10.1084/jem.20040139   83080620   \n",
       "35637       10.1126/science.aar3246    4860145   \n",
       "35638       10.1126/science.aad2791   62290395   \n",
       "35640   10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "7      The correct positioning of the nucleus is ofte...   \n",
       "8      E2F is a family of transcription factors that ...   \n",
       "10     Telomere shortening is the mechanism underlyin...   \n",
       "...                                                  ...   \n",
       "35633  Autologous regulatory T cells can be expanded ...   \n",
       "35634  The low number of CD4+ CD25+ regulatory T cell...   \n",
       "35637  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35638  T cells target peptide combos One of the endur...   \n",
       "35640  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \n",
       "0      A demonstration that cattle have been domestic...  \n",
       "1      Evidence is presented for independent domestic...  \n",
       "7      Using live imaging and computer simulation the...  \n",
       "8      Disruption of mouse E2f3 , but not E2f1 , redu...  \n",
       "10     Growing primary human keratinocytes and mammar...  \n",
       "...                                                  ...  \n",
       "35633  First clinical trial demonstrating up to 1 yea...  \n",
       "35634  Seminal study showing that antigen-specific T ...  \n",
       "35637  This study reports the generation of an orthog...  \n",
       "35638  This article shows that some diabetogenic T ce...  \n",
       "35640  Together with Levings et al. (2001), Jonuleit ...  \n",
       "\n",
       "[10304 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4019 papers are annotated by multiple annotators\n"
     ]
    }
   ],
   "source": [
    "full = pd.read_csv('/home/lyuzhuoqi/projects/TLDR/data/paper_html_10.1038/abs_annotation/abs_annotation.tsv', sep='\\t')\n",
    "print('# of papers: ', full['paper_id'].nunique())\n",
    "\n",
    "multi_annotated = full[full['paper_id'].isin(full['paper_id'].value_counts()[full['paper_id'].value_counts() > 1].index)]\n",
    "display(multi_annotated)\n",
    "print(multi_annotated['paper_id'].unique().shape[0], 'papers are annotated by multiple annotators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88983205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paper_id_counts = full['paper_id'].value_counts()\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.histplot(paper_id_counts, bins=30, stat='count', discrete=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Times of being annotated')\n",
    "plt.ylabel('# of paper')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e74a42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paper_id_counts = multi_annotated['paper_id'].value_counts()\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.histplot(paper_id_counts, bins=30, stat='count', discrete=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Times of being annotated')\n",
    "plt.ylabel('# of paper')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a061e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                     | 0/10 [00:00<?, ?it/s][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 10%|███████▋                                                                     | 1/10 [00:13<01:57, 13.04s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 20%|███████████████▍                                                             | 2/10 [00:27<01:51, 14.00s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 30%|███████████████████████                                                      | 3/10 [00:40<01:34, 13.47s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 40%|██████████████████████████████▊                                              | 4/10 [00:54<01:21, 13.63s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 50%|██████████████████████████████████████▌                                      | 5/10 [01:08<01:09, 13.82s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 60%|██████████████████████████████████████████████▏                              | 6/10 [01:20<00:53, 13.28s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 70%|█████████████████████████████████████████████████████▉                       | 7/10 [01:35<00:41, 13.73s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 80%|█████████████████████████████████████████████████████████████▌               | 8/10 [01:46<00:25, 12.92s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 90%|█████████████████████████████████████████████████████████████████████▎       | 9/10 [02:00<00:13, 13.31s/it][nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 10/10 [02:12<00:00, 13.28s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rouge3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     26\u001b[39m rouge_avg = {}\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rouge_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrouge1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrouge2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrouge3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrougeL\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     rouge_avg[rouge_type] = \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrouge\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrouge_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_scores\u001b[49m\u001b[43m)\u001b[49m / n_sample\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== 10次抽样平均 ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBLEU: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[33m\"\u001b[39m.format(bleu_avg))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     26\u001b[39m rouge_avg = {}\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rouge_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrouge1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrouge2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrouge3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrougeL\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     rouge_avg[rouge_type] = \u001b[38;5;28msum\u001b[39m(\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrouge\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrouge_type\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m all_scores) / n_sample\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== 10次抽样平均 ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBLEU: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[33m\"\u001b[39m.format(bleu_avg))\n",
      "\u001b[31mKeyError\u001b[39m: 'rouge3'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    scores = evaluate_metrics(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b59abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10次抽样平均 ===\n",
      "BLEU: 0.0453\n",
      "METEOR: 0.2158\n",
      "ROUGE (F):\n",
      "  ROUGE1: 0.2738\n",
      "  ROUGE2: 0.0677\n",
      "  ROUGEL: 0.2163\n"
     ]
    }
   ],
   "source": [
    "# 计算平均分\n",
    "bleu_avg = sum(s['bleu'] for s in all_scores) / n_sample\n",
    "meteor_avg = sum(s['meteor'] for s in all_scores) / n_sample\n",
    "rouge_avg = {}\n",
    "for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]:\n",
    "    rouge_avg[rouge_type] = sum(s['rouge'][rouge_type] for s in all_scores) / n_sample\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"BLEU: {:.4f}\".format(bleu_avg))\n",
    "print(\"METEOR: {:.4f}\".format(meteor_avg))\n",
    "print(\"ROUGE (F):\")\n",
    "for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]:\n",
    "    print(\"  {}: {:.4f}\".format(rouge_type.upper(), rouge_avg[rouge_type]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee60430",
   "metadata": {},
   "source": [
    "# Simlarity-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b8949",
   "metadata": {},
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5a5835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "def evaluate_bertscore(df, pred_col='prediction', ref_col='reference'):\n",
    "    preds = df[pred_col].tolist()\n",
    "    refs = df[ref_col].tolist()\n",
    "\n",
    "    P, R, F1 = score(preds, refs, lang='en', verbose=True)  # 如果是中文，改为 lang='zh'\n",
    "    print(f\"BERTScore F1: {F1.mean().item():.4f}\")\n",
    "    return {\n",
    "        \"BERTScore_P\": P.mean().item(),\n",
    "        \"BERTScore_R\": R.mean().item(),\n",
    "        \"BERTScore_F1\": F1.mean().item()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869dcd26",
   "metadata": {},
   "source": [
    "### Human-wrtten annotations as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11ecc8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c469f49aaa9549e2ad5544e4ac53a6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65585fa8cd274c2e85c3e203cf0b0f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 379.09 seconds, 93.96 sentences/sec\n",
      "BERTScore F1: 0.8752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.859603226184845,\n",
       " 'BERTScore_R': 0.8917859792709351,\n",
       " 'BERTScore_F1': 0.8752175569534302}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='deepseek_v3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68df66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02f85fdac874a13bb1b5d4e86f7230a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18cc9265aaa447c8f7ca0c3178349e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 564.50 seconds, 63.10 sentences/sec\n",
      "BERTScore F1: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8417383432388306,\n",
       " 'BERTScore_R': 0.8892121315002441,\n",
       " 'BERTScore_F1': 0.8646422624588013}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f2a4590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b22f74e7a1e453aa3d20dc96cc4a885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732324690ec4422ea164cf6a28676a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 283.89 seconds, 125.48 sentences/sec\n",
      "BERTScore F1: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8740829229354858,\n",
       " 'BERTScore_R': 0.886883556842804,\n",
       " 'BERTScore_F1': 0.8802496194839478}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fd7d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7ca93d85b2468499a8571b22f383f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300ff9d4c1c54ef1a3b55376a0923e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 316.19 seconds, 112.66 sentences/sec\n",
      "BERTScore F1: 0.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8746355772018433,\n",
       " 'BERTScore_R': 0.8801242113113403,\n",
       " 'BERTScore_F1': 0.8771476745605469}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ad7f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff833332dc944ef0aff7f98b26635228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ec92848b8e4028b57907740312e376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 608.11 seconds, 58.58 sentences/sec\n",
      "BERTScore F1: 0.8607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.83527010679245,\n",
       " 'BERTScore_R': 0.8880637288093567,\n",
       " 'BERTScore_F1': 0.8606795072555542}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='qwq', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2d975",
   "metadata": {},
   "source": [
    "#### Multi-annotated abstracts as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fff830e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca48708fbdf74f9189b342e2672c3831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91929146b04f4492ad37cb3724ba49c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 1/10 [00:38<05:50, 39.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.19 seconds, 168.93 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c48c755134749c18147a4f25ad4a336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459bed1d8b1e4054828c5c916057f4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                            | 2/10 [01:16<05:04, 38.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.41 seconds, 167.90 sentences/sec\n",
      "BERTScore F1: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5772820aac5444f94d375533bff96ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e72dc098eb4cf0a1e194f6f728c83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 3/10 [01:55<04:28, 38.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.74 seconds, 166.45 sentences/sec\n",
      "BERTScore F1: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed4c9d63f7c4ffcbe2abed6a2189858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a90079173a34652bd983dc4b3ab6a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 4/10 [02:33<03:50, 38.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.65 seconds, 166.86 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5aca048be64898a71e98e08af6116b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a9bb69300e469d9143db66ac4e0d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████                                      | 5/10 [03:12<03:12, 38.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.83 seconds, 166.05 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33e34168bdf48c98655cbaa80117f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161bc74ea8b94c1ab8649478223452b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▌                              | 6/10 [03:50<02:33, 38.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.71 seconds, 166.58 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c98cd44d1a643d7bda38ea0ca71de87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6f66f705c641cbb8054a2ae29b943c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▏                      | 7/10 [04:28<01:55, 38.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.82 seconds, 166.09 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe77b56e4a54358b9cf37bb8ee328a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805759f302ac484b8a083df4baf1eddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▊               | 8/10 [05:07<01:16, 38.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.64 seconds, 166.84 sentences/sec\n",
      "BERTScore F1: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f267f3ad097e41518342f1a8c35cbfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6c72d5777c4f84b44d656c882458b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████▍       | 9/10 [05:45<00:38, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.64 seconds, 166.86 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50cbd3639e94398a3f1ee040592f84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b81b58e5734f53b123e32143e67880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10/10 [06:24<00:00, 38.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.97 seconds, 165.43 sentences/sec\n",
      "BERTScore F1: 0.8813\n",
      "=== 10次抽样平均 ===\n",
      "BERTScore: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    scores = evaluate_bertscore(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(scores)\n",
    "\n",
    "# 计算平均分\n",
    "bertscore_avg = sum(s['BERTScore_F1'] for s in all_scores) / n_sample\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"BERTScore: {:.4f}\".format(bertscore_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9edfd",
   "metadata": {},
   "source": [
    "### Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02950398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [05:34<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:17<00:00, 31.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 354.50 seconds, 100.48 sentences/sec\n",
      "BERTScore F1: 0.8410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8739364147186279,\n",
       " 'BERTScore_R': 0.8107424378395081,\n",
       " 'BERTScore_F1': 0.840957522392273}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='annotation', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e08b3613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1012/1012 [06:15<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:16<00:00, 33.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 395.40 seconds, 90.09 sentences/sec\n",
      "BERTScore F1: 0.8718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8991764187812805,\n",
       " 'BERTScore_R': 0.8462992906570435,\n",
       " 'BERTScore_F1': 0.8717939257621765}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='deepseek_v3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a81c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [06:49<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:18<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 431.02 seconds, 82.64 sentences/sec\n",
      "BERTScore F1: 0.8773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.89637291431427,\n",
       " 'BERTScore_R': 0.859321653842926,\n",
       " 'BERTScore_F1': 0.877304196357727}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479664e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [05:40<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:15<00:00, 36.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 358.71 seconds, 99.30 sentences/sec\n",
      "BERTScore F1: 0.8630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8985253572463989,\n",
       " 'BERTScore_R': 0.8303980231285095,\n",
       " 'BERTScore_F1': 0.8629780411720276}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e61a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [05:51<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:15<00:00, 34.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 369.92 seconds, 96.29 sentences/sec\n",
      "BERTScore F1: 0.8556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8905962705612183,\n",
       " 'BERTScore_R': 0.8236058354377747,\n",
       " 'BERTScore_F1': 0.8555719256401062}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7256c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [07:26<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:19<00:00, 28.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 469.97 seconds, 75.79 sentences/sec\n",
      "BERTScore F1: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.9028448462486267,\n",
       " 'BERTScore_R': 0.8713891506195068,\n",
       " 'BERTScore_F1': 0.8867055773735046}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='qwq', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3351f35",
   "metadata": {},
   "source": [
    "## MoverScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0706f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "158947a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(home / 'projects/TLDR/evaluation/ref_based'))\n",
    "\n",
    "from moverscore_v2 import get_idf_dict, word_mover_score \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def evaluate_moverscore(df, pred_col='prediction', ref_col='reference'):\n",
    "    preds = df[pred_col].tolist()\n",
    "    refs = df[ref_col].tolist()\n",
    "\n",
    "    idf_dict_hyp = get_idf_dict(preds)\n",
    "    idf_dict_ref = get_idf_dict(refs)\n",
    "\n",
    "    scores = word_mover_score(refs, preds, idf_dict_ref, idf_dict_hyp, stop_words=stopwords.words('english'))\n",
    "    print(f'MoverScore: {np.mean(scores):.4f}')\n",
    "\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d26011",
   "metadata": {},
   "source": [
    "### Human-written annotations as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb461a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|████████████████████████████████████████████████████████| 140/140 [26:29<00:00, 11.35s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5605247859286613"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='deepseek_v3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "049ffff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (22174 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2481 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (38381 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|                                                                   | 0/279 [00:00<?, ?it/s]DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS:   5%|██▊                                                     | 14/279 [03:40<1:13:13, 16.58s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS: 100%|█████████████████████████████████████████████████████████| 279/279 [41:28<00:00,  8.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5512474859691321"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728a265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|                                                                  | 0/279 [00:00<?, ?it/s]DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS:  76%|██████████████████████████████████████████▊             | 213/279 [02:59<00:58,  1.13it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS: 100%|████████████████████████████████████████████████████████| 279/279 [04:22<00:00,  1.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5647836527205226"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dcc1e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|████████████████████████████████████████████████████████| 279/279 [59:27<00:00, 12.79s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5584464708240221"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a38c41a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|████████████████████████████████████████████████████████| 279/279 [55:58<00:00, 12.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5462896681747191"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwq', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4688852c",
   "metadata": {},
   "source": [
    "#### Multi-annotated abstracts as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a052747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.08it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:43<00:00,  1.16it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:45<00:00,  1.10it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:47<00:00,  1.05it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:40<00:00,  1.23it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:38<00:00,  1.31it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:39<00:00,  1.26it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:39<00:00,  1.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10/10 [07:18<00:00, 43.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10次抽样平均 ===\n",
      "MoverScore: 0.5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    score = evaluate_moverscore(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(score)\n",
    "\n",
    "# 计算平均分\n",
    "moverscore_avg = np.mean(all_scores)\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"MoverScore: {:.4f}\".format(moverscore_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac24c13e",
   "metadata": {},
   "source": [
    "### Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05007b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|          | 0/279 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS: 100%|██████████| 279/279 [25:33<00:00,  5.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5301549328571855)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='annotation', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6010a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████| 279/279 [35:23<00:00,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5713711705541193)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='deepseek_v3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b13164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [54:37<00:00, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5834857282245158)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f7a2f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [29:24<00:00,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5538394052582443)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f83c86bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [55:08<00:00, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5448833061145204)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc6c01d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3079 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2865 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|                                                                                                                    | 0/279 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [50:44<00:00, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5969758933708594)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwq', ref_col='abstract')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
