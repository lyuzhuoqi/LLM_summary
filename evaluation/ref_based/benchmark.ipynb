{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfd40bc",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0013e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded llama4 data with shape: (35636, 1)\n",
      "Loaded gemma3 data with shape: (35636, 1)\n",
      "Loaded qwen3 data with shape: (35636, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>llama4</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>qwen3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study suggests that there were two distin...</td>\n",
       "      <td>This study refutes the single origin of domest...</td>\n",
       "      <td>mtDNA analysis reveals ancient divergence betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study, among others, provides evidence of...</td>\n",
       "      <td>This study provides evidence for independent d...</td>\n",
       "      <td>This study demonstrates independent pig domest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>The study describes the fine-mapping approach ...</td>\n",
       "      <td>This study used fine-mapping methods to identi...</td>\n",
       "      <td>This QTL study identifies a 5cM bovine chromos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study demonstrated that linkage disequili...</td>\n",
       "      <td>Reference 35 reports long-range LD in Dutch bl...</td>\n",
       "      <td>\"Genome-wide analysis of Dutch Black-and-white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>The data reported here constitute a comprehens...</td>\n",
       "      <td>This study identifies a major QTL on SSC4 affe...</td>\n",
       "      <td>Identifies a major QTL on chromosome 4 underly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>These studies suggest that isolation and expan...</td>\n",
       "      <td>This study describes an efficient protocol for...</td>\n",
       "      <td>This study demonstrates that CD4+CD127lo/−CD25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that orthogonal IL-2 a...</td>\n",
       "      <td>Reference 48 describes the engineering of a sy...</td>\n",
       "      <td>This work describes engineered synthetic IL-2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies an important mechanism u...</td>\n",
       "      <td>Reference 51 shows that autoreactive T cells c...</td>\n",
       "      <td>This study identifies autoimmune T cell recogn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study presents a comprehensive strategy t...</td>\n",
       "      <td>This work demonstrates that a combined strateg...</td>\n",
       "      <td>This study reports a genome-editing strategy t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study identifies and characterizes human ...</td>\n",
       "      <td>This study identifies a human CD4+CD25high T c...</td>\n",
       "      <td>This study identifies human CD4+CD25high regul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35621 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      This study suggests that there were two distin...   \n",
       "1      This study, among others, provides evidence of...   \n",
       "2      The study describes the fine-mapping approach ...   \n",
       "3      This study demonstrated that linkage disequili...   \n",
       "4      The data reported here constitute a comprehens...   \n",
       "...                                                  ...   \n",
       "35631  These studies suggest that isolation and expan...   \n",
       "35632  This study demonstrates that orthogonal IL-2 a...   \n",
       "35633  This study identifies an important mechanism u...   \n",
       "35634  This study presents a comprehensive strategy t...   \n",
       "35635  This study identifies and characterizes human ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This study refutes the single origin of domest...   \n",
       "1      This study provides evidence for independent d...   \n",
       "2      This study used fine-mapping methods to identi...   \n",
       "3      Reference 35 reports long-range LD in Dutch bl...   \n",
       "4      This study identifies a major QTL on SSC4 affe...   \n",
       "...                                                  ...   \n",
       "35631  This study describes an efficient protocol for...   \n",
       "35632  Reference 48 describes the engineering of a sy...   \n",
       "35633  Reference 51 shows that autoreactive T cells c...   \n",
       "35634  This work demonstrates that a combined strateg...   \n",
       "35635  This study identifies a human CD4+CD25high T c...   \n",
       "\n",
       "                                                   qwen3  \n",
       "0      mtDNA analysis reveals ancient divergence betw...  \n",
       "1      This study demonstrates independent pig domest...  \n",
       "2      This QTL study identifies a 5cM bovine chromos...  \n",
       "3      \"Genome-wide analysis of Dutch Black-and-white...  \n",
       "4      Identifies a major QTL on chromosome 4 underly...  \n",
       "...                                                  ...  \n",
       "35631  This study demonstrates that CD4+CD127lo/−CD25...  \n",
       "35632  This work describes engineered synthetic IL-2 ...  \n",
       "35633  This study identifies autoimmune T cell recogn...  \n",
       "35634  This study reports a genome-editing strategy t...  \n",
       "35635  This study identifies human CD4+CD25high regul...  \n",
       "\n",
       "[35621 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "\n",
    "# models = ['qwen3', 'gemma3', 'llama4', 'qwq']\n",
    "models = ['llama4', 'gemma3', 'qwen3']\n",
    "\n",
    "suffixes = None\n",
    "# suffixes = '_sent_shuffle'\n",
    "# suffixes = '_tail'\n",
    "\n",
    "if suffixes is not None:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}{suffixes}.txt' for model in models]\n",
    "else:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}.txt' for model in models]\n",
    "\n",
    "df = pd.read_csv(home / 'projects/TLDR/data/paper_html_10.1038/abs_annotation/test.tsv', sep='\\t')\n",
    "for model, csv_file in zip(models, csv_files):\n",
    "    with open(csv_file, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        single_df = pd.DataFrame({model: [line.rstrip('\\n') for line in lines]})\n",
    "    print(f\"Loaded {model} data with shape: {single_df.shape}\")\n",
    "    df = df.join(single_df)\n",
    "\n",
    "for index in pd.read_csv(home / \"projects/TLDR/description/invalid_entry_in_test.txt\", sep='\\t', header=None).values.flatten().tolist():\n",
    "    df = df.drop(index-2)  # Adjusting for zero-based index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccece17",
   "metadata": {},
   "source": [
    "# Overlap-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73336b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "def evaluate_metrics(df, pred_col='prediction', ref_col='reference'):\n",
    "    references = df[ref_col].tolist()\n",
    "    predictions = df[pred_col].tolist()\n",
    "\n",
    "    # BLEU\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    bleu_result = bleu.compute(\n",
    "        predictions=predictions,                 # 每个元素是一个字符串\n",
    "        references=[[ref] for ref in references] # 每个元素是字符串列表\n",
    "    )\n",
    "\n",
    "    # METEOR\n",
    "    meteor = evaluate.load(\"meteor\")\n",
    "    meteor_result = meteor.compute(predictions=predictions, references=references)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    rouge_result = rouge.compute(\n",
    "        predictions=predictions,\n",
    "        references=references,\n",
    "        rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "    )\n",
    "\n",
    "    # 只返回需要的分数，便于后续统计平均\n",
    "    rouge_f = {rouge_type: rouge_result[rouge_type] if rouge_result is not None else None \n",
    "               for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]}\n",
    "\n",
    "    return {\n",
    "        'bleu': bleu_result[\"bleu\"] if bleu_result is not None else None,\n",
    "        'rouge': rouge_f,\n",
    "        'meteor': meteor_result[\"meteor\"] if meteor_result is not None else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2306e",
   "metadata": {},
   "source": [
    "## Human-written annotations as references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e2eb0a",
   "metadata": {},
   "source": [
    "### LLMs' performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8adbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.028969544607848348,\n",
       " 'meteor': np.float64(0.22160834782127842),\n",
       " 'rouge': {'rouge1': np.float64(0.2633470229908166),\n",
       "  'rouge2': np.float64(0.05838978845385924),\n",
       "  'rougeL': np.float64(0.20214153426621606)}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3392fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674ed3fb4c4b4ad181756244b6437929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbca90c16ae44934b9c32fbe5a11f4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c26daefb224b709f82889f3939461c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bc6db2a66a4509ad4adf37705b68cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.018849717569693607,\n",
       " 'meteor': np.float64(0.20897899022668442),\n",
       " 'rouge': {'rouge1': np.float64(0.2457537024528486),\n",
       "  'rouge2': np.float64(0.05078721837806385),\n",
       "  'rougeL': np.float64(0.18647269840594777)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567d7493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.004598863487931305,\n",
       " 'rouge': {'rouge1': 0.22713471575476182,\n",
       "  'rouge2': 0.04649528001042595,\n",
       "  'rougeL': 0.1665290272249928},\n",
       " 'meteor': 0.2128801177639297}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec01a63",
   "metadata": {},
   "source": [
    "### Multi-annotated abstracts as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6d7760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of papers:  29356\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.1083/jcb.153.2.397</td>\n",
       "      <td>58551536</td>\n",
       "      <td>The correct positioning of the nucleus is ofte...</td>\n",
       "      <td>Using live imaging and computer simulation the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.1101/gad.14.6.690</td>\n",
       "      <td>131922988</td>\n",
       "      <td>E2F is a family of transcription factors that ...</td>\n",
       "      <td>Disruption of mouse E2f3 , but not E2f1 , redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.1101/gad.859201</td>\n",
       "      <td>18000382</td>\n",
       "      <td>Telomere shortening is the mechanism underlyin...</td>\n",
       "      <td>Growing primary human keratinocytes and mammar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/scitranslmed.aad4134</td>\n",
       "      <td>103721459</td>\n",
       "      <td>Autologous regulatory T cells can be expanded ...</td>\n",
       "      <td>First clinical trial demonstrating up to 1 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1084/jem.20040139</td>\n",
       "      <td>83080620</td>\n",
       "      <td>The low number of CD4+ CD25+ regulatory T cell...</td>\n",
       "      <td>Seminal study showing that antigen-specific T ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35637</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35638</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35640</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10304 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            abs_doi   paper_id  \\\n",
       "0            10.1073/pnas.91.7.2757  107202074   \n",
       "1       10.1093/genetics/154.4.1785   83366887   \n",
       "7             10.1083/jcb.153.2.397   58551536   \n",
       "8              10.1101/gad.14.6.690  131922988   \n",
       "10               10.1101/gad.859201   18000382   \n",
       "...                             ...        ...   \n",
       "35633  10.1126/scitranslmed.aad4134  103721459   \n",
       "35634          10.1084/jem.20040139   83080620   \n",
       "35637       10.1126/science.aar3246    4860145   \n",
       "35638       10.1126/science.aad2791   62290395   \n",
       "35640   10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "7      The correct positioning of the nucleus is ofte...   \n",
       "8      E2F is a family of transcription factors that ...   \n",
       "10     Telomere shortening is the mechanism underlyin...   \n",
       "...                                                  ...   \n",
       "35633  Autologous regulatory T cells can be expanded ...   \n",
       "35634  The low number of CD4+ CD25+ regulatory T cell...   \n",
       "35637  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35638  T cells target peptide combos One of the endur...   \n",
       "35640  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \n",
       "0      A demonstration that cattle have been domestic...  \n",
       "1      Evidence is presented for independent domestic...  \n",
       "7      Using live imaging and computer simulation the...  \n",
       "8      Disruption of mouse E2f3 , but not E2f1 , redu...  \n",
       "10     Growing primary human keratinocytes and mammar...  \n",
       "...                                                  ...  \n",
       "35633  First clinical trial demonstrating up to 1 yea...  \n",
       "35634  Seminal study showing that antigen-specific T ...  \n",
       "35637  This study reports the generation of an orthog...  \n",
       "35638  This article shows that some diabetogenic T ce...  \n",
       "35640  Together with Levings et al. (2001), Jonuleit ...  \n",
       "\n",
       "[10304 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4019 papers are annotated by multiple annotators\n"
     ]
    }
   ],
   "source": [
    "full = pd.read_csv(home / 'projects/TLDR/data/paper_html_10.1038/abs_annotation/abs_annotation.tsv', sep='\\t')\n",
    "print('# of papers: ', full['paper_id'].nunique())\n",
    "\n",
    "multi_annotated = full[full['paper_id'].isin(full['paper_id'].value_counts()[full['paper_id'].value_counts() > 1].index)]\n",
    "display(multi_annotated)\n",
    "print(multi_annotated['paper_id'].unique().shape[0], 'papers are annotated by multiple annotators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88517bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paper_id_counts = full['paper_id'].value_counts()\n",
    "fig = plt.figure(figsize=(3, 2))\n",
    "sns.histplot(x=paper_id_counts, bins=30, stat='count', discrete=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Times of being annotated')\n",
    "plt.ylabel('# of paper')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964dfaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(home / 'projects/TLDR/evaluation/ref_based/paper_annotated_times.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a6668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "paper_id_counts = multi_annotated['paper_id'].value_counts()\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.histplot(x=paper_id_counts, bins=30, stat='count', discrete=True)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Times of being annotated')\n",
    "plt.ylabel('# of paper')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                      | 0/10 [00:00<?, ?it/s][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 10%|████████████▌                                                                                                                 | 1/10 [00:12<01:50, 12.32s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 20%|█████████████████████████▏                                                                                                    | 2/10 [00:22<01:29, 11.15s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 30%|█████████████████████████████████████▊                                                                                        | 3/10 [00:33<01:15, 10.80s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 40%|██████████████████████████████████████████████████▍                                                                           | 4/10 [00:43<01:03, 10.56s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 50%|███████████████████████████████████████████████████████████████                                                               | 5/10 [00:53<00:53, 10.64s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 60%|███████████████████████████████████████████████████████████████████████████▌                                                  | 6/10 [01:04<00:42, 10.51s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 70%|████████████████████████████████████████████████████████████████████████████████████████▏                                     | 7/10 [01:14<00:31, 10.46s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                         | 8/10 [01:25<00:20, 10.47s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 9/10 [01:35<00:10, 10.35s/it][nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:45<00:00, 10.51s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    scores = evaluate_metrics(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643069de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10次抽样平均 ===\n",
      "BLEU: 0.0452\n",
      "METEOR: 0.2159\n",
      "ROUGE (F):\n",
      "  ROUGE1: 0.2739\n",
      "  ROUGE2: 0.0679\n",
      "  ROUGEL: 0.2166\n"
     ]
    }
   ],
   "source": [
    "# 计算平均分\n",
    "bleu_avg = sum(s['bleu'] for s in all_scores) / n_sample\n",
    "meteor_avg = sum(s['meteor'] for s in all_scores) / n_sample\n",
    "rouge_avg = {}\n",
    "for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]:\n",
    "    rouge_avg[rouge_type] = sum(s['rouge'][rouge_type] for s in all_scores) / n_sample\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"BLEU: {:.4f}\".format(bleu_avg))\n",
    "print(\"METEOR: {:.4f}\".format(meteor_avg))\n",
    "print(\"ROUGE (F):\")\n",
    "for rouge_type in [\"rouge1\", \"rouge2\", \"rougeL\"]:\n",
    "    print(\"  {}: {:.4f}\".format(rouge_type.upper(), rouge_avg[rouge_type]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a796d6",
   "metadata": {},
   "source": [
    "## Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d1106a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0006133061271783294,\n",
       " 'rouge': {'rouge1': np.float64(0.19306453849239616),\n",
       "  'rouge2': np.float64(0.07524048036774444),\n",
       "  'rougeL': np.float64(0.13812604747936919)},\n",
       " 'meteor': np.float64(0.10040613089886721)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c62d6219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.003487585346369448,\n",
       " 'rouge': {'rouge1': np.float64(0.18779820422684113),\n",
       "  'rouge2': np.float64(0.0615513947936469),\n",
       "  'rougeL': np.float64(0.12630913326598375)},\n",
       " 'meteor': np.float64(0.09422179709159398)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f33d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.030714638745234092,\n",
       " 'rouge': {'rouge1': 0.2494894076577696,\n",
       "  'rouge2': 0.09113576218297251,\n",
       "  'rougeL': 0.16591093974635696},\n",
       " 'meteor': 0.13454828241954828}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fc89e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.00014032267591655747,\n",
       " 'meteor': np.float64(0.06377415902193286),\n",
       " 'rouge': {'rouge1': np.float64(0.1408848000436993),\n",
       "  'rouge2': np.float64(0.03825775412279675),\n",
       "  'rougeL': np.float64(0.10050406185966701)}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metrics(df, pred_col='annotation', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee60430",
   "metadata": {},
   "source": [
    "# Simlarity-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b8949",
   "metadata": {},
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5a5835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "def evaluate_bertscore(df, pred_col='prediction', ref_col='reference'):\n",
    "    preds = df[pred_col].tolist()\n",
    "    refs = df[ref_col].tolist()\n",
    "\n",
    "    P, R, F1 = score(preds, refs, lang='en', \n",
    "                     use_fast_tokenizer=True,\n",
    "                     batch_size=32,\n",
    "                     verbose=True)\n",
    "    print(f\"BERTScore F1: {F1.mean().item():.4f}\")\n",
    "    return {\n",
    "        \"BERTScore_P\": P.mean().item(),\n",
    "        \"BERTScore_R\": R.mean().item(),\n",
    "        \"BERTScore_F1\": F1.mean().item()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869dcd26",
   "metadata": {},
   "source": [
    "### Human-wrtten annotations as references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de17ed",
   "metadata": {},
   "source": [
    "#### LLMs' performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f2a4590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ed97cf740e4241b4428dfadf8f27c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb0840794904df9b60fd9eeee5374b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 110.27 seconds, 323.05 sentences/sec\n",
      "BERTScore F1: 0.8817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8761969804763794,\n",
       " 'BERTScore_R': 0.8877111673355103,\n",
       " 'BERTScore_F1': 0.8817406296730042}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fd7d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7ca93d85b2468499a8571b22f383f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1113 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300ff9d4c1c54ef1a3b55376a0923e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 316.19 seconds, 112.66 sentences/sec\n",
      "BERTScore F1: 0.8771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8746355772018433,\n",
       " 'BERTScore_R': 0.8801242113113403,\n",
       " 'BERTScore_F1': 0.8771476745605469}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68df66e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce57d4ebf914ac2b21936cdc56d48b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c09fd540d84d3cb7b51c0da2a53d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 460.14 seconds, 77.41 sentences/sec\n",
      "BERTScore F1: 0.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8533397912979126,\n",
       " 'BERTScore_R': 0.8875028491020203,\n",
       " 'BERTScore_F1': 0.8699047565460205}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2d975",
   "metadata": {},
   "source": [
    "#### Multi-annotated papers as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fff830e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                    | 0/10 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca48708fbdf74f9189b342e2672c3831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91929146b04f4492ad37cb3724ba49c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▌                                                                    | 1/10 [00:38<05:50, 39.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.19 seconds, 168.93 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c48c755134749c18147a4f25ad4a336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459bed1d8b1e4054828c5c916057f4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████▏                                                            | 2/10 [01:16<05:04, 38.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.41 seconds, 167.90 sentences/sec\n",
      "BERTScore F1: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5772820aac5444f94d375533bff96ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e72dc098eb4cf0a1e194f6f728c83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████████████▊                                                     | 3/10 [01:55<04:28, 38.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.74 seconds, 166.45 sentences/sec\n",
      "BERTScore F1: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed4c9d63f7c4ffcbe2abed6a2189858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a90079173a34652bd983dc4b3ab6a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 4/10 [02:33<03:50, 38.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.65 seconds, 166.86 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5aca048be64898a71e98e08af6116b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a9bb69300e469d9143db66ac4e0d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████                                      | 5/10 [03:12<03:12, 38.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.83 seconds, 166.05 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33e34168bdf48c98655cbaa80117f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161bc74ea8b94c1ab8649478223452b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████▌                              | 6/10 [03:50<02:33, 38.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.71 seconds, 166.58 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c98cd44d1a643d7bda38ea0ca71de87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6f66f705c641cbb8054a2ae29b943c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████▏                      | 7/10 [04:28<01:55, 38.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.82 seconds, 166.09 sentences/sec\n",
      "BERTScore F1: 0.8813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe77b56e4a54358b9cf37bb8ee328a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805759f302ac484b8a083df4baf1eddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████▊               | 8/10 [05:07<01:16, 38.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.64 seconds, 166.84 sentences/sec\n",
      "BERTScore F1: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f267f3ad097e41518342f1a8c35cbfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6c72d5777c4f84b44d656c882458b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████▍       | 9/10 [05:45<00:38, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.64 seconds, 166.86 sentences/sec\n",
      "BERTScore F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50cbd3639e94398a3f1ee040592f84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/161 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b81b58e5734f53b123e32143e67880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10/10 [06:24<00:00, 38.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 37.97 seconds, 165.43 sentences/sec\n",
      "BERTScore F1: 0.8813\n",
      "=== 10次抽样平均 ===\n",
      "BERTScore: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    scores = evaluate_bertscore(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(scores)\n",
    "\n",
    "# 计算平均分\n",
    "bertscore_avg = sum(s['BERTScore_F1'] for s in all_scores) / n_sample\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"BERTScore: {:.4f}\".format(bertscore_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9edfd",
   "metadata": {},
   "source": [
    "### Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "479664e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7364b869bf2c4e908fe6cb0e6e68eb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57df04af6edd40289982244e0a532aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 344.80 seconds, 103.31 sentences/sec\n",
      "BERTScore F1: 0.8637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.9006731510162354,\n",
       " 'BERTScore_R': 0.8299712538719177,\n",
       " 'BERTScore_F1': 0.8637344837188721}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80e61a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6369862d8104d52aaefbbc9a78defe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a171ed0f105949b1a09cdeb8ed9ba753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 360.11 seconds, 98.92 sentences/sec\n",
      "BERTScore F1: 0.8565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8925188183784485,\n",
       " 'BERTScore_R': 0.8236910700798035,\n",
       " 'BERTScore_F1': 0.8565149307250977}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a81c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1737ad1b757d4666b33fe90acdfe8e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5800e8fdf4ee46d18cbdd1f99826067a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1268.99 seconds, 28.07 sentences/sec\n",
      "BERTScore F1: 0.8694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8968477249145508,\n",
       " 'BERTScore_R': 0.8439767956733704,\n",
       " 'BERTScore_F1': 0.8694406151771545}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02950398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [05:34<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [00:17<00:00, 31.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 354.50 seconds, 100.48 sentences/sec\n",
      "BERTScore F1: 0.8410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BERTScore_P': 0.8739364147186279,\n",
       " 'BERTScore_R': 0.8107424378395081,\n",
       " 'BERTScore_F1': 0.840957522392273}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_bertscore(df, pred_col='annotation', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3351f35",
   "metadata": {},
   "source": [
    "## MoverScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0706f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158947a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.model_max_length:  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lyuzhuoqi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(home / 'projects/TLDR/evaluation/ref_based'))\n",
    "\n",
    "from moverscore_v2 import get_idf_dict, word_mover_score \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def evaluate_moverscore(df, pred_col='prediction', ref_col='reference'):\n",
    "    preds = df[pred_col].tolist()\n",
    "    refs = df[ref_col].tolist()\n",
    "\n",
    "    idf_dict_hyp = get_idf_dict(preds)\n",
    "    idf_dict_ref = get_idf_dict(refs)\n",
    "\n",
    "    scores = word_mover_score(refs, preds, idf_dict_ref, idf_dict_hyp, stop_words=stopwords.words('english'))\n",
    "    print(f'MoverScore: {np.mean(scores):.4f}')\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d26011",
   "metadata": {},
   "source": [
    "### Human-written annotations as references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735fcb81",
   "metadata": {},
   "source": [
    "#### LLMs' performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "728a265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:  92%|██████████████████████████████████████████████████████████████████████████████████████████████████        | 258/279 [02:06<00:08,  2.37it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [02:32<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.566014325735857)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='gemma3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dcc1e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [06:55<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.559332717702572)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='llama4', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "049ffff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2578 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (41841 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (41493 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|                                                                   | 0/279 [00:00<?, ?it/s]DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS:   1%|▋                                                          | 3/279 [00:07<10:03,  2.19s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (41493 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS: 100%|███████████████████████████████████████████████████████| 279/279 [1:26:58<00:00, 18.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5578431509562374"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwen3', ref_col='annotation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4688852c",
   "metadata": {},
   "source": [
    "#### Multi-annotated abstracts as a human-evaluation baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a052747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.08it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:43<00:00,  1.16it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:45<00:00,  1.10it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:47<00:00,  1.05it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:40<00:00,  1.23it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:44<00:00,  1.12it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:38<00:00,  1.31it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:39<00:00,  1.26it/s]\n",
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████| 50/50 [00:39<00:00,  1.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10/10 [07:18<00:00, 43.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 10次抽样平均 ===\n",
      "MoverScore: 0.5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_scores = []\n",
    "n_sample = 10  # 抽样次数\n",
    "\n",
    "for _ in tqdm(range(n_sample)):\n",
    "    grouped = multi_annotated.groupby('paper_id')\n",
    "    results = []\n",
    "    for paper_id, group in grouped:\n",
    "        annotations = group['annotation'].tolist()\n",
    "        if len(annotations) < 2:\n",
    "            continue\n",
    "        ref = random.choice(annotations)\n",
    "        preds = [a for a in annotations if a != ref]\n",
    "        for pred in preds:\n",
    "            results.append({'paper_id': paper_id, 'reference': ref, 'prediction': pred})\n",
    "\n",
    "    eval_df = pd.DataFrame(results)\n",
    "    score = evaluate_moverscore(eval_df, pred_col='prediction', ref_col='reference')\n",
    "    all_scores.append(score)\n",
    "\n",
    "# 计算平均分\n",
    "moverscore_avg = np.mean(all_scores)\n",
    "\n",
    "print(\"=== 10次抽样平均 ===\")\n",
    "print(\"MoverScore: {:.4f}\".format(moverscore_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac24c13e",
   "metadata": {},
   "source": [
    "### Abstracts as references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f7a2f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [27:06<00:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5523958961946267)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='gemma3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f83c86bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating WMS: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 279/279 [42:41<00:00,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5438416908340507)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='llama4', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06b13164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2578 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (41841 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (41493 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|                                                                    | 0/279 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS: 100%|████████████████████████████████████████████████████████| 279/279 [3:46:22<00:00, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoverScore: 0.5681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5681377232282112"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='qwen3', ref_col='abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05007b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
      "Calculating WMS:   0%|          | 0/279 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "DistilBertSdpaAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Calculating WMS: 100%|██████████| 279/279 [25:33<00:00,  5.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5301549328571855)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_moverscore(df, pred_col='annotation', ref_col='abstract')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
