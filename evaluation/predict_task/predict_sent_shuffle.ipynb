{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1ac11c",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a395ee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35621 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "35631  This work shows that Tregs from type 1 diabeti...   \n",
       "35632  This study demonstrates that engineered IL-2 r...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This report describes a novel genome editing a...   \n",
       "35635  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4  \n",
       "0      These results provide evidence that modern cat...  \n",
       "1      These findings provide evidence for independen...  \n",
       "2      The authors fine-map a QTL for milk fat percen...  \n",
       "3      This study is among the first to examine the e...  \n",
       "4      This study mapped genetic loci associated with...  \n",
       "...                                                  ...  \n",
       "35631  This study highlights the challenges of transl...  \n",
       "35632  These findings suggest that engineering cytoki...  \n",
       "35633  T cells recognize a unique type of antigen tha...  \n",
       "35634  This study demonstrated that human ESCs and iP...  \n",
       "35635  These studies identify a population of human C...  \n",
       "\n",
       "[35621 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "\n",
    "# models = ['gemma3', 'llama4', 'qwen3']\n",
    "models = ['gemma3', 'llama4']\n",
    "\n",
    "# suffixes = None\n",
    "suffixes = '_sent_shuffle'\n",
    "# suffixes = '_tail'\n",
    "if suffixes is not None:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}{suffixes}.txt' for model in models]\n",
    "else:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}.txt' for model in models]\n",
    "\n",
    "df = pd.read_csv(home / 'projects/TLDR/data/paper_html_10.1038/abs_annotation/test.tsv', sep='\\t')\n",
    "for model, csv_file in zip(models, csv_files):\n",
    "    single_df = pd.read_csv(csv_file, sep='\\t', header=None, names=[model])\n",
    "    df = df.join(single_df)\n",
    "\n",
    "for index in pd.read_csv(home / \"projects/TLDR/description/invalid_entry_in_test.txt\", sep='\\t', header=None).values.flatten().tolist():\n",
    "    df = df.drop(index-2)  # Adjusting for zero-based index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c7b3f",
   "metadata": {},
   "source": [
    "# Load publication venue and year from MAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1b38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading doi_mag_pid_dict...\n",
      "doi_mag_pid_dict loaded.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34775 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "35631  This work shows that Tregs from type 1 diabeti...   \n",
       "35632  This study demonstrates that engineered IL-2 r...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This report describes a novel genome editing a...   \n",
       "35635  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \n",
       "0      These results provide evidence that modern cat...  2005395185  \n",
       "1      These findings provide evidence for independen...  2110049233  \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742  \n",
       "3      This study is among the first to examine the e...  2103106090  \n",
       "4      This study mapped genetic loci associated with...  2045457895  \n",
       "...                                                  ...         ...  \n",
       "35631  This study highlights the challenges of transl...  2137227986  \n",
       "35632  These findings suggest that engineering cytoki...  2789780246  \n",
       "35633  T cells recognize a unique type of antigen tha...  2266478788  \n",
       "35634  This study demonstrated that human ESCs and iP...  2943378944  \n",
       "35635  These studies identify a population of human C...  1560277370  \n",
       "\n",
       "[34775 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "print(\"Loading doi_mag_pid_dict...\")\n",
    "with open(home / \"projects/TLDR/data/doi_mag_pid_dict.pkl\", \"rb\") as f:\n",
    "    doi_mag_pid_dict = pickle.load(f)\n",
    "    print(\"doi_mag_pid_dict loaded.\")\n",
    "\n",
    "df['mag_pid'] = df['doi'].map(doi_mag_pid_dict)\n",
    "df = df.dropna(subset=['mag_pid'])\n",
    "df.loc[:, 'mag_pid'] = df['mag_pid'].apply(lambda x: x.split(';')[0] if isinstance(x, str) else x)\n",
    "df.loc[:, 'mag_pid'] = df['mag_pid'].astype(int)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01563aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34262 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "35631  This work shows that Tregs from type 1 diabeti...   \n",
       "35632  This study demonstrates that engineered IL-2 r...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This report describes a novel genome editing a...   \n",
       "35635  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \\\n",
       "0      These results provide evidence that modern cat...  2005395185   \n",
       "1      These findings provide evidence for independen...  2110049233   \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742   \n",
       "3      This study is among the first to examine the e...  2103106090   \n",
       "4      This study mapped genetic loci associated with...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "35631  This study highlights the challenges of transl...  2137227986   \n",
       "35632  These findings suggest that engineering cytoki...  2789780246   \n",
       "35633  T cells recognize a unique type of antigen tha...  2266478788   \n",
       "35634  This study demonstrated that human ESCs and iP...  2943378944   \n",
       "35635  These studies identify a population of human C...  1560277370   \n",
       "\n",
       "         mag_vid  year  \n",
       "0      125754415  1994  \n",
       "1       65932378  2000  \n",
       "2      125754415  1999  \n",
       "3       43092948  2000  \n",
       "4        3880285  1994  \n",
       "...          ...   ...  \n",
       "35631  129060628  2009  \n",
       "35632    3880285  2018  \n",
       "35633    3880285  2016  \n",
       "35634  125754415  2019  \n",
       "35635   38008053  2001  \n",
       "\n",
       "[34262 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAG_paper_df = pd.read_parquet(home / 'projects/TLDR/data/MAG_paper.parquet')\n",
    "df = df.merge(MAG_paper_df[['VenueID', 'Year']], left_on='mag_pid', right_index=True, how='inner')\n",
    "df.rename(columns={'VenueID': 'mag_vid', 'Year': 'year'}, inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd1e4d",
   "metadata": {},
   "source": [
    "# Load subject label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc271ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scopus_label</th>\n",
       "      <th>movMF_label</th>\n",
       "      <th>movMF_distance</th>\n",
       "      <th>x_val</th>\n",
       "      <th>y_val</th>\n",
       "      <th>kmeans_label</th>\n",
       "      <th>kmeans_distance</th>\n",
       "      <th>skm_label</th>\n",
       "      <th>skm_distance</th>\n",
       "      <th>spectral_label</th>\n",
       "      <th>n2v_kmeans_label</th>\n",
       "      <th>cm_kmeans_label</th>\n",
       "      <th>gnn_kmeans_label</th>\n",
       "      <th>bert_kmeans_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202381698</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.445886</td>\n",
       "      <td>-67.928200</td>\n",
       "      <td>15.572327</td>\n",
       "      <td>17</td>\n",
       "      <td>0.628846</td>\n",
       "      <td>20</td>\n",
       "      <td>0.444711</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137773608</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>-68.405334</td>\n",
       "      <td>-55.633186</td>\n",
       "      <td>17</td>\n",
       "      <td>0.735654</td>\n",
       "      <td>20</td>\n",
       "      <td>0.559494</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125754415</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.574571</td>\n",
       "      <td>-68.448853</td>\n",
       "      <td>-55.613579</td>\n",
       "      <td>17</td>\n",
       "      <td>0.705024</td>\n",
       "      <td>20</td>\n",
       "      <td>0.550081</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880285</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>23</td>\n",
       "      <td>0.618842</td>\n",
       "      <td>-68.407288</td>\n",
       "      <td>-55.634430</td>\n",
       "      <td>8</td>\n",
       "      <td>0.724859</td>\n",
       "      <td>17</td>\n",
       "      <td>0.610582</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111155417</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>23</td>\n",
       "      <td>0.220853</td>\n",
       "      <td>-54.506985</td>\n",
       "      <td>-61.217068</td>\n",
       "      <td>11</td>\n",
       "      <td>0.495787</td>\n",
       "      <td>12</td>\n",
       "      <td>0.198758</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764485818</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>21</td>\n",
       "      <td>0.268070</td>\n",
       "      <td>-28.969574</td>\n",
       "      <td>34.819569</td>\n",
       "      <td>18</td>\n",
       "      <td>0.542531</td>\n",
       "      <td>14</td>\n",
       "      <td>0.251015</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83454320</th>\n",
       "      <td>Arts and Humanities</td>\n",
       "      <td>25</td>\n",
       "      <td>0.034777</td>\n",
       "      <td>78.609909</td>\n",
       "      <td>31.736822</td>\n",
       "      <td>13</td>\n",
       "      <td>0.251599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056642</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507453</th>\n",
       "      <td>Arts and Humanities</td>\n",
       "      <td>6</td>\n",
       "      <td>0.113656</td>\n",
       "      <td>89.206772</td>\n",
       "      <td>17.625090</td>\n",
       "      <td>13</td>\n",
       "      <td>0.307089</td>\n",
       "      <td>3</td>\n",
       "      <td>0.128660</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121509672</th>\n",
       "      <td>Agricultural and Biological Sciences</td>\n",
       "      <td>5</td>\n",
       "      <td>0.179111</td>\n",
       "      <td>-36.757057</td>\n",
       "      <td>-0.591017</td>\n",
       "      <td>21</td>\n",
       "      <td>0.430040</td>\n",
       "      <td>16</td>\n",
       "      <td>0.207435</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53107364</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>23</td>\n",
       "      <td>0.258839</td>\n",
       "      <td>-46.797390</td>\n",
       "      <td>-55.657715</td>\n",
       "      <td>11</td>\n",
       "      <td>0.494533</td>\n",
       "      <td>12</td>\n",
       "      <td>0.223036</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20038 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Scopus_label  movMF_label  movMF_distance  \\\n",
       "202381698                      Multidisciplinary           22        0.445886   \n",
       "137773608                      Multidisciplinary           22        0.590942   \n",
       "125754415                      Multidisciplinary           22        0.574571   \n",
       "3880285                        Multidisciplinary           23        0.618842   \n",
       "111155417                              Chemistry           23        0.220853   \n",
       "...                                          ...          ...             ...   \n",
       "2764485818                              Medicine           21        0.268070   \n",
       "83454320                     Arts and Humanities           25        0.034777   \n",
       "16507453                     Arts and Humanities            6        0.113656   \n",
       "121509672   Agricultural and Biological Sciences            5        0.179111   \n",
       "53107364                                Medicine           23        0.258839   \n",
       "\n",
       "                x_val      y_val  kmeans_label  kmeans_distance  skm_label  \\\n",
       "202381698  -67.928200  15.572327            17         0.628846         20   \n",
       "137773608  -68.405334 -55.633186            17         0.735654         20   \n",
       "125754415  -68.448853 -55.613579            17         0.705024         20   \n",
       "3880285    -68.407288 -55.634430             8         0.724859         17   \n",
       "111155417  -54.506985 -61.217068            11         0.495787         12   \n",
       "...               ...        ...           ...              ...        ...   \n",
       "2764485818 -28.969574  34.819569            18         0.542531         14   \n",
       "83454320    78.609909  31.736822            13         0.251599          3   \n",
       "16507453    89.206772  17.625090            13         0.307089          3   \n",
       "121509672  -36.757057  -0.591017            21         0.430040         16   \n",
       "53107364   -46.797390 -55.657715            11         0.494533         12   \n",
       "\n",
       "            skm_distance  spectral_label  n2v_kmeans_label  cm_kmeans_label  \\\n",
       "202381698       0.444711              24                 3               21   \n",
       "137773608       0.559494              24                20               21   \n",
       "125754415       0.550081              24                20               21   \n",
       "3880285         0.610582              24                20               21   \n",
       "111155417       0.198758              14                 4               24   \n",
       "...                  ...             ...               ...              ...   \n",
       "2764485818      0.251015               8                18                1   \n",
       "83454320        0.056642              21                 5                1   \n",
       "16507453        0.128660              21                 5                1   \n",
       "121509672       0.207435              10                 5                1   \n",
       "53107364        0.223036              14                 0               24   \n",
       "\n",
       "            gnn_kmeans_label  bert_kmeans_label  \n",
       "202381698                  0                  0  \n",
       "137773608                  0                  3  \n",
       "125754415                  0                  0  \n",
       "3880285                    0                  3  \n",
       "111155417                 21                  0  \n",
       "...                      ...                ...  \n",
       "2764485818                19                  1  \n",
       "83454320                  14                  1  \n",
       "16507453                  14                  1  \n",
       "121509672                 10                  1  \n",
       "53107364                  22                  1  \n",
       "\n",
       "[20038 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_parquet(home / 'projects/TLDR/data/cluster_df.parquet')\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0971ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34146 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "35631  This work shows that Tregs from type 1 diabeti...   \n",
       "35632  This study demonstrates that engineered IL-2 r...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This report describes a novel genome editing a...   \n",
       "35635  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \\\n",
       "0      These results provide evidence that modern cat...  2005395185   \n",
       "1      These findings provide evidence for independen...  2110049233   \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742   \n",
       "3      This study is among the first to examine the e...  2103106090   \n",
       "4      This study mapped genetic loci associated with...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "35631  This study highlights the challenges of transl...  2137227986   \n",
       "35632  These findings suggest that engineering cytoki...  2789780246   \n",
       "35633  T cells recognize a unique type of antigen tha...  2266478788   \n",
       "35634  This study demonstrated that human ESCs and iP...  2943378944   \n",
       "35635  These studies identify a population of human C...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "35631  129060628  2009         17   \n",
       "35632    3880285  2018          8   \n",
       "35633    3880285  2016          8   \n",
       "35634  125754415  2019         17   \n",
       "35635   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \n",
       "0                                 Multidisciplinary  \n",
       "1      Biochemistry, Genetics and Molecular Biology  \n",
       "2                                 Multidisciplinary  \n",
       "3      Biochemistry, Genetics and Molecular Biology  \n",
       "4                                 Multidisciplinary  \n",
       "...                                             ...  \n",
       "35631                                      Medicine  \n",
       "35632                             Multidisciplinary  \n",
       "35633                             Multidisciplinary  \n",
       "35634                             Multidisciplinary  \n",
       "35635                   Immunology and Microbiology  \n",
       "\n",
       "[34146 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(label_df[['kmeans_label', 'Scopus_label']], left_on='mag_vid', right_index=True, how='inner')\n",
    "df.rename(columns={'kmeans_label': 'p2v_label', 'Scopus_label': 'scopus_label'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "226296ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p2v_label\n",
       "17    18439\n",
       "8      9625\n",
       "6      1457\n",
       "7      1028\n",
       "4       627\n",
       "9       611\n",
       "11      580\n",
       "22      404\n",
       "18      363\n",
       "21      319\n",
       "12      292\n",
       "20      121\n",
       "1        60\n",
       "3        49\n",
       "14       32\n",
       "5        25\n",
       "24       21\n",
       "16       21\n",
       "15       17\n",
       "2        16\n",
       "23       16\n",
       "0        10\n",
       "19        6\n",
       "13        5\n",
       "25        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['p2v_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcc140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scopus_label\n",
       "Multidisciplinary                               15639\n",
       "Medicine                                         5262\n",
       "Immunology and Microbiology                      4146\n",
       "Biochemistry, Genetics and Molecular Biology     4116\n",
       "Chemistry                                        1285\n",
       "Neuroscience                                     1211\n",
       "Agricultural and Biological Sciences              704\n",
       "Social Sciences                                   608\n",
       "Earth and Planetary Sciences                      235\n",
       "Materials Science                                 179\n",
       "Psychology                                        156\n",
       "Physics and Astronomy                             139\n",
       "Pharmacology, Toxicology and Pharmaceutics        128\n",
       "Environmental Science                             119\n",
       "Energy                                             39\n",
       "Mathematics                                        30\n",
       "Engineering                                        28\n",
       "Computer Science                                   24\n",
       "Nursing                                            24\n",
       "Economics, Econometrics and Finance                21\n",
       "Dentistry                                          16\n",
       "Chemical Engineering                               13\n",
       "Business, Management and Accounting                 8\n",
       "Health Professions                                  6\n",
       "Arts and Humanities                                 6\n",
       "Veterinary                                          3\n",
       "Decision Sciences                                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scopus_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbda26a",
   "metadata": {},
   "source": [
    "# Predict subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd843a0",
   "metadata": {},
   "source": [
    "## 10-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590f6dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 10000 positive pairs and 10000 negative pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing abstract: 100%|█████████████████████████████████████████████████████| 10/10 [00:45<00:00,  4.59s/folds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score for abstract: 0.7613152636945468\n",
      "Standard deviation of F1 score for abstract: 0.014532715830758054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing annotation: 100%|███████████████████████████████████████████████████| 10/10 [00:24<00:00,  2.48s/folds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score for annotation: 0.7041539962283803\n",
      "Standard deviation of F1 score for annotation: 0.015020152453215205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gemma3: 100%|███████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.70s/folds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score for gemma3: 0.7165072279835548\n",
      "Standard deviation of F1 score for gemma3: 0.013928923810372484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing llama4: 100%|███████████████████████████████████████████████████████| 10/10 [00:24<00:00,  2.47s/folds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score for llama4: 0.7167345318626148\n",
      "Standard deviation of F1 score for llama4: 0.009185133151252784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.75935</td>\n",
       "      <td>0.012806</td>\n",
       "      <td>0.755011</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.761315</td>\n",
       "      <td>0.015319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.70095</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.696856</td>\n",
       "      <td>0.017330</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.020808</td>\n",
       "      <td>0.704154</td>\n",
       "      <td>0.015833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.71335</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.708843</td>\n",
       "      <td>0.015227</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.026783</td>\n",
       "      <td>0.716507</td>\n",
       "      <td>0.014682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.71495</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>0.712741</td>\n",
       "      <td>0.015927</td>\n",
       "      <td>0.7216</td>\n",
       "      <td>0.024514</td>\n",
       "      <td>0.716735</td>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "0    abstract        0.75935      0.012806        0.755011       0.013546   \n",
       "1  annotation        0.70095      0.015935        0.696856       0.017330   \n",
       "2      gemma3        0.71335      0.013058        0.708843       0.015227   \n",
       "3      llama4        0.71495      0.009293        0.712741       0.015927   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "0       0.7683    0.027725  0.761315  0.015319  \n",
       "1       0.7119    0.020808  0.704154  0.015833  \n",
       "2       0.7250    0.026783  0.716507  0.014682  \n",
       "3       0.7216    0.024514  0.716735  0.009682  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TorchMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "def train_torch_mlp(X_train, y_train, X_val, y_val, hidden_dim=128, lr=1e-3, num_epochs=10, batch_size=128):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TorchMLP(X_train.shape[1], hidden_dim=hidden_dim).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        permutation = torch.randperm(X_train_tensor.size(0))\n",
    "        for i in range(0, X_train_tensor.size(0), batch_size):\n",
    "            idx = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = X_train_tensor[idx], y_train_tensor[idx]\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_torch_mlp(model, X, y):\n",
    "    device = next(model.parameters()).device\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_tensor)\n",
    "        preds = (torch.sigmoid(logits) > 0.5).cpu().numpy()\n",
    "    return {\n",
    "        'f1': f1_score(y, preds, zero_division=0),\n",
    "        'accuracy': accuracy_score(y, preds),\n",
    "        'precision': precision_score(y, preds, zero_division=0),\n",
    "        'recall': recall_score(y, preds, zero_division=0)\n",
    "    }\n",
    "\n",
    "def sample_pairs(df_q, n_pairs, rng):\n",
    "    \"\"\"\n",
    "    - 正样本：随机选择一个有效类别，从该类别中选两个不同paper组成pair\n",
    "    - 负样本：随机选择一个类别，选择一个paper，再从其他类别中选择一个paper组成pair\n",
    "    \n",
    "    参数:\n",
    "        df_q: 包含数据的DataFrame\n",
    "        n_pairs: 需要采样的正负样本对数量\n",
    "        rng: 随机数生成器\n",
    "        \n",
    "    返回:\n",
    "        pos_pairs, neg_pairs: 正样本对和负样本对的列表\n",
    "    \"\"\"\n",
    "    label_groups = {k: v.index.tolist() for k, v in df_q.groupby('p2v_label')} # 按标签分组\n",
    "    valid_labels = [lbl for lbl, idxs in label_groups.items() if len(idxs) >= 2]  # 找出有效标签（至少有2个样本）\n",
    "    if not valid_labels:\n",
    "        raise ValueError(\"没有找到包含至少2个样本的有效标签\")\n",
    "    all_pairs = set() # 用于跟踪所有生成的对（无论正负）以避免重复\n",
    "    \n",
    "    # 生成正样本对\n",
    "    pos_pairs = []\n",
    "    attempts_pos = 0\n",
    "    max_attempts_pos = n_pairs * 10  # 避免无限循\n",
    "    while len(pos_pairs) < n_pairs and attempts_pos < max_attempts_pos:\n",
    "        attempts_pos += 1\n",
    "        # 1. 随机选择一个有效标签\n",
    "        label = rng.choice(valid_labels)\n",
    "        papers = label_groups[label]\n",
    "        if len(papers) < 2:\n",
    "            continue\n",
    "        # 2. 从该标签的papers中选择两个不同的paper\n",
    "        idx1, idx2 = rng.choice(papers, 2, replace=False)\n",
    "        pair = (min(idx1, idx2), max(idx1, idx2))  # 确保顺序一致性\n",
    "        # 3. 检查是否重复\n",
    "        if pair not in all_pairs:\n",
    "            pos_pairs.append(pair)\n",
    "            all_pairs.add(pair)\n",
    "    if len(pos_pairs) < n_pairs:\n",
    "        warnings.warn(f\"只能生成 {len(pos_pairs)}/{n_pairs} 个正样本对\")\n",
    "    \n",
    "    # 生成负样本对\n",
    "    neg_pairs = []\n",
    "    attempts_neg = 0\n",
    "    max_attempts_neg = n_pairs * 10  # 避免无限循环\n",
    "    # 创建一个反向映射，用于快速检查索引属于哪个标签\n",
    "    index_to_label = {}\n",
    "    for label, indices in label_groups.items():\n",
    "        for idx in indices:\n",
    "            index_to_label[idx] = label\n",
    "    \n",
    "    while len(neg_pairs) < n_pairs and attempts_neg < max_attempts_neg:\n",
    "        attempts_neg += 1\n",
    "        # 1. 随机选择一个标签\n",
    "        label1 = rng.choice(list(label_groups.keys()))\n",
    "        if not label_groups[label1]:  # 如果该标签没有样本，跳过\n",
    "            continue\n",
    "        # 2. 从该标签中选择一个paper\n",
    "        idx1 = rng.choice(label_groups[label1])\n",
    "        # 3. 构建不属于该标签的papers列表\n",
    "        other_papers = [idx for idx in df_q.index if index_to_label.get(idx) != label1]\n",
    "        if not other_papers:  # 如果没有其他标签的paper，跳过\n",
    "            continue\n",
    "        # 4. 从其他标签的papers中选择一个\n",
    "        idx2 = rng.choice(other_papers)\n",
    "        # 确保顺序一致性并检查重复\n",
    "        pair = (min(idx1, idx2), max(idx1, idx2))\n",
    "        if pair not in all_pairs:\n",
    "            neg_pairs.append(pair)\n",
    "            all_pairs.add(pair)\n",
    "    if len(neg_pairs) < n_pairs:\n",
    "        warnings.warn(f\"只能生成 {len(neg_pairs)}/{n_pairs} 个负样本对\")\n",
    "        \n",
    "    return pos_pairs, neg_pairs\n",
    "\n",
    "metrics_sub_df = pd.DataFrame(columns=[\n",
    "    'feature', \n",
    "    'accuracy_mean', 'accuracy_std',\n",
    "    'precision_mean', 'precision_std', \n",
    "    'recall_mean', 'recall_std',\n",
    "    'f1_mean', 'f1_std',\n",
    "])\n",
    "\n",
    "PAIR_SAMPLE_SIZE = 10000\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "df_sub = df.reset_index(drop=True)\n",
    "pos_pairs, neg_pairs = sample_pairs(df_sub, PAIR_SAMPLE_SIZE, rng)\n",
    "print(f\"Sampled {len(pos_pairs)} positive pairs and {len(neg_pairs)} negative pairs.\")\n",
    "pair_samples = (\n",
    "    [{'idx1': idx1, 'idx2': idx2, 'label': 1} for idx1, idx2 in pos_pairs] +\n",
    "    [{'idx1': idx1, 'idx2': idx2, 'label': 0} for idx1, idx2 in neg_pairs]\n",
    ")\n",
    "pair_samples_df = pd.DataFrame(pair_samples)\n",
    "metrics_list = []\n",
    "for feat in ['abstract', 'annotation','gemma3', 'llama4']:\n",
    "    X = df_sub[feat].astype(str).fillna('').tolist()\n",
    "    y = pair_samples_df['label'].values\n",
    "    txt1_list = [X[row['idx1']] for _, row in pair_samples_df.iterrows()]\n",
    "    txt2_list = [X[row['idx2']] for _, row in pair_samples_df.iterrows()]\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_metrics = []\n",
    "    for fold_idx, (train_idx, test_idx) in tqdm(enumerate(cv.split(np.zeros(len(y)), y)), total=cv.get_n_splits(), unit='folds', desc=f\"Processing {feat}\"):\n",
    "        txt1_train = [txt1_list[j] for j in train_idx]\n",
    "        txt2_train = [txt2_list[j] for j in train_idx]\n",
    "        txt1_test = [txt1_list[j] for j in test_idx]\n",
    "        txt2_test = [txt2_list[j] for j in test_idx]\n",
    "\n",
    "        vectorizer1 = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "        vectorizer2 = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "        vec1_train = vectorizer1.fit_transform(txt1_train).toarray()\n",
    "        vec2_train = vectorizer2.fit_transform(txt2_train).toarray()\n",
    "        vec1_test = vectorizer1.transform(txt1_test).toarray()\n",
    "        vec2_test = vectorizer2.transform(txt2_test).toarray()\n",
    "        X_train = np.concatenate([vec1_train, vec2_train], axis=1)\n",
    "        X_test = np.concatenate([vec1_test, vec2_test], axis=1)\n",
    "        y_train = y[train_idx]\n",
    "        y_test = y[test_idx]\n",
    "        model = train_torch_mlp(X_train, y_train, X_test, y_test, num_epochs=10)\n",
    "        metrics = eval_torch_mlp(model, X_test, y_test)\n",
    "        fold_metrics.append(metrics)\n",
    "    print(f\"Mean F1 score for {feat}: {np.mean([m['f1'] for m in fold_metrics])}\")\n",
    "    print(f\"Standard deviation of F1 score for {feat}: {np.std([m['f1'] for m in fold_metrics])}\")\n",
    "\n",
    "    metrics_10_fold = pd.DataFrame(fold_metrics)\n",
    "    metrics_list.append({\n",
    "            'feature': feat,\n",
    "            'accuracy_mean': metrics_10_fold['accuracy'].mean(),\n",
    "            'accuracy_std': metrics_10_fold['accuracy'].std(),\n",
    "            'precision_mean': metrics_10_fold['precision'].mean(),\n",
    "            'precision_std': metrics_10_fold['precision'].std(),\n",
    "            'recall_mean': metrics_10_fold['recall'].mean(),\n",
    "            'recall_std': metrics_10_fold['recall'].std(),\n",
    "            'f1_mean': metrics_10_fold['f1'].mean(),\n",
    "            'f1_std': metrics_10_fold['f1'].std(),\n",
    "        })\n",
    "\n",
    "metrics_sub_df = pd.DataFrame(metrics_list)\n",
    "display(metrics_sub_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a2558",
   "metadata": {},
   "source": [
    "## no cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e71fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:01<00:00, 21263.68it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 21465.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.6972 | Precision: 0.6540 | Recall: 0.9328 | F1: 0.7689\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 138569.82it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 137783.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.6442 | Precision: 0.6150 | Recall: 0.9121 | F1: 0.7347\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 75092.37it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 73381.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.6656 | Precision: 0.6333 | Recall: 0.9046 | F1: 0.7450\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 118969.75it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 110159.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.6723 | Precision: 0.6389 | Recall: 0.9040 | F1: 0.7487\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 57141.27it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 84019.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.6624 | Precision: 0.6299 | Recall: 0.9084 | F1: 0.7439\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 43916.52it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 44519.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.6685 | Precision: 0.6364 | Recall: 0.9008 | F1: 0.7458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.697218</td>\n",
       "      <td>0.653992</td>\n",
       "      <td>0.932755</td>\n",
       "      <td>0.768887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.644217</td>\n",
       "      <td>0.614991</td>\n",
       "      <td>0.912148</td>\n",
       "      <td>0.734658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.665593</td>\n",
       "      <td>0.633257</td>\n",
       "      <td>0.904555</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.672328</td>\n",
       "      <td>0.638942</td>\n",
       "      <td>0.904013</td>\n",
       "      <td>0.748709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.662372</td>\n",
       "      <td>0.629936</td>\n",
       "      <td>0.908351</td>\n",
       "      <td>0.743948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.668521</td>\n",
       "      <td>0.636398</td>\n",
       "      <td>0.900759</td>\n",
       "      <td>0.745846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  accuracy  precision    recall        f1\n",
       "0     abstract  0.697218   0.653992  0.932755  0.768887\n",
       "1   annotation  0.644217   0.614991  0.912148  0.734658\n",
       "2  deepseek_v3  0.665593   0.633257  0.904555  0.744975\n",
       "3       gemma3  0.672328   0.638942  0.904013  0.748709\n",
       "4       llama4  0.662372   0.629936  0.908351  0.743948\n",
       "5          qwq  0.668521   0.636398  0.900759  0.745846"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "# 二分类标签：是否为17\n",
    "y = (df['p2v_label'] == 17).astype(int)  # 17为1，否则为0\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.1, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**18, stop_words='english', alternate_sign=False)\n",
    "    X_train_vec = vectorizer.transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['accuracy']:.4f} | \"\n",
    "        f\"Precision: {res['precision']:.4f} | \"\n",
    "        f\"Recall: {res['recall']:.4f} | \"\n",
    "        f\"F1: {res['f1']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762be464",
   "metadata": {},
   "source": [
    "# Predict year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40795c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    34146.000000\n",
       "mean      2006.680724\n",
       "std          9.105688\n",
       "min       1887.000000\n",
       "25%       2001.000000\n",
       "50%       2007.000000\n",
       "75%       2014.000000\n",
       "max       2022.000000\n",
       "Name: year, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fb2f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATMAAADZCAYAAABM8NcOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAI99JREFUeJzt3XtwU2XeB/BveklKLwm0hZbQlnITKZcWC2UqKlQjpQhYcPat7quEW73QIhLAoatQZXU66lLLulHGC62wOCK+iEixbik3hbLQ0qpFQMEqLPSaQtMLJG3yvH+wOSY0bZM0aZKT32cmM805T57zyzH8PM95nvM8AsYYAyGEuDkvZwdACCH2QMmMEMILlMwIIbxAyYwQwguUzAghvEDJjBDCC5TMCCG8QMmMEMILPs4OwNn0ej2uXbuGoKAgCAQCZ4dDCDHCGENLSwukUim8vHq+9vL4ZHbt2jVERkY6OwxCSA+uXLmCiIiIHst4fDILCgoCcPtkicViJ0dDCDGmVqsRGRnJ/TvticcmM6VSCaVSCZ1OBwAQi8WUzAhxUZbcAhJ4+oPmarUaEokEzc3NlMwIcTHW/Puk3kxCCC9QMiOE8ILH3jMjxFMxxqBSqRASEgIAUKlUMNxtCg0NddshSpTMCPEQhiSmUqmw4qMjeHfZTADA6l0V0Lap0dnZic+z/gchISFcsnOnxEbJjBAPoVKpsOjdg9C2qaHT6bBy52noNe3wCw6HEIBAq+2S7IKDg8EYg0AggEAgcOkE5/bJ7MaNG5DJZOjs7ERnZydWrVqF9PR0Z4dFiEsSBUoAAJ3NTRAGiKH3+SMFdNxs5RKccbK72XIDAaFS+Pj4YPsKGUJDQ83Wbdx8dUbCc/tkFhQUhGPHjsHf3x9tbW2YMGECFi5cyN0PIIT8kWh6Y0hwxsmus7MTwgAxfHx80NjYCOPRXAKBAMHBwWhqajK5ogsJCen3pOb2yczb2xv+/v4AAI1GA8YYPHzoHCFdqFQqpP+jEOKI0TbXoW1TY9nf9yEgVAq9ph1eIn/4+Pjg7bTJ3H03wxVdb1dxjuD0oRnHjh3DvHnzIJVKIRAIsHfv3i5llEoloqOj4efnh2nTpuHUqVMm+2/cuIHY2FhERERg3bp1/XoCCXEXQv+APtfhOyAQwgCxyev69esQBUogDLg9qFUYIOaas/3J6cmsra0NsbGxUCqVZvfv2rULCoUC2dnZOHPmDGJjY5GcnIz6+nquzMCBA/H999+juroan3zyCerq6vorfEI8mrZNjTXbj6Gjo8Nku6FZ25+tJKcns5SUFLz22mtYsGCB2f25ublIT0/HkiVLEBMTg61bt8Lf3x/btm3rUjYsLAyxsbH49ttvuz2eRqOBWq02eRFCbOc7ILDLNm2bGs+8X2LRfTp7cXoy64lWq0V5eTlkMhm3zcvLCzKZDKWlpQCAuro6tLS0AACam5tx7NgxjB07tts6c3JyIJFIuBdN/0OIY/gOCIRKpUJDQwMaGhocfpXm0h0AjY2N0Ol0CAsLM9keFhaG8+fPAwB+//13PP3009yN/5UrV2LixInd1pmVlQWFQsG9N0wxQgjfMMbQ2NgIAGhqaur34xsP9TAMyHXk/WyXTmaWSEhIQGVlpcXlRSIRRCJRlymACOEblUqFxzbtgN+gIf9NKP3/WzcM7/C6456aI7h0MzM0NBTe3t5dbujX1dUhPDy8T3VnZGTgp59+wunTp/tUDyGuTOgfwPU68p1LJzOhUIj4+HiUlJRw2/R6PUpKSpCYmOjEyAghrsbpzczW1lZcvHiRe19dXY3KykoEBwcjKioKCoUCcrkcU6ZMQUJCAvLy8tDW1oYlS5b06bjUzCSEX5yezMrKypCUlMS9N9ycl8vlKCgoQFpaGhoaGrBx40bU1tYiLi4ORUVFXToFrJWRkYGMjAxuJktCiHtzejKbOXNmr122mZmZyMzMtOtx6cqMEH5x6XtmjkQdAISPDMMxXO35ZMMTAY6MzWOTGSF8pFKpkPbm/+Hnn3/u19H3vTGMOVv07kGHxeX0ZqazUDOT8JVAAKPBqq7z+xYGiOHr6+uw+j32yoyamYTPPGVsmTGPTWaEEH7x2GSmVCoRExODqVOnOjsUQogdeGwyo2YmIfzisR0AhPCJ8TJynoqSGSE8YLyMnCv1YPYnj21mEsI3xvPweyKPTWbUAUD4wDDi35OblwYe28ykB80JHxg3L/2C+zbHn7vz2GRGiLsz3PR3xrJurshjm5mEuDvDwr53LvPmqSiZEeLG7LGwL194bDKjDgBC+MVjkxk9AUAIv3hsMiOE8AslM0IIL1AyI4TwAiUzQggv0KBZQtyAYYAsAAQHB6OpqYkeYboDJTNC3IDhsSUAeDttMlbvqvDoGTLM8dhmJo0zI+7GMCvG9evXPX6GDHM8NpnRODPijrRtaqzZfoweYTLDY5MZIe7Kd0Cgs0NwSZTMCCG8QMmMEBdn3JNJukfJjBAXR1P9WIaSGSFugKb66Z3bJ7MrV65g5syZiImJwaRJk7B7925nh0QIcQK3HzTr4+ODvLw8xMXFoba2FvHx8ZgzZw4CAuj/ZIR4ErdPZkOHDsXQoUMBAOHh4QgNDUVTUxMlM0I8jNObmceOHcO8efMglUohEAiwd+/eLmWUSiWio6Ph5+eHadOm4dSpU2brKi8vh06nQ2RkpIOjJsTxaBk56zg9mbW1tSE2NhZKpdLs/l27dkGhUCA7OxtnzpxBbGwskpOTUV9fb1KuqakJixYtwvvvv98fYRPicIbnMTO2HaVnMC3g9GZmSkoKUlJSut2fm5uL9PR0LFmyBACwdetWFBYWYtu2bVi/fj0AQKPRIDU1FevXr8e9997b4/E0Gg00Gg33Xq1W2+FbEGJfdy4j19nc5OSIXJ9NV2YjR440e+l748YNjBw5ss9BGWi1WpSXl0Mmk3HbvLy8IJPJUFpaCuD2f/TFixfjwQcfxFNPPdVrnTk5OZBIJNyLmqTEFdHYMuvZlMx+++036HRdL3s1Gg2uXr3a56AMGhsbodPpEBYWZrI9LCwMtbW1AIDjx49j165d2Lt3L+Li4hAXF4cff/yx2zqzsrLQ3NzMva5cuWK3eAmxJxpbZh2rmpn79u3j/v7mm28gkfyxkrJOp0NJSQmio6PtFpwl7rvvPuj1eovLi0QiiEQiKJVKKJVKs0mZEOJ+rEpmqampAACBQAC5XG6yz9fXF9HR0di8ebPdggsNDYW3tzfq6upMttfV1SE8PLxPdWdkZCAjIwNqtdokKRNC3JNVzUy9Xg+9Xo+oqCjU19dz7/V6PTQaDS5cuIC5c+faLTihUIj4+HiUlJSYxFBSUoLExMQ+1U2TMxLCLzb1ZlZXV9stgNbWVly8eNGk7srKSgQHByMqKgoKhQJyuRxTpkxBQkIC8vLy0NbWxvVu2oquzIgrMZ4ZIyQkxMnRuCebh2aUlJSgpKSEu0Iztm3bNovrKSsrQ1JSEvdeoVAAAORyOQoKCpCWloaGhgZs3LgRtbW1iIuLQ1FRUZdOAULciSF5hYSEQCAQcGPKGGPIe/weZ4fnlmxKZq+++io2bdqEKVOmYOjQoRAIBDYHMHPmTDDGeiyTmZmJzMxMm49hDnUAEGdSqVRIe/P/8O6ymQgJCQFjDKJACTStzVi58zT0mnYaKGslm5LZ1q1bUVBQYNG4LldFzUzibAIBsHLnafj4+ODttMncdmGAGHofHxooayWbkplWq+11pD0hpHfCADF8fHxw/fp1Z4fi9mwaNLt8+XJ88skn9o6lX1FvJnEVtOKSfdh0ZXbr1i28//77OHjwICZNmgRfX1+T/bm5uXYJzpGomUmcwXDj/87HAWnFpb6zKZn98MMPiIuLAwBUVVWZ7OtLZwAhfGfotaTVyO3PpmR2+PBhe8fR76g3kzgLzYThGE6fz8xZaEVzQvjFpiuzpKSkHpuThw4dsjkgQgixhU3JzHC/zKCjowOVlZWoqqrq8gA6IZ7EcIPfMBBcIBBwo/yJY9mUzN5++22z21955RW0trb2KSBC3BVjDD///DNW76qAtk0NL5E/fHx88PFzD3HJrLenXYjt7HrP7Mknn7TquUxnonFmxN4Ms8N6ifwhDBBDGCCGKFBye32Kdw/iKWUxLl265Owwecuuyay0tBR+fn72rNJhqAOAOMKds8MyxnD9+nWIAiUQCAQ0ONaBbGpmLly40OQ9Yww1NTUoKyvDhg0b7BIYIe7AePYLc26P7q/CoOF3A6DBsY5kUzK7c8S8l5cXxo4di02bNmHWrFl2CYwQd6BSqfD4W3vw6bqF3ZahBNY/bEpm+fn59o6DELclDAhydggEfVw3s7y8HOfOnQMAjB8/HpMnT+7lE66DngAghF9sSmb19fV4/PHHceTIEQwcOBDA7TUzk5KS8Omnn2Lw4MH2jNEh6EFzQvjFpt7MlStXoqWlBWfPnkVTUxOamppQVVUFtVqN559/3t4xEkJIr2y6MisqKsLBgwcxbtw4bltMTAyUSiV1ABCP0N1UPsR5bEpmer2+yxxmwO21M61ZkJcQd2U8lY+XcICzwyGwsZn54IMPYtWqVbh27Rq37erVq1i9ejUeeughuwVHiCsTBUogDBA7OwzyXzYls3/84x9Qq9WIjo7GqFGjMGrUKIwYMQJqtRrvvPOOvWMkhJBe2dTMjIyMxJkzZ3Dw4EGcP38eADBu3DjIZDK7BkcIIZay6srs0KFDiImJgVqthkAgwMMPP4yVK1di5cqVmDp1KsaPH49vv/3WUbHaFT1oTgi/WJXM8vLykJ6eDrG4630CiUSCZ555xi0WMwHoQXNC+MaqZPb9999j9uzZ3e6fNWsWysvL+xwUIa7MMCyDuBarklldXZ3ZIRkGPj4+aGho6HNQhLgyw7xlhql8aMyZa7CqA2DYsGGoqqrC6NGjze7/4YcfMHToULsERoirMU5axvOWddxsxcqdp6HXtNPycU5kVTKbM2cONmzYgNmzZ3eZhPHmzZvIzs7G3Llz7RogIa6ipzUvhQFi6H18aPk4J7Iqmb388svYs2cP7rrrLmRmZmLs2LEAgPPnz3MzULz00ksOCZQQRzO+F9bdIiS05qXrsiqZhYWF4cSJE3juueeQlZVlsgJNcnIylEolwsLCHBJoTxYsWIAjR47goYcewueff97vxyf8YLjyAoDtK2QIDQ11ckTEGlYPmh0+fDgOHDiA69ev4+LFi2CMYcyYMRg0aJAj4rPIqlWrsHTpUnz88cdOi4Hwg+HKi7gfmydnHDRokMsMOJ05cyaOHDni7DAIIU5k19WZbHHs2DHMmzcPUqkUAoEAe/fu7VJGqVQiOjoafn5+mDZtGk6dOtX/gRKPRmPLXJ/Tk1lbWxtiY2OhVCrN7t+1axcUCgWys7Nx5swZxMbGIjk5GfX19f0cKfFkd44tI66nT2sA2ENKSgpSUlK63Z+bm4v09HQsWbIEALB161YUFhZi27ZtWL9+vdXH02g00Gg03Hu1Wm190MRjdDe2jLgep1+Z9USr1aK8vNxkNg4vLy/IZDKUlpbaVGdOTg4kEgn3ioyMtFe4hIcMPZwZ247SgFgX59LJrLGxETqdrstwj7CwMNTW1nLvZTIZ/vSnP+HAgQOIiIjoMdFlZWWhubmZe125csVh8RP3YXxPjDGGxsZGNDQ0QKVS0SSMbsLpzUx7OHjwoMVlRSIRRCIRLTVHTBjuiYkjRkOvaceyv+9DQKgUek07/ILDnR0esYBLX5mFhobC29sbdXV1Jtvr6uoQHt63HxhNAUTuZHxPzHdAIIQBYroicyMuncyEQiHi4+NRUlLCbdPr9SgpKUFiYmKf6qbJGQnhF6c3M1tbW3Hx4kXufXV1NSorKxEcHIyoqCgoFArI5XJMmTIFCQkJyMvLQ1tbG9e7aStaBJgQfnF6MisrK0NSUhL3XqFQAADkcjkKCgqQlpaGhoYGbNy4EbW1tYiLi0NRUZFTngElhLgupyezmTNncg+sdyczMxOZmZl2PS51ABDCLy59z8yRqAOAEH7x2GRGCOEXj01m1JtJCL94bDKjZiYh/OL0DgBC7M2S6a/vLEvT+7g/j01m1JvJX9ZMf93TIiXEvVAzk5qZvCQKlFg8BTY9SM4PHpvMCCH8QsmMEMILHpvMaGgGIfziscmM7pkRwi8em8wIIfxCyYwQwguUzAghvOCxg2ZJ3xlGz/c2yt7Rxwf+GOlvyWK9hjK0sC+/eGwyoycA+k6lUuHxt/bg03ULexxl78jj3znS33hhEl9f3x4/p21T42bLDQwafnd/hk0cxGObmdSbaR/CgCCnHt/cSH9LFus1jPr3HRDoqNBIP/PYZEYI4RdKZoQQXqBkRgjhBUpmhBBeoGRGCOEFSmbEoRhjaGxs7HU5wd7KGvZZWpfxZxoaGqz6HHEcw9g+R/z38NhkRrNm9A/DWDRLBqf2VNYwNmzRuwctHuiqbVNj2d/34X/f+caqzxHH0bapsXLnaYf89/DYZEbjzPqPNWPReiprzeyxBr4DAiEMEFv9OeI4jvrv4bHJjBDCL5TMCCG8QMmMEMILlMwIIbxAyYwQwgu8SGb79+/H2LFjMWbMGHz44YfODocQ4gRuP59ZZ2cnFAoFDh8+DIlEgvj4eCxYsAAhISHODo0Q0o/c/srs1KlTGD9+PIYNG4bAwECkpKTgX//6l7PDIoT0M6cns2PHjmHevHmQSqUQCATYu3dvlzJKpRLR0dHw8/PDtGnTcOrUKW7ftWvXMGzYMO79sGHDcPXq1f4InRDiQpyezNra2hAbGwulUml2/65du6BQKJCdnY0zZ84gNjYWycnJqK+v7+dICSGuzOn3zFJSUpCSktLt/tzcXKSnp2PJkiUAgK1bt6KwsBDbtm3D+vXrIZVKTa7Erl69ioSEhG7r02g00Gg03Hu1Wm1RnOYWz3AV1sbW20IgxnUYbw8ODkZTUxNXxlydhu2NjY0AgKampl7jM+w3flbP8JC4gWGfucVIjB9QN8RnyXcn/OL0ZNYTrVaL8vJyZGVlcdu8vLwgk8lQWloKAEhISEBVVRWuXr0KiUSCr7/+Ghs2bOi2zpycHLz66qtWx2Ju8QxXYW1s3S0EYq4O4+1vp03G6l0VXJk76zQsbgIAj23aAb9BQ6DXtKOzsxMrd56Gj4+P2fiMFxjxEg7gthnXYVh4RK9px8qdp7tsW/b3fQgIlf73eN0vUmO84AnhF5dOZo2NjdDpdAgLCzPZHhYWhvPnzwMAfHx8sHnzZiQlJUGv1+PFF1/ssSczKysLCoWCe69WqxEZGWlRPK78sLK1sZkr310dxtt7Oo7xQ+JC/wAIA8TQ+/igs7np9uIh3ayWZFxvZ0eH+To6O42O03Wb4YFyw/F6YsmCJ8T9uHQys9T8+fMxf/58i8qKRCKIRCJaao4QnnF6B0BPQkND4e3tjbq6OpPtdXV1CA8P71PdNAUQIfzi0slMKBQiPj4eJSUl3Da9Xo+SkhIkJib2qW6anJEQfnF6M7O1tRUXL17k3ldXV6OyshLBwcGIioqCQqGAXC7HlClTkJCQgLy8PLS1tXG9m7bKyMhARkYG1Go1JBLXvRdGCLGM05NZWVkZkpKSuPeGm/NyuRwFBQVIS0tDQ0MDNm7ciNraWsTFxaGoqKhLp4CtDPOQ9zZEo6WlBR232rm/hUKhXY5vD9bGZq58d3UYb29tbTUpAwAdt9rN/t2puYmOW+23exf/+zd0vmbjMxyj41Y7dJ2dPdah17TDi6HLtt7+Nhy7p3rteTz6XM+f6+63cCfDv0tL1gsQMA9d5cHQAaDVanHp0iVnh0MI6cGVK1cQERHRYxmPTWYGer0e165dQ1BQUL8PhDUMC7ly5QrEYnG/Htud0XmzjTueN8YYWlpaIJVK4eXV8y1+pzcznc3Ly6vXjO9oYrHYbX5croTOm23c7bxZek/bpXszCSHEUpTMCCG8QMnMiUQiEbKzsyESiZwdiluh82Ybvp83j+8AIITwA12ZEUJ4gZIZIYQXKJkRQniBkhkhhBcomfVRbwuy1NXVYfHixZBKpfD398fs2bPxyy+/mJS5desWMjIyEBISgsDAQDz22GNdpj26fPkyHnnkEfj7+2PIkCFYt26dyeSE7sYe523mzJkQCAQmr2effdakDJ/OW05ODqZOnYqgoCAMGTIEqampuHDhgkkZe/2Wjhw5gnvuuQcikQijR49GQUGBo79en1Ey66OeFmRhjCE1NRW//vorvvzyS1RUVGD48OGQyWRoa2vjyq1evRpfffUVdu/ejaNHj+LatWtYuHAht1+n0+GRRx6BVqvFiRMn8PHHH6OgoAAbN27sl+/oCPY4bwCQnp6Ompoa7vXmm29y+/h23o4ePYqMjAycPHkSxcXF6OjowKxZs+z+W6qursYjjzyCpKQkVFZW4oUXXsDy5cvxzTff9Ov3tRojdgOAffHFF9z7CxcuMACsqqqK26bT6djgwYPZBx98wBhj7MaNG8zX15ft3r2bK3Pu3DkGgJWWljLGGDtw4ADz8vJitbW1XJn33nuPicViptFoHPytHM+W88YYYzNmzGCrVq3qtl6+n7f6+noGgB09epQxZr/f0osvvsjGjx9vcqy0tDSWnJzs6K/UJ3Rl5kCGVaD8/Py4bV5eXhCJRPjuu+8AAOXl5ejo6IBM9scCIXfffTeioqK4RVtKS0sxceJEk2mPkpOToVarcfbs2f74Kv3KkvNmsHPnToSGhmLChAnIyspCe3s7t4/v5625uRnA7VWzAPv9lkpLS03qMJQx1OGqKJk5kOGHlJWVhevXr0Or1eKNN97Af/7zH9TU1AAAamtrIRQKMXDgQJPPhoWFoba2litjblEXwz6+seS8AcCf//xn/POf/8Thw4eRlZWFHTt24Mknn+T28/m86fV6vPDCC5g+fTomTJgAwH6/pe7KqNVq3Lx50xFfxy48ftYMR/L19cWePXuwbNkyBAcHw9vbGzKZDCkpKRZNNuepLD1vTz/9NPf3xIkTMXToUDz00EO4dOkSRo0a5YzQ+01GRgaqqqq6XKl6Mroyc7D4+HhUVlbixo0bqKmpQVFREVQqFUaOHAkACA8Ph1arxY0bN0w+Z7xoS3h4uNlFXQz7+Ki382bOtGnTAICbhp2v5y0zMxP79+/H4cOHTaavstdvqbsyYrEYAwYMsPfXsRtKZv1EIpFg8ODB+OWXX1BWVoZHH30UwO1/tL6+viaLtly4cAGXL1/mFm1JTEzEjz/+iPr6eq5McXExxGIxYmJi+veL9LPuzps5lZWVAIChQ4cC4N95Y4whMzMTX3zxBQ4dOoQRI0aY7LfXbykxMdGkDkOZvi4i5HBO7oBwey0tLayiooJVVFQwACw3N5dVVFSw33//nTHG2GeffcYOHz7MLl26xPbu3cuGDx/OFi5caFLHs88+y6KiotihQ4dYWVkZS0xMZImJidz+zs5ONmHCBDZr1ixWWVnJioqK2ODBg1lWVla/fld76ut5u3jxItu0aRMrKytj1dXV7Msvv2QjR45kDzzwAFeGb+ftueeeYxKJhB05coTV1NRwr/b2dq6MPX5Lv/76K/P392fr1q1j586dY0qlknl7e7OioqJ+/b7WomTWR4cPH2YAurzkcjljjLEtW7awiIgI5uvry6KiotjLL7/cZVjAzZs32YoVK9igQYOYv78/W7BgAaupqTEp89tvv7GUlBQ2YMAAFhoaytasWcM6Ojr662vaXV/P2+XLl9kDDzzAgoODmUgkYqNHj2br1q1jzc3NJsfh03kzd74AsPz8fK6MvX5Lhw8fZnFxcUwoFLKRI0eaHMNV0RRAhBBeoHtmhBBeoGRGCOEFSmaEEF6gZEYI4QVKZoQQXqBkRgjhBUpmhBBeoGRGbBYdHY28vLweyxjPIvvbb79BIBBwjx05yiuvvIK4uDiHHoO4HkpmHmrx4sXcVNNCoRCjR4/Gpk2bHDqldGRkJGpqargpa+zB3JTba9eu7fJsIeE/mgLIg82ePRv5+fnQaDQ4cOAAMjIy4Ovri6ysLIccz9vbu19mqwgMDERgYKDDj+MMWq0WQqHQ2WG4JLoy82AikQjh4eEYPnw4nnvuOchkMuzbtw/A7cVCXnjhBZPyqampWLx4scm2lpYWPPHEEwgICMCwYcPMzulvYK6ZefbsWcydOxdisRhBQUG4//77cenSJQDA6dOn8fDDDyM0NBQSiQQzZszAmTNnuM9GR0cDABYsWACBQMC9v7OZqdfrsWnTJkREREAkEiEuLg5FRUVd4tqzZw+SkpLg7++P2NjYHmdWXbp0KebOnWuyraOjA0OGDMFHH33EHTcnJwcjRozAgAEDEBsbi88//5wrr9PpsGzZMm7/2LFjsWXLFpM6Fy9ejNTUVLz++uuQSqUYO3ZstzF5OkpmhDNgwABotVqrPvPWW28hNjYWFRUVWL9+PVatWoXi4mKLPnv16lU88MADEIlEOHToEMrLy7F06VKuqdvS0gK5XI7vvvsOJ0+exJgxYzBnzhy0tLQAuJ3sACA/Px81NTXc+ztt2bIFmzdvxt/+9jf88MMPSE5Oxvz587us9vTSSy9h7dq1qKysxF133YUnnnii22b38uXLUVRUZDLz7f79+9He3o60tDQAt1dT2r59O7Zu3YqzZ89i9erVePLJJ3H06FEAt5NdREQEdu/ejZ9++gkbN27EX/7yF3z22WcmxyopKcGFCxdQXFyM/fv3W3RuPZKzn3QnziGXy9mjjz7KGGNMr9ez4uJiJhKJ2Nq1axlj5hcLefTRR7lZLRhjbPjw4Wz27NkmZdLS0lhKSgr3HkaLlVRXVzMArKKigjHGWFZWFhsxYgTTarUWxazT6VhQUBD76quvzNZvkJ2dzWJjY7n3UqmUvf766yZlpk6dylasWGES14cffsjtP3v2LAPAzp071208MTEx7I033uDez5s3jy1evJgxxtitW7eYv78/O3HihMlnli1bxp544olu68zIyGCPPfYY914ul7OwsDBeLMDiaHRl5sH279+PwMBA+Pn5ISUlBWlpaXjllVesquPOCfsSExNx7tw5iz5bWVmJ+++/H76+vmb319XVIT09HWPGjIFEIoFYLEZraysuX75scXxqtRrXrl3D9OnTTbZPnz69S5yTJk3i/jZM8Gg8ieGdli9fjvz8fC7Wr7/+GkuXLgVwe7bb9vZ2PPzww9w9vMDAQGzfvp1rRgOAUqlEfHw8Bg8ejMDAQLz//vtdvt/EiRPpPpkFqAPAgyUlJeG9996DUCiEVCqFj88fPwcvL68u6xR0dHTY9fi9TcEsl8uhUqmwZcsWDB8+HCKRCImJiVY3hS1lnFQFAgGA203B7ixatAjr169HaWkpTpw4gREjRuD+++8HALS2tgIACgsLMWzYMJPPiUQiAMCnn36KtWvXYvPmzUhMTERQUBDeeust/Pvf/zYpHxAQ0Pcv5wEomXmwgIAAjB492uy+wYMHm9wP0ul0qKqqQlJSkkm5kydPdnk/btw4i44/adIkfPzxx+jo6DB7dXb8+HG8++67mDNnDgDgypUraGxsNCnj6+sLnU7X7THEYjGkUimOHz+OGTNmmNSdkJBgUZzdCQkJQWpqKvLz81FaWoolS5Zw+2JiYiASiXD58mWT4xo7fvw47r33XqxYsYLbZnzVRqxDyYyY9eCDD0KhUKCwsBCjRo1Cbm5ul4UygNv/IN98802kpqaiuLgYu3fvRmFhoUXHyMzMxDvvvIPHH38cWVlZkEgkOHnyJBISEjB27FiMGTMGO3bswJQpU6BWq7Fu3bouV3PR0dEoKSnB9OnTIRKJMGjQoC7HWbduHbKzszFq1CjExcUhPz8flZWV2Llzp03nxtjy5csxd+5c6HQ6yOVybntQUBDWrl2L1atXQ6/X47777kNzczOOHz8OsVgMuVyOMWPGYPv27fjmm28wYsQI7NixA6dPn+4ytz+xDN0zI2YtXboUcrkcixYtwowZMzBy5MguV2UAsGbNGpSVlWHy5Ml47bXXkJubi+TkZIuOERISgkOHDqG1tRUzZsxAfHw8PvjgA+4q7aOPPsL169dxzz334KmnnsLzzz+PIUOGmNSxefNmFBcXIzIyEpMnTzZ7nOeffx4KhQJr1qzBxIkTUVRUhH379mHMmDFWnpWuZDIZhg4diuTkZEilUpN9f/3rX7Fhwwbk5ORg3LhxmD17NgoLC7lk9cwzz2DhwoVIS0vDtGnToFKpTK7SiHVo2mxC+qC1tRXDhg1Dfn4+Fi5c6OxwPBo1MwmxgV6vR2NjIzZv3oyBAwdi/vz5zg7J41EyI8QGly9fxogRIxAREYGCggKTnmDiHNTMJITwAnUAEEJ4gZIZIYQXKJkRQniBkhkhhBcomRFCeIGSGSGEFyiZEUJ4gZIZIYQXKJkRQnjh/wGuwIkzI0mV+AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.histplot(df, x='year', stat='count', discrete=True)\n",
    "plt.xlabel('Publication year')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5fa53",
   "metadata": {},
   "source": [
    "## 10-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580439a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents:   0%|                                                                                                            | 0/34146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 89301.78it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "/home/zqlyu2/.local/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.0s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.7049±0.0074 | F1: 0.6446±0.0089\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 76306.55it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "/home/zqlyu2/.local/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    1.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.7020±0.0086 | F1: 0.6547±0.0101\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 111202.33it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.7161±0.0090 | F1: 0.6678±0.0120\n",
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:02<00:00, 16993.84it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.7542±0.0080 | F1: 0.7063±0.0094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.704856</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.553764</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.644592</td>\n",
       "      <td>0.008896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.701956</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.744273</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.584601</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.654728</td>\n",
       "      <td>0.010091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.716131</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.768938</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.590483</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.667834</td>\n",
       "      <td>0.011960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.754203</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.836492</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.611367</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.706276</td>\n",
       "      <td>0.009402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  \\\n",
       "0      gemma3       0.704856      0.007369        0.771654       0.011675   \n",
       "1      llama4       0.701956      0.008589        0.744273       0.012986   \n",
       "2  annotation       0.716131      0.009039        0.768938       0.013663   \n",
       "3    abstract       0.754203      0.008020        0.836492       0.011048   \n",
       "\n",
       "   Recall_mean  Recall_std   F1_mean    F1_std  \n",
       "0     0.553764    0.014894  0.644592  0.008896  \n",
       "1     0.584601    0.013100  0.654728  0.010091  \n",
       "2     0.590483    0.016425  0.667834  0.011960  \n",
       "3     0.611367    0.014414  0.706276  0.009402  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "# 指标: Accuracy, Precision, Recall, F1\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "text_features = models + ['annotation', 'abstract']\n",
    "y = (df['year'] >= 2008).astype(int)\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**20, stop_words='english', alternate_sign=False)\n",
    "    X = vectorizer.transform(X_text)\n",
    "    model = MultinomialNB()\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1, verbose=1, return_train_score=False)\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy_mean': scores['test_Accuracy'].mean(),\n",
    "        'Accuracy_std': scores['test_Accuracy'].std(),\n",
    "        'Precision_mean': scores['test_Precision'].mean(),\n",
    "        'Precision_std': scores['test_Precision'].std(),\n",
    "        'Recall_mean': scores['test_Recall'].mean(),\n",
    "        'Recall_std': scores['test_Recall'].std(),\n",
    "        'F1_mean': scores['test_F1'].mean(),\n",
    "        'F1_std': scores['test_F1'].std(),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy_mean']:.4f}±{res['Accuracy_std']:.4f} | \"\n",
    "        f\"F1: {res['F1_mean']:.4f}±{res['F1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f2c119",
   "metadata": {},
   "source": [
    "## no cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:01<00:00, 21330.43it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 22020.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | MAE: 4.2865 | R2: 0.5755\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 110815.97it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 130228.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | MAE: 5.5461 | R2: 0.3061\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 67192.84it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 77554.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | MAE: 5.0521 | R2: 0.4281\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 99404.52it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 120217.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | MAE: 5.5035 | R2: 0.3244\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 55302.63it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 54197.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | MAE: 5.5231 | R2: 0.3139\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 40333.08it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 44297.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | MAE: 5.0755 | R2: 0.4131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>4.286524</td>\n",
       "      <td>34.042876</td>\n",
       "      <td>0.575475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>5.546063</td>\n",
       "      <td>55.646234</td>\n",
       "      <td>0.306074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>5.052078</td>\n",
       "      <td>45.857851</td>\n",
       "      <td>0.428139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>5.503463</td>\n",
       "      <td>54.177417</td>\n",
       "      <td>0.324391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama4</td>\n",
       "      <td>5.523119</td>\n",
       "      <td>55.020432</td>\n",
       "      <td>0.313878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwq</td>\n",
       "      <td>5.075490</td>\n",
       "      <td>47.060866</td>\n",
       "      <td>0.413137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature       MAE        MSE        R2\n",
       "0     abstract  4.286524  34.042876  0.575475\n",
       "1   annotation  5.546063  55.646234  0.306074\n",
       "2  deepseek_v3  5.052078  45.857851  0.428139\n",
       "3       gemma3  5.503463  54.177417  0.324391\n",
       "4       llama4  5.523119  55.020432  0.313878\n",
       "5          qwq  5.075490  47.060866  0.413137"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "y = df['year'].astype(int)  # 年份作为连续变量回归\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**18, stop_words='english', alternate_sign=False)\n",
    "    X_train_vec = vectorizer.transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"MAE: {res['MAE']:.4f} | \"\n",
    "        f\"R2: {res['R2']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0799cb16",
   "metadata": {},
   "source": [
    "# Predict title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7f76a",
   "metadata": {},
   "source": [
    "## Fetch titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12388ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying titles: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:00<00:00, 160.05batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1353153</td>\n",
       "      <td>Efficient Generation of a Hepatitis B Virus Cy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1634910</td>\n",
       "      <td>Structure of Hjc, a Holliday junction resolvas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1655469</td>\n",
       "      <td>From Complete Genomes to Measures of Substitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1778349</td>\n",
       "      <td>Regulation of the Proinflammatory Effects of F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2550721</td>\n",
       "      <td>Differential requirement for p19ARF in the p53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28005</th>\n",
       "      <td>83433077</td>\n",
       "      <td>Revisiting IL-2: Biology and therapeutic prosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28006</th>\n",
       "      <td>104021261</td>\n",
       "      <td>Systems-level analysis of mechanisms regulatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28007</th>\n",
       "      <td>104393236</td>\n",
       "      <td>siRNA nanoparticles targeting CaMKIIγ in lesio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28008</th>\n",
       "      <td>123181209</td>\n",
       "      <td>Immunotherapy of autoimmune encephalomyelitis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28009</th>\n",
       "      <td>125333095</td>\n",
       "      <td>RNA components of the spliceosome regulate tis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper_id                                              title\n",
       "0        1353153  Efficient Generation of a Hepatitis B Virus Cy...\n",
       "1        1634910  Structure of Hjc, a Holliday junction resolvas...\n",
       "2        1655469  From Complete Genomes to Measures of Substitut...\n",
       "3        1778349  Regulation of the Proinflammatory Effects of F...\n",
       "4        2550721  Differential requirement for p19ARF in the p53...\n",
       "...          ...                                                ...\n",
       "28005   83433077  Revisiting IL-2: Biology and therapeutic prosp...\n",
       "28006  104021261  Systems-level analysis of mechanisms regulatin...\n",
       "28007  104393236  siRNA nanoparticles targeting CaMKIIγ in lesio...\n",
       "28008  123181209  Immunotherapy of autoimmune encephalomyelitis ...\n",
       "28009  125333095  RNA components of the spliceosome regulate tis...\n",
       "\n",
       "[28010 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "\n",
    "MYSQL_HOST = '144.214.39.113'\n",
    "MYSQL_USER = 'key'\n",
    "MYSQL_PASS = 'Keydge11'\n",
    "MYSQL_DB = 'keydge'\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASS}@{MYSQL_HOST}/{MYSQL_DB}?charset=utf8mb4')\n",
    "\n",
    "paper_ids = df['paper_id'].unique().tolist()\n",
    "BATCH_SIZE = 500  # 每批查多少条，可调大或调小\n",
    "\n",
    "results = []\n",
    "# 用tqdm显示批次进度和预计完成时间\n",
    "for i in tqdm(range(0, len(paper_ids), BATCH_SIZE), desc=\"Querying titles\", unit=\"batch\"):\n",
    "    batch = paper_ids[i:i+BATCH_SIZE]\n",
    "    id_str = ','.join(str(int(pid)) for pid in batch)\n",
    "    sql = f\"SELECT paper_id, title FROM paper_bib WHERE paper_id IN ({id_str})\"\n",
    "    batch_df = pd.read_sql(sql, engine)\n",
    "    results.append(batch_df)\n",
    "\n",
    "# 合并所有批次的查询结果\n",
    "paper_title_df = pd.concat(results, ignore_index=True)\n",
    "display(paper_title_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_title_df.to_parquet(home / 'projects/TLDR/data/paper_title.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402df34b",
   "metadata": {},
   "source": [
    "## Load titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a09c2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Evidence for two independent domestications of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>The Origin of the Domestic Pig: Independent Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Fine-mapping of quantitative trait loci by ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>Extensive Genome-wide Linkage Disequilibrium i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Genetic mapping of quantitative trait loci for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34141</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Expansion of Human Regulatory T-Cells From Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34142</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Selective targeting of engineered T cells usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34143</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Pathogenic CD4 T cells in type 1 diabetes reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34144</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Generation of hypoimmunogenic human pluripoten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34145</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "      <td>CD4+CD25high Regulatory Cells in Human Periphe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34146 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "34141            10.2337/db08-1168    4860455   \n",
       "34142      10.1126/science.aar3246    4860145   \n",
       "34143      10.1126/science.aad2791   62290395   \n",
       "34144      10.1073/pnas.1902566116   82979762   \n",
       "34145  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "34141  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "34142  Engineering cytokine-receptor pairs Interleuki...   \n",
       "34143  T cells target peptide combos One of the endur...   \n",
       "34144  Polymorphic HLAs form the primary immune barri...   \n",
       "34145  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "34141  This article describes the good manufacturing ...   \n",
       "34142  This study reports the generation of an orthog...   \n",
       "34143  This article shows that some diabetogenic T ce...   \n",
       "34144  This article describes the development of gene...   \n",
       "34145  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "34141  This work shows that Tregs from type 1 diabeti...   \n",
       "34142  This study demonstrates that engineered IL-2 r...   \n",
       "34143  This study identified that autoreactive T cell...   \n",
       "34144  This report describes a novel genome editing a...   \n",
       "34145  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \\\n",
       "0      These results provide evidence that modern cat...  2005395185   \n",
       "1      These findings provide evidence for independen...  2110049233   \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742   \n",
       "3      This study is among the first to examine the e...  2103106090   \n",
       "4      This study mapped genetic loci associated with...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "34141  This study highlights the challenges of transl...  2137227986   \n",
       "34142  These findings suggest that engineering cytoki...  2789780246   \n",
       "34143  T cells recognize a unique type of antigen tha...  2266478788   \n",
       "34144  This study demonstrated that human ESCs and iP...  2943378944   \n",
       "34145  These studies identify a population of human C...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "34141  129060628  2009         17   \n",
       "34142    3880285  2018          8   \n",
       "34143    3880285  2016          8   \n",
       "34144  125754415  2019         17   \n",
       "34145   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \\\n",
       "0                                 Multidisciplinary   \n",
       "1      Biochemistry, Genetics and Molecular Biology   \n",
       "2                                 Multidisciplinary   \n",
       "3      Biochemistry, Genetics and Molecular Biology   \n",
       "4                                 Multidisciplinary   \n",
       "...                                             ...   \n",
       "34141                                      Medicine   \n",
       "34142                             Multidisciplinary   \n",
       "34143                             Multidisciplinary   \n",
       "34144                             Multidisciplinary   \n",
       "34145                   Immunology and Microbiology   \n",
       "\n",
       "                                                   title  \n",
       "0      Evidence for two independent domestications of...  \n",
       "1      The Origin of the Domestic Pig: Independent Do...  \n",
       "2      Fine-mapping of quantitative trait loci by ide...  \n",
       "3      Extensive Genome-wide Linkage Disequilibrium i...  \n",
       "4      Genetic mapping of quantitative trait loci for...  \n",
       "...                                                  ...  \n",
       "34141  Expansion of Human Regulatory T-Cells From Pat...  \n",
       "34142  Selective targeting of engineered T cells usin...  \n",
       "34143  Pathogenic CD4 T cells in type 1 diabetes reco...  \n",
       "34144  Generation of hypoimmunogenic human pluripoten...  \n",
       "34145  CD4+CD25high Regulatory Cells in Human Periphe...  \n",
       "\n",
       "[34146 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper_title_df = pd.read_parquet(home / 'projects/TLDR/data/paper_title.parquet')\n",
    "df = df.merge(paper_title_df, on='paper_id', how='left')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e52db",
   "metadata": {},
   "source": [
    "## Generate negative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ac1d8",
   "metadata": {},
   "source": [
    "### Use random title of other papers in same subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9129e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:   0%|                                                                       | 0/34146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本: 100%|██████████████████████████████████████████████████████████| 34146/34146 [00:58<00:00, 581.66it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "pos_df = df.copy()\n",
    "\n",
    "# 标记正样本\n",
    "pos_df['title_paired'] = True\n",
    "\n",
    "# 收集负样本\n",
    "neg_samples = []\n",
    "rng = np.random.default_rng(42)  # 固定随机种子便于复现\n",
    "\n",
    "for idx, row in tqdm(pos_df.iterrows(), total=len(pos_df), desc=\"生成负样本\"):\n",
    "    # 查找同学科标签但不同paper_id的候选title\n",
    "    candidates = pos_df[(pos_df['p2v_label'] == row['p2v_label']) & (pos_df['paper_id'] != row['paper_id'])]\n",
    "    if not candidates.empty:\n",
    "        neg_title = rng.choice(candidates['title'].values)\n",
    "        neg_row = row.copy()\n",
    "        neg_row['title'] = neg_title\n",
    "        neg_row['title_paired'] = False\n",
    "        neg_samples.append(neg_row)\n",
    "    else:\n",
    "        raise ValueError(f\"没有找到与行 {idx} 同学科但不同paper_id的候选title。\")\n",
    "\n",
    "neg_df = pd.DataFrame(neg_samples)\n",
    "\n",
    "# 合并正负样本\n",
    "title_match_df = pd.concat([pos_df, neg_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "056e5c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global Transposon Mutagenesis and a Minimal Mycoplasma Genome',\n",
       " 'Centuries of intense surface melt on Larsen C Ice Shelf',\n",
       " 'Restoration of visual function by transplantation of optogenetically engineered photoreceptors',\n",
       " 'Plasmodium falciparum transmission stages accumulate in the human bone marrow',\n",
       " 'Coordination of Three Signaling Enzymes by AKAP79, a Mammalian Scaffold Protein']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match_df[title_match_df['title_paired'] == False]['title'].sample(5).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5dea7c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23bca6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "      <th>title</th>\n",
       "      <th>title_paired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Evidence for two independent domestications of...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>The Origin of the Domestic Pig: Independent Do...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Fine-mapping of quantitative trait loci by ide...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>Extensive Genome-wide Linkage Disequilibrium i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Genetic mapping of quantitative trait loci for...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68287</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Experience and Activity-Dependent Maturation o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68288</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>A Clonogenic Bone Marrow Progenitor Specific f...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68289</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Single-cell RNA-seq highlights intratumoral he...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68290</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Iterative fractionation of recycling receptors...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68291</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "      <td>Novel Analytic Criteria and Effective Plate De...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68292 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "68287            10.2337/db08-1168    4860455   \n",
       "68288      10.1126/science.aar3246    4860145   \n",
       "68289      10.1126/science.aad2791   62290395   \n",
       "68290      10.1073/pnas.1902566116   82979762   \n",
       "68291  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "68287  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "68288  Engineering cytokine-receptor pairs Interleuki...   \n",
       "68289  T cells target peptide combos One of the endur...   \n",
       "68290  Polymorphic HLAs form the primary immune barri...   \n",
       "68291  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "68287  This article describes the good manufacturing ...   \n",
       "68288  This study reports the generation of an orthog...   \n",
       "68289  This article shows that some diabetogenic T ce...   \n",
       "68290  This article describes the development of gene...   \n",
       "68291  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "68287  This work shows that Tregs from type 1 diabeti...   \n",
       "68288  This study demonstrates that engineered IL-2 r...   \n",
       "68289  This study identified that autoreactive T cell...   \n",
       "68290  This report describes a novel genome editing a...   \n",
       "68291  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \\\n",
       "0      These results provide evidence that modern cat...  2005395185   \n",
       "1      These findings provide evidence for independen...  2110049233   \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742   \n",
       "3      This study is among the first to examine the e...  2103106090   \n",
       "4      This study mapped genetic loci associated with...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "68287  This study highlights the challenges of transl...  2137227986   \n",
       "68288  These findings suggest that engineering cytoki...  2789780246   \n",
       "68289  T cells recognize a unique type of antigen tha...  2266478788   \n",
       "68290  This study demonstrated that human ESCs and iP...  2943378944   \n",
       "68291  These studies identify a population of human C...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "68287  129060628  2009         17   \n",
       "68288    3880285  2018          8   \n",
       "68289    3880285  2016          8   \n",
       "68290  125754415  2019         17   \n",
       "68291   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \\\n",
       "0                                 Multidisciplinary   \n",
       "1      Biochemistry, Genetics and Molecular Biology   \n",
       "2                                 Multidisciplinary   \n",
       "3      Biochemistry, Genetics and Molecular Biology   \n",
       "4                                 Multidisciplinary   \n",
       "...                                             ...   \n",
       "68287                                      Medicine   \n",
       "68288                             Multidisciplinary   \n",
       "68289                             Multidisciplinary   \n",
       "68290                             Multidisciplinary   \n",
       "68291                   Immunology and Microbiology   \n",
       "\n",
       "                                                   title  title_paired  \n",
       "0      Evidence for two independent domestications of...          True  \n",
       "1      The Origin of the Domestic Pig: Independent Do...          True  \n",
       "2      Fine-mapping of quantitative trait loci by ide...          True  \n",
       "3      Extensive Genome-wide Linkage Disequilibrium i...          True  \n",
       "4      Genetic mapping of quantitative trait loci for...          True  \n",
       "...                                                  ...           ...  \n",
       "68287  Experience and Activity-Dependent Maturation o...         False  \n",
       "68288  A Clonogenic Bone Marrow Progenitor Specific f...         False  \n",
       "68289  Single-cell RNA-seq highlights intratumoral he...         False  \n",
       "68290  Iterative fractionation of recycling receptors...         False  \n",
       "68291  Novel Analytic Criteria and Effective Plate De...         False  \n",
       "\n",
       "[68292 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe462cf6",
   "metadata": {},
   "source": [
    "### 10-CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4e904",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3833dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents:   0%|                                                                                                            | 0/68292 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:04<00:00, 15976.39it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.3s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.5499±0.0056 | F1: 0.5498±0.0070\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:00<00:00, 72535.34it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.2s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.6618±0.0051 | F1: 0.6569±0.0062\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 46628.61it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.7557±0.0062 | F1: 0.7537±0.0069\n",
      "Processing feature: qwen3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:02<00:00, 32650.61it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwen3 | Accuracy: 0.7139±0.0055 | F1: 0.7124±0.0040\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 64844.09it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.3s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.7577±0.0038 | F1: 0.7544±0.0045\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 38042.45it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.6843±0.0058 | F1: 0.6779±0.0066\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:02<00:00, 30616.49it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.4s remaining:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.6742±0.0061 | F1: 0.6738±0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.549933</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.549973</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.549904</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.549849</td>\n",
       "      <td>0.006991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.661805</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.666455</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.647740</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.006182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.759852</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.747601</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.753659</td>\n",
       "      <td>0.006902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen3</td>\n",
       "      <td>0.713920</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.716325</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.712379</td>\n",
       "      <td>0.004045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.757658</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.764547</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.744599</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.754423</td>\n",
       "      <td>0.004546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.684282</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.691811</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.664674</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.677939</td>\n",
       "      <td>0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.674222</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.673095</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>0.673829</td>\n",
       "      <td>0.005692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  \\\n",
       "0     abstract       0.549933      0.005592        0.549973       0.007610   \n",
       "1   annotation       0.661805      0.005107        0.666455       0.007536   \n",
       "2  deepseek_v3       0.755682      0.006233        0.759852       0.007990   \n",
       "3        qwen3       0.713920      0.005532        0.716325       0.007133   \n",
       "4       gemma3       0.757658      0.003785        0.764547       0.006018   \n",
       "5       llama4       0.684282      0.005826        0.691811       0.009807   \n",
       "6          qwq       0.674222      0.006091        0.674641       0.006608   \n",
       "\n",
       "   Recall_mean  Recall_std   F1_mean    F1_std  \n",
       "0     0.549904    0.011833  0.549849  0.006991  \n",
       "1     0.647740    0.006525  0.656947  0.006182  \n",
       "2     0.747601    0.007543  0.753659  0.006902  \n",
       "3     0.708609    0.008824  0.712379  0.004045  \n",
       "4     0.744599    0.005684  0.754423  0.004546  \n",
       "5     0.664674    0.006120  0.677939  0.006620  \n",
       "6     0.673095    0.008468  0.673829  0.005692  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "# 评价指标\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'qwen3','gemma3', 'llama4', 'qwq']\n",
    "y = title_match_df['title_paired'].astype(int)  # 1: 匹配，0: 不匹配\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    # 拼接title和对应的feature\n",
    "    X_text = (title_match_df['title'].astype(str).fillna('') + ' [SEP] ' + title_match_df[feat].astype(str).fillna(''))\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**20, stop_words='english', alternate_sign=False)\n",
    "    X = vectorizer.transform(X_text)\n",
    "    model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1, verbose=1, return_train_score=False)\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy_mean': scores['test_Accuracy'].mean(),\n",
    "        'Accuracy_std': scores['test_Accuracy'].std(),\n",
    "        'Precision_mean': scores['test_Precision'].mean(),\n",
    "        'Precision_std': scores['test_Precision'].std(),\n",
    "        'Recall_mean': scores['test_Recall'].mean(),\n",
    "        'Recall_std': scores['test_Recall'].std(),\n",
    "        'F1_mean': scores['test_F1'].mean(),\n",
    "        'F1_std': scores['test_F1'].std(),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy_mean']:.4f}±{res['Accuracy_std']:.4f} | \"\n",
    "        f\"F1: {res['F1_mean']:.4f}±{res['F1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e046c",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a441afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing feature: annotation\n",
      "  annotation k-folds running serially...\n",
      "Feature: annotation | Acc: 0.7614±0.0046 | Precision: 0.7598±0.0052 | Recall: 0.7646±0.0103 | F1: 0.7621±0.0055\n",
      "\n",
      "Processing feature: abstract\n",
      "  abstract k-folds running serially...\n",
      "Feature: abstract | Acc: 0.8844±0.0042 | Precision: 0.8716±0.0082 | Recall: 0.9017±0.0059 | F1: 0.8863±0.0038\n",
      "\n",
      "Processing feature: gemma3\n",
      "  gemma3 k-folds running serially...\n",
      "Feature: gemma3 | Acc: 0.8351±0.0035 | Precision: 0.8301±0.0053 | Recall: 0.8427±0.0085 | F1: 0.8363±0.0038\n",
      "\n",
      "Processing feature: llama4\n",
      "  llama4 k-folds running serially...\n",
      "Feature: llama4 | Acc: 0.8126±0.0027 | Precision: 0.8072±0.0061 | Recall: 0.8215±0.0084 | F1: 0.8142±0.0029\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.761407</td>\n",
       "      <td>0.004650</td>\n",
       "      <td>0.759809</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.764570</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>0.762133</td>\n",
       "      <td>0.005513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.884364</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.871597</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.901687</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>0.886344</td>\n",
       "      <td>0.003760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.835105</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.830125</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.842734</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>0.836341</td>\n",
       "      <td>0.003825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.812584</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.807215</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.821473</td>\n",
       "      <td>0.008438</td>\n",
       "      <td>0.814226</td>\n",
       "      <td>0.002914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "0  annotation       0.761407      0.004650        0.759809       0.005225   \n",
       "1    abstract       0.884364      0.004227        0.871597       0.008236   \n",
       "2      gemma3       0.835105      0.003455        0.830125       0.005263   \n",
       "3      llama4       0.812584      0.002738        0.807215       0.006118   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "0     0.764570    0.010342  0.762133  0.005513  \n",
       "1     0.901687    0.005883  0.886344  0.003760  \n",
       "2     0.842734    0.008486  0.836341  0.003825  \n",
       "3     0.821473    0.008438  0.814226  0.002914  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn \n",
    "patch_sklearn()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def create_tfidf_features(X_title_train, X_content_train, X_title_test, X_content_test, max_features=1000):\n",
    "    tfidf_title = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "    tfidf_content = TfidfVectorizer(max_features=max_features, stop_words='english')\n",
    "    # fit only on the training set\n",
    "    X_title_train_vec = tfidf_title.fit_transform(X_title_train).toarray()\n",
    "    X_content_train_vec = tfidf_content.fit_transform(X_content_train).toarray()\n",
    "    X_title_test_vec = tfidf_title.transform(X_title_test).toarray()\n",
    "    X_content_test_vec = tfidf_content.transform(X_content_test).toarray()\n",
    "    # Fit and transform title and content separately, adding the diff\n",
    "    X_train_feat = np.concatenate([X_title_train_vec, X_content_train_vec, X_title_train_vec - X_content_train_vec], axis=1)\n",
    "    X_test_feat = np.concatenate([X_title_test_vec, X_content_test_vec, X_title_test_vec - X_content_test_vec], axis=1)\n",
    "    return X_train_feat, X_test_feat\n",
    "\n",
    "class TorchMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "def train_torch_mlp(X_train, y_train, X_val, y_val, hidden_dim=128, lr=1e-3, num_epochs=10, batch_size=128):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TorchMLP(X_train.shape[1], hidden_dim=hidden_dim).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        permutation = torch.randperm(X_train_tensor.size(0))\n",
    "        for i in range(0, X_train_tensor.size(0), batch_size):\n",
    "            idx = permutation[i:i+batch_size]\n",
    "            batch_x, batch_y = X_train_tensor[idx], y_train_tensor[idx]\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_x)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "def eval_torch_mlp(model, X, y):\n",
    "    device = next(model.parameters()).device\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_tensor)\n",
    "        preds = (torch.sigmoid(logits) > 0.5).cpu().numpy()\n",
    "    return {\n",
    "        'f1': f1_score(y, preds, zero_division=0),\n",
    "        'accuracy': accuracy_score(y, preds),\n",
    "        'precision': precision_score(y, preds, zero_division=0),\n",
    "        'recall': recall_score(y, preds, zero_division=0)\n",
    "    }\n",
    "\n",
    "def run_one_fold(X_title, X_content, y, train_idx, test_idx, max_features=1000):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    \n",
    "    X_title_train, X_title_test = X_title[train_idx].tolist(), X_title[test_idx].tolist()\n",
    "    X_content_train, X_content_test = X_content[train_idx].tolist(), X_content[test_idx].tolist()\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    X_train_feat, X_test_feat = create_tfidf_features(X_title_train, X_content_train, X_title_test, X_content_test, max_features=max_features)\n",
    "    model = train_torch_mlp(X_train_feat, y_train, X_test_feat, y_test, num_epochs=10)\n",
    "    metrics = eval_torch_mlp(model, X_test_feat, y_test)\n",
    "    return {\n",
    "        'accuracy': metrics['accuracy'],\n",
    "        'precision': metrics['precision'],\n",
    "        'recall': metrics['recall'],\n",
    "        'f1': metrics['f1']\n",
    "    }\n",
    "\n",
    "y = title_match_df['title_paired'].astype(int).values\n",
    "X_title = title_match_df['title'].astype(str).fillna('').values\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "folds = list(cv.split(X_title, y))\n",
    "\n",
    "results = []\n",
    "text_features = ['annotation', 'abstract'] + models\n",
    "for feat in text_features:\n",
    "    print(f\"\\nProcessing feature: {feat}\")\n",
    "    X_content = title_match_df[feat].astype(str).fillna('').values\n",
    "    print(f\"  {feat} k-folds running serially...\")\n",
    "    metrics_list = []\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(folds):\n",
    "        metrics = run_one_fold(X_title, X_content, y, train_idx, test_idx)\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'accuracy_mean': np.mean([m['accuracy'] for m in metrics_list]),\n",
    "        'accuracy_std': np.std([m['accuracy'] for m in metrics_list]),\n",
    "        'precision_mean': np.mean([m['precision'] for m in metrics_list]),\n",
    "        'precision_std': np.std([m['precision'] for m in metrics_list]),\n",
    "        'recall_mean': np.mean([m['recall'] for m in metrics_list]),\n",
    "        'recall_std': np.std([m['recall'] for m in metrics_list]),\n",
    "        'f1_mean': np.mean([m['f1'] for m in metrics_list]),\n",
    "        'f1_std': np.std([m['f1'] for m in metrics_list]),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Acc: {res['accuracy_mean']:.4f}±{res['accuracy_std']:.4f} | \"\n",
    "        f\"Precision: {res['precision_mean']:.4f}±{res['precision_std']:.4f} | \"\n",
    "        f\"Recall: {res['recall_mean']:.4f}±{res['recall_std']:.4f} | \"\n",
    "        f\"F1: {res['f1_mean']:.4f}±{res['f1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53552de0",
   "metadata": {},
   "source": [
    "### No CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fbaef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 01:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.098041</td>\n",
       "      <td>0.967274</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.955191</td>\n",
       "      <td>0.966872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.080129</td>\n",
       "      <td>0.975108</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>0.968809</td>\n",
       "      <td>0.974948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.076666</td>\n",
       "      <td>0.974596</td>\n",
       "      <td>0.973415</td>\n",
       "      <td>0.975838</td>\n",
       "      <td>0.974625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.070916</td>\n",
       "      <td>0.976645</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.976611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.9763 | F1: 0.9762\n",
      "\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 01:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.166034</td>\n",
       "      <td>0.940040</td>\n",
       "      <td>0.955717</td>\n",
       "      <td>0.922829</td>\n",
       "      <td>0.938985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.149244</td>\n",
       "      <td>0.947580</td>\n",
       "      <td>0.941499</td>\n",
       "      <td>0.954459</td>\n",
       "      <td>0.947935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.129424</td>\n",
       "      <td>0.954975</td>\n",
       "      <td>0.954107</td>\n",
       "      <td>0.955923</td>\n",
       "      <td>0.955014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.120594</td>\n",
       "      <td>0.958196</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.951970</td>\n",
       "      <td>0.957931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.9581 | F1: 0.9576\n",
      "\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 01:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.217543</td>\n",
       "      <td>0.918222</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.899692</td>\n",
       "      <td>0.916673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.190222</td>\n",
       "      <td>0.928545</td>\n",
       "      <td>0.935686</td>\n",
       "      <td>0.920340</td>\n",
       "      <td>0.927949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.176155</td>\n",
       "      <td>0.935134</td>\n",
       "      <td>0.966410</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.932879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.168881</td>\n",
       "      <td>0.938429</td>\n",
       "      <td>0.953774</td>\n",
       "      <td>0.921511</td>\n",
       "      <td>0.937365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.9393 | F1: 0.9383\n",
      "\n",
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 01:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.963248</td>\n",
       "      <td>0.959611</td>\n",
       "      <td>0.967199</td>\n",
       "      <td>0.963390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.082622</td>\n",
       "      <td>0.974742</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.972910</td>\n",
       "      <td>0.974694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.068250</td>\n",
       "      <td>0.980233</td>\n",
       "      <td>0.984918</td>\n",
       "      <td>0.975399</td>\n",
       "      <td>0.980135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.069009</td>\n",
       "      <td>0.979647</td>\n",
       "      <td>0.972451</td>\n",
       "      <td>0.987260</td>\n",
       "      <td>0.979799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.9813 | F1: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.976279</td>\n",
       "      <td>0.978238</td>\n",
       "      <td>0.974228</td>\n",
       "      <td>0.976229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.958123</td>\n",
       "      <td>0.969815</td>\n",
       "      <td>0.945673</td>\n",
       "      <td>0.957592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.939307</td>\n",
       "      <td>0.954133</td>\n",
       "      <td>0.922976</td>\n",
       "      <td>0.938295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.981331</td>\n",
       "      <td>0.978179</td>\n",
       "      <td>0.984624</td>\n",
       "      <td>0.981391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  Accuracy  Precision    Recall        F1\n",
       "0      gemma3  0.976279   0.978238  0.974228  0.976229\n",
       "1      llama4  0.958123   0.969815  0.945673  0.957592\n",
       "2  annotation  0.939307   0.954133  0.922976  0.938295\n",
       "3    abstract  0.981331   0.978179  0.984624  0.981391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设定设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 评价指标\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds),\n",
    "        'recall': recall_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "class TitlePairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, titles, contents, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(\n",
    "            titles, contents,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "text_features = models + ['annotation', 'abstract']\n",
    "y = title_match_df['title_paired'].astype(int).values\n",
    "results = []\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "for feat in text_features:\n",
    "    print(f\"\\nProcessing feature: {feat}\")\n",
    "    output_dir = home / f'projects/TLDR/evaluation/predict_task/cached_title_distilbert_{feat}' / 'no_cv'\n",
    "    output_dir_str = str(output_dir)\n",
    "    X_title = title_match_df['title'].astype(str).fillna('').tolist()\n",
    "    X_content = title_match_df[feat].astype(str).fillna('').tolist()\n",
    "    labels = y\n",
    "\n",
    "    # dataset split\n",
    "    train_titles, test_titles, train_contents, test_contents, train_labels, test_labels = train_test_split(\n",
    "        X_title, X_content, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    # construct datasets\n",
    "    train_dataset = TitlePairDataset(train_titles, train_contents, train_labels, tokenizer)\n",
    "    test_dataset = TitlePairDataset(test_titles, test_contents, test_labels, tokenizer)\n",
    "\n",
    "    # 新建模型\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir_str,\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        eval_strategy='steps',\n",
    "        eval_steps=200,\n",
    "        save_strategy='no',\n",
    "        learning_rate=2e-5,\n",
    "        logging_steps=50,\n",
    "        report_to=[],\n",
    "        load_best_model_at_end=False,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "\n",
    "    # 汇总\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy': eval_result['eval_accuracy'],\n",
    "        'Precision': eval_result['eval_precision'],\n",
    "        'Recall': eval_result['eval_recall'],\n",
    "        'F1': eval_result['eval_f1'],\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy']:.4f} | \"\n",
    "        f\"F1: {res['F1']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
