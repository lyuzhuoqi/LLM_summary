{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1ac11c",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a395ee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35621 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "35631  This work shows that Tregs from type 1 diabeti...   \n",
       "35632  This study demonstrates that engineered IL-2 r...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This report describes a novel genome editing a...   \n",
       "35635  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4  \n",
       "0      These results provide evidence that modern cat...  \n",
       "1      These findings provide evidence for independen...  \n",
       "2      The authors fine-map a QTL for milk fat percen...  \n",
       "3      This study is among the first to examine the e...  \n",
       "4      This study mapped genetic loci associated with...  \n",
       "...                                                  ...  \n",
       "35631  This study highlights the challenges of transl...  \n",
       "35632  These findings suggest that engineering cytoki...  \n",
       "35633  T cells recognize a unique type of antigen tha...  \n",
       "35634  This study demonstrated that human ESCs and iP...  \n",
       "35635  These studies identify a population of human C...  \n",
       "\n",
       "[35621 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "\n",
    "# models = ['gemma3', 'llama4', 'qwen3']\n",
    "models = ['gemma3', 'llama4']\n",
    "\n",
    "# suffixes = None\n",
    "suffixes = '_sent_shuffle'\n",
    "# suffixes = '_tail'\n",
    "if suffixes is not None:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}{suffixes}.txt' for model in models]\n",
    "else:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}.txt' for model in models]\n",
    "\n",
    "df = pd.read_csv(home / 'projects/TLDR/data/paper_html_10.1038/abs_annotation/test.tsv', sep='\\t')\n",
    "for model, csv_file in zip(models, csv_files):\n",
    "    single_df = pd.read_csv(csv_file, sep='\\t', header=None, names=[model])\n",
    "    df = df.join(single_df)\n",
    "\n",
    "for index in pd.read_csv(home / \"projects/TLDR/description/invalid_entry_in_test.txt\", sep='\\t', header=None).values.flatten().tolist():\n",
    "    df = df.drop(index-2)  # Adjusting for zero-based index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c7b3f",
   "metadata": {},
   "source": [
    "# Load publication venue and year from MAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1b38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading doi_mag_pid_dict...\n",
      "doi_mag_pid_dict loaded.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34775 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "35631  This work shows that Tregs from type 1 diabeti...   \n",
       "35632  This study demonstrates that engineered IL-2 r...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This report describes a novel genome editing a...   \n",
       "35635  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \n",
       "0      These results provide evidence that modern cat...  2005395185  \n",
       "1      These findings provide evidence for independen...  2110049233  \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742  \n",
       "3      This study is among the first to examine the e...  2103106090  \n",
       "4      This study mapped genetic loci associated with...  2045457895  \n",
       "...                                                  ...         ...  \n",
       "35631  This study highlights the challenges of transl...  2137227986  \n",
       "35632  These findings suggest that engineering cytoki...  2789780246  \n",
       "35633  T cells recognize a unique type of antigen tha...  2266478788  \n",
       "35634  This study demonstrated that human ESCs and iP...  2943378944  \n",
       "35635  These studies identify a population of human C...  1560277370  \n",
       "\n",
       "[34775 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "print(\"Loading doi_mag_pid_dict...\")\n",
    "with open(home / \"projects/TLDR/data/doi_mag_pid_dict.pkl\", \"rb\") as f:\n",
    "    doi_mag_pid_dict = pickle.load(f)\n",
    "    print(\"doi_mag_pid_dict loaded.\")\n",
    "\n",
    "df['mag_pid'] = df['doi'].map(doi_mag_pid_dict)\n",
    "df = df.dropna(subset=['mag_pid'])\n",
    "df.loc[:, 'mag_pid'] = df['mag_pid'].apply(lambda x: x.split(';')[0] if isinstance(x, str) else x)\n",
    "df.loc[:, 'mag_pid'] = df['mag_pid'].astype(int)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01563aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34262 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "35631  This work shows that Tregs from type 1 diabeti...   \n",
       "35632  This study demonstrates that engineered IL-2 r...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This report describes a novel genome editing a...   \n",
       "35635  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \\\n",
       "0      These results provide evidence that modern cat...  2005395185   \n",
       "1      These findings provide evidence for independen...  2110049233   \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742   \n",
       "3      This study is among the first to examine the e...  2103106090   \n",
       "4      This study mapped genetic loci associated with...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "35631  This study highlights the challenges of transl...  2137227986   \n",
       "35632  These findings suggest that engineering cytoki...  2789780246   \n",
       "35633  T cells recognize a unique type of antigen tha...  2266478788   \n",
       "35634  This study demonstrated that human ESCs and iP...  2943378944   \n",
       "35635  These studies identify a population of human C...  1560277370   \n",
       "\n",
       "         mag_vid  year  \n",
       "0      125754415  1994  \n",
       "1       65932378  2000  \n",
       "2      125754415  1999  \n",
       "3       43092948  2000  \n",
       "4        3880285  1994  \n",
       "...          ...   ...  \n",
       "35631  129060628  2009  \n",
       "35632    3880285  2018  \n",
       "35633    3880285  2016  \n",
       "35634  125754415  2019  \n",
       "35635   38008053  2001  \n",
       "\n",
       "[34262 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAG_paper_df = pd.read_parquet(home / 'projects/TLDR/data/MAG_paper.parquet')\n",
    "df = df.merge(MAG_paper_df[['VenueID', 'Year']], left_on='mag_pid', right_index=True, how='inner')\n",
    "df.rename(columns={'VenueID': 'mag_vid', 'Year': 'year'}, inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd1e4d",
   "metadata": {},
   "source": [
    "# Load subject label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc271ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scopus_label</th>\n",
       "      <th>movMF_label</th>\n",
       "      <th>movMF_distance</th>\n",
       "      <th>x_val</th>\n",
       "      <th>y_val</th>\n",
       "      <th>kmeans_label</th>\n",
       "      <th>kmeans_distance</th>\n",
       "      <th>skm_label</th>\n",
       "      <th>skm_distance</th>\n",
       "      <th>spectral_label</th>\n",
       "      <th>n2v_kmeans_label</th>\n",
       "      <th>cm_kmeans_label</th>\n",
       "      <th>gnn_kmeans_label</th>\n",
       "      <th>bert_kmeans_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202381698</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.445886</td>\n",
       "      <td>-67.928200</td>\n",
       "      <td>15.572327</td>\n",
       "      <td>17</td>\n",
       "      <td>0.628846</td>\n",
       "      <td>20</td>\n",
       "      <td>0.444711</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137773608</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>-68.405334</td>\n",
       "      <td>-55.633186</td>\n",
       "      <td>17</td>\n",
       "      <td>0.735654</td>\n",
       "      <td>20</td>\n",
       "      <td>0.559494</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125754415</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.574571</td>\n",
       "      <td>-68.448853</td>\n",
       "      <td>-55.613579</td>\n",
       "      <td>17</td>\n",
       "      <td>0.705024</td>\n",
       "      <td>20</td>\n",
       "      <td>0.550081</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880285</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>23</td>\n",
       "      <td>0.618842</td>\n",
       "      <td>-68.407288</td>\n",
       "      <td>-55.634430</td>\n",
       "      <td>8</td>\n",
       "      <td>0.724859</td>\n",
       "      <td>17</td>\n",
       "      <td>0.610582</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111155417</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>23</td>\n",
       "      <td>0.220853</td>\n",
       "      <td>-54.506985</td>\n",
       "      <td>-61.217068</td>\n",
       "      <td>11</td>\n",
       "      <td>0.495787</td>\n",
       "      <td>12</td>\n",
       "      <td>0.198758</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764485818</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>21</td>\n",
       "      <td>0.268070</td>\n",
       "      <td>-28.969574</td>\n",
       "      <td>34.819569</td>\n",
       "      <td>18</td>\n",
       "      <td>0.542531</td>\n",
       "      <td>14</td>\n",
       "      <td>0.251015</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83454320</th>\n",
       "      <td>Arts and Humanities</td>\n",
       "      <td>25</td>\n",
       "      <td>0.034777</td>\n",
       "      <td>78.609909</td>\n",
       "      <td>31.736822</td>\n",
       "      <td>13</td>\n",
       "      <td>0.251599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056642</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507453</th>\n",
       "      <td>Arts and Humanities</td>\n",
       "      <td>6</td>\n",
       "      <td>0.113656</td>\n",
       "      <td>89.206772</td>\n",
       "      <td>17.625090</td>\n",
       "      <td>13</td>\n",
       "      <td>0.307089</td>\n",
       "      <td>3</td>\n",
       "      <td>0.128660</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121509672</th>\n",
       "      <td>Agricultural and Biological Sciences</td>\n",
       "      <td>5</td>\n",
       "      <td>0.179111</td>\n",
       "      <td>-36.757057</td>\n",
       "      <td>-0.591017</td>\n",
       "      <td>21</td>\n",
       "      <td>0.430040</td>\n",
       "      <td>16</td>\n",
       "      <td>0.207435</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53107364</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>23</td>\n",
       "      <td>0.258839</td>\n",
       "      <td>-46.797390</td>\n",
       "      <td>-55.657715</td>\n",
       "      <td>11</td>\n",
       "      <td>0.494533</td>\n",
       "      <td>12</td>\n",
       "      <td>0.223036</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20038 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Scopus_label  movMF_label  movMF_distance  \\\n",
       "202381698                      Multidisciplinary           22        0.445886   \n",
       "137773608                      Multidisciplinary           22        0.590942   \n",
       "125754415                      Multidisciplinary           22        0.574571   \n",
       "3880285                        Multidisciplinary           23        0.618842   \n",
       "111155417                              Chemistry           23        0.220853   \n",
       "...                                          ...          ...             ...   \n",
       "2764485818                              Medicine           21        0.268070   \n",
       "83454320                     Arts and Humanities           25        0.034777   \n",
       "16507453                     Arts and Humanities            6        0.113656   \n",
       "121509672   Agricultural and Biological Sciences            5        0.179111   \n",
       "53107364                                Medicine           23        0.258839   \n",
       "\n",
       "                x_val      y_val  kmeans_label  kmeans_distance  skm_label  \\\n",
       "202381698  -67.928200  15.572327            17         0.628846         20   \n",
       "137773608  -68.405334 -55.633186            17         0.735654         20   \n",
       "125754415  -68.448853 -55.613579            17         0.705024         20   \n",
       "3880285    -68.407288 -55.634430             8         0.724859         17   \n",
       "111155417  -54.506985 -61.217068            11         0.495787         12   \n",
       "...               ...        ...           ...              ...        ...   \n",
       "2764485818 -28.969574  34.819569            18         0.542531         14   \n",
       "83454320    78.609909  31.736822            13         0.251599          3   \n",
       "16507453    89.206772  17.625090            13         0.307089          3   \n",
       "121509672  -36.757057  -0.591017            21         0.430040         16   \n",
       "53107364   -46.797390 -55.657715            11         0.494533         12   \n",
       "\n",
       "            skm_distance  spectral_label  n2v_kmeans_label  cm_kmeans_label  \\\n",
       "202381698       0.444711              24                 3               21   \n",
       "137773608       0.559494              24                20               21   \n",
       "125754415       0.550081              24                20               21   \n",
       "3880285         0.610582              24                20               21   \n",
       "111155417       0.198758              14                 4               24   \n",
       "...                  ...             ...               ...              ...   \n",
       "2764485818      0.251015               8                18                1   \n",
       "83454320        0.056642              21                 5                1   \n",
       "16507453        0.128660              21                 5                1   \n",
       "121509672       0.207435              10                 5                1   \n",
       "53107364        0.223036              14                 0               24   \n",
       "\n",
       "            gnn_kmeans_label  bert_kmeans_label  \n",
       "202381698                  0                  0  \n",
       "137773608                  0                  3  \n",
       "125754415                  0                  0  \n",
       "3880285                    0                  3  \n",
       "111155417                 21                  0  \n",
       "...                      ...                ...  \n",
       "2764485818                19                  1  \n",
       "83454320                  14                  1  \n",
       "16507453                  14                  1  \n",
       "121509672                 10                  1  \n",
       "53107364                  22                  1  \n",
       "\n",
       "[20038 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_parquet(home / 'projects/TLDR/data/cluster_df.parquet')\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0971ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34146 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "35631  This work shows that Tregs from type 1 diabeti...   \n",
       "35632  This study demonstrates that engineered IL-2 r...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This report describes a novel genome editing a...   \n",
       "35635  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \\\n",
       "0      These results provide evidence that modern cat...  2005395185   \n",
       "1      These findings provide evidence for independen...  2110049233   \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742   \n",
       "3      This study is among the first to examine the e...  2103106090   \n",
       "4      This study mapped genetic loci associated with...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "35631  This study highlights the challenges of transl...  2137227986   \n",
       "35632  These findings suggest that engineering cytoki...  2789780246   \n",
       "35633  T cells recognize a unique type of antigen tha...  2266478788   \n",
       "35634  This study demonstrated that human ESCs and iP...  2943378944   \n",
       "35635  These studies identify a population of human C...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "35631  129060628  2009         17   \n",
       "35632    3880285  2018          8   \n",
       "35633    3880285  2016          8   \n",
       "35634  125754415  2019         17   \n",
       "35635   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \n",
       "0                                 Multidisciplinary  \n",
       "1      Biochemistry, Genetics and Molecular Biology  \n",
       "2                                 Multidisciplinary  \n",
       "3      Biochemistry, Genetics and Molecular Biology  \n",
       "4                                 Multidisciplinary  \n",
       "...                                             ...  \n",
       "35631                                      Medicine  \n",
       "35632                             Multidisciplinary  \n",
       "35633                             Multidisciplinary  \n",
       "35634                             Multidisciplinary  \n",
       "35635                   Immunology and Microbiology  \n",
       "\n",
       "[34146 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(label_df[['kmeans_label', 'Scopus_label']], left_on='mag_vid', right_index=True, how='inner')\n",
    "df.rename(columns={'kmeans_label': 'p2v_label', 'Scopus_label': 'scopus_label'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "226296ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p2v_label\n",
       "17    18439\n",
       "8      9625\n",
       "6      1457\n",
       "7      1028\n",
       "4       627\n",
       "9       611\n",
       "11      580\n",
       "22      404\n",
       "18      363\n",
       "21      319\n",
       "12      292\n",
       "20      121\n",
       "1        60\n",
       "3        49\n",
       "14       32\n",
       "5        25\n",
       "24       21\n",
       "16       21\n",
       "15       17\n",
       "2        16\n",
       "23       16\n",
       "0        10\n",
       "19        6\n",
       "13        5\n",
       "25        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['p2v_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcc140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scopus_label\n",
       "Multidisciplinary                               15639\n",
       "Medicine                                         5262\n",
       "Immunology and Microbiology                      4146\n",
       "Biochemistry, Genetics and Molecular Biology     4116\n",
       "Chemistry                                        1285\n",
       "Neuroscience                                     1211\n",
       "Agricultural and Biological Sciences              704\n",
       "Social Sciences                                   608\n",
       "Earth and Planetary Sciences                      235\n",
       "Materials Science                                 179\n",
       "Psychology                                        156\n",
       "Physics and Astronomy                             139\n",
       "Pharmacology, Toxicology and Pharmaceutics        128\n",
       "Environmental Science                             119\n",
       "Energy                                             39\n",
       "Mathematics                                        30\n",
       "Engineering                                        28\n",
       "Computer Science                                   24\n",
       "Nursing                                            24\n",
       "Economics, Econometrics and Finance                21\n",
       "Dentistry                                          16\n",
       "Chemical Engineering                               13\n",
       "Business, Management and Accounting                 8\n",
       "Health Professions                                  6\n",
       "Arts and Humanities                                 6\n",
       "Veterinary                                          3\n",
       "Decision Sciences                                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scopus_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbda26a",
   "metadata": {},
   "source": [
    "# Predict subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd843a0",
   "metadata": {},
   "source": [
    "## 10-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590f6dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 93187.77it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    1.4s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Acc: 0.6587±0.0061 | Precision: 0.6287±0.0040 | Recall: 0.8987±0.0075 | F1: 0.7398±0.0049\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 71788.10it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Acc: 0.6488±0.0055 | Precision: 0.6210±0.0040 | Recall: 0.8969±0.0049 | F1: 0.7339±0.0038\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 111279.23it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Acc: 0.6411±0.0043 | Precision: 0.6133±0.0028 | Recall: 0.9076±0.0078 | F1: 0.7320±0.0036\n",
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:02<00:00, 16560.78it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Acc: 0.6962±0.0039 | Precision: 0.6544±0.0022 | Recall: 0.9270±0.0074 | F1: 0.7672±0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.658702</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.628717</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.898693</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>0.739838</td>\n",
       "      <td>0.004856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.648774</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>0.621047</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.896903</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.733902</td>\n",
       "      <td>0.003784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.641100</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.613316</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.907641</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.731988</td>\n",
       "      <td>0.003620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.654427</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.927002</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.767215</td>\n",
       "      <td>0.003539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "0      gemma3       0.658702      0.006141        0.628717       0.004039   \n",
       "1      llama4       0.648774      0.005533        0.621047       0.004037   \n",
       "2  annotation       0.641100      0.004256        0.613316       0.002769   \n",
       "3    abstract       0.696246      0.003894        0.654427       0.002232   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "0     0.898693    0.007472  0.739838  0.004856  \n",
       "1     0.896903    0.004904  0.733902  0.003784  \n",
       "2     0.907641    0.007798  0.731988  0.003620  \n",
       "3     0.927002    0.007353  0.767215  0.003539  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "# text_features = ['abstract', 'annotation', 'deepseek_v3', 'qwen3','gemma3', 'llama4', 'qwq']\n",
    "text_features = models + ['annotation', 'abstract']\n",
    "y = (df['p2v_label'] == 17).astype(int)  # 17为1，否则为0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**18, stop_words='english', alternate_sign=False)\n",
    "    X = vectorizer.transform(X_text)\n",
    "    clf = MultinomialNB()\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=scoring, n_jobs=-1, verbose=1)\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'accuracy_mean': scores['test_accuracy'].mean(),\n",
    "        'accuracy_std': scores['test_accuracy'].std(),\n",
    "        'precision_mean': scores['test_precision'].mean(),\n",
    "        'precision_std': scores['test_precision'].std(),\n",
    "        'recall_mean': scores['test_recall'].mean(),\n",
    "        'recall_std': scores['test_recall'].std(),\n",
    "        'f1_mean': scores['test_f1'].mean(),\n",
    "        'f1_std': scores['test_f1'].std(),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Acc: {res['accuracy_mean']:.4f}±{res['accuracy_std']:.4f} | \"\n",
    "        f\"Precision: {res['precision_mean']:.4f}±{res['precision_std']:.4f} | \"\n",
    "        f\"Recall: {res['recall_mean']:.4f}±{res['recall_std']:.4f} | \"\n",
    "        f\"F1: {res['f1_mean']:.4f}±{res['f1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a2558",
   "metadata": {},
   "source": [
    "## no cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e71fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:01<00:00, 21263.68it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 21465.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.6972 | Precision: 0.6540 | Recall: 0.9328 | F1: 0.7689\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 138569.82it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 137783.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.6442 | Precision: 0.6150 | Recall: 0.9121 | F1: 0.7347\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 75092.37it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 73381.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.6656 | Precision: 0.6333 | Recall: 0.9046 | F1: 0.7450\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 118969.75it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 110159.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.6723 | Precision: 0.6389 | Recall: 0.9040 | F1: 0.7487\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 57141.27it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 84019.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.6624 | Precision: 0.6299 | Recall: 0.9084 | F1: 0.7439\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 43916.52it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 44519.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.6685 | Precision: 0.6364 | Recall: 0.9008 | F1: 0.7458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.697218</td>\n",
       "      <td>0.653992</td>\n",
       "      <td>0.932755</td>\n",
       "      <td>0.768887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.644217</td>\n",
       "      <td>0.614991</td>\n",
       "      <td>0.912148</td>\n",
       "      <td>0.734658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.665593</td>\n",
       "      <td>0.633257</td>\n",
       "      <td>0.904555</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.672328</td>\n",
       "      <td>0.638942</td>\n",
       "      <td>0.904013</td>\n",
       "      <td>0.748709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.662372</td>\n",
       "      <td>0.629936</td>\n",
       "      <td>0.908351</td>\n",
       "      <td>0.743948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.668521</td>\n",
       "      <td>0.636398</td>\n",
       "      <td>0.900759</td>\n",
       "      <td>0.745846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  accuracy  precision    recall        f1\n",
       "0     abstract  0.697218   0.653992  0.932755  0.768887\n",
       "1   annotation  0.644217   0.614991  0.912148  0.734658\n",
       "2  deepseek_v3  0.665593   0.633257  0.904555  0.744975\n",
       "3       gemma3  0.672328   0.638942  0.904013  0.748709\n",
       "4       llama4  0.662372   0.629936  0.908351  0.743948\n",
       "5          qwq  0.668521   0.636398  0.900759  0.745846"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "# 二分类标签：是否为17\n",
    "y = (df['p2v_label'] == 17).astype(int)  # 17为1，否则为0\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.1, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**18, stop_words='english', alternate_sign=False)\n",
    "    X_train_vec = vectorizer.transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['accuracy']:.4f} | \"\n",
    "        f\"Precision: {res['precision']:.4f} | \"\n",
    "        f\"Recall: {res['recall']:.4f} | \"\n",
    "        f\"F1: {res['f1']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762be464",
   "metadata": {},
   "source": [
    "# Predict year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40795c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    34146.000000\n",
       "mean      2006.680724\n",
       "std          9.105688\n",
       "min       1887.000000\n",
       "25%       2001.000000\n",
       "50%       2007.000000\n",
       "75%       2014.000000\n",
       "max       2022.000000\n",
       "Name: year, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fb2f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.histplot(df, x='year', stat='count', discrete=True)\n",
    "plt.xlabel('Publication year')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5fa53",
   "metadata": {},
   "source": [
    "## 10-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580439a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents:   0%|                                                                                                            | 0/34146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 89301.78it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "/home/zqlyu2/.local/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.0s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.7049±0.0074 | F1: 0.6446±0.0089\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 76306.55it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "/home/zqlyu2/.local/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    1.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.7020±0.0086 | F1: 0.6547±0.0101\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 111202.33it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.7161±0.0090 | F1: 0.6678±0.0120\n",
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:02<00:00, 16993.84it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.7542±0.0080 | F1: 0.7063±0.0094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.704856</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.553764</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.644592</td>\n",
       "      <td>0.008896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.701956</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.744273</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.584601</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.654728</td>\n",
       "      <td>0.010091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.716131</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.768938</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.590483</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.667834</td>\n",
       "      <td>0.011960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.754203</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.836492</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.611367</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.706276</td>\n",
       "      <td>0.009402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  \\\n",
       "0      gemma3       0.704856      0.007369        0.771654       0.011675   \n",
       "1      llama4       0.701956      0.008589        0.744273       0.012986   \n",
       "2  annotation       0.716131      0.009039        0.768938       0.013663   \n",
       "3    abstract       0.754203      0.008020        0.836492       0.011048   \n",
       "\n",
       "   Recall_mean  Recall_std   F1_mean    F1_std  \n",
       "0     0.553764    0.014894  0.644592  0.008896  \n",
       "1     0.584601    0.013100  0.654728  0.010091  \n",
       "2     0.590483    0.016425  0.667834  0.011960  \n",
       "3     0.611367    0.014414  0.706276  0.009402  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "# 指标: Accuracy, Precision, Recall, F1\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "text_features = models + ['annotation', 'abstract']\n",
    "y = (df['year'] >= 2008).astype(int)\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**20, stop_words='english', alternate_sign=False)\n",
    "    X = vectorizer.transform(X_text)\n",
    "    model = MultinomialNB()\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1, verbose=1, return_train_score=False)\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy_mean': scores['test_Accuracy'].mean(),\n",
    "        'Accuracy_std': scores['test_Accuracy'].std(),\n",
    "        'Precision_mean': scores['test_Precision'].mean(),\n",
    "        'Precision_std': scores['test_Precision'].std(),\n",
    "        'Recall_mean': scores['test_Recall'].mean(),\n",
    "        'Recall_std': scores['test_Recall'].std(),\n",
    "        'F1_mean': scores['test_F1'].mean(),\n",
    "        'F1_std': scores['test_F1'].std(),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy_mean']:.4f}±{res['Accuracy_std']:.4f} | \"\n",
    "        f\"F1: {res['F1_mean']:.4f}±{res['F1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f2c119",
   "metadata": {},
   "source": [
    "## no cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:01<00:00, 21330.43it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 22020.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | MAE: 4.2865 | R2: 0.5755\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 110815.97it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 130228.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | MAE: 5.5461 | R2: 0.3061\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 67192.84it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 77554.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | MAE: 5.0521 | R2: 0.4281\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 99404.52it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 120217.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | MAE: 5.5035 | R2: 0.3244\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 55302.63it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 54197.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | MAE: 5.5231 | R2: 0.3139\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 40333.08it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 44297.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | MAE: 5.0755 | R2: 0.4131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>4.286524</td>\n",
       "      <td>34.042876</td>\n",
       "      <td>0.575475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>5.546063</td>\n",
       "      <td>55.646234</td>\n",
       "      <td>0.306074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>5.052078</td>\n",
       "      <td>45.857851</td>\n",
       "      <td>0.428139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>5.503463</td>\n",
       "      <td>54.177417</td>\n",
       "      <td>0.324391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama4</td>\n",
       "      <td>5.523119</td>\n",
       "      <td>55.020432</td>\n",
       "      <td>0.313878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwq</td>\n",
       "      <td>5.075490</td>\n",
       "      <td>47.060866</td>\n",
       "      <td>0.413137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature       MAE        MSE        R2\n",
       "0     abstract  4.286524  34.042876  0.575475\n",
       "1   annotation  5.546063  55.646234  0.306074\n",
       "2  deepseek_v3  5.052078  45.857851  0.428139\n",
       "3       gemma3  5.503463  54.177417  0.324391\n",
       "4       llama4  5.523119  55.020432  0.313878\n",
       "5          qwq  5.075490  47.060866  0.413137"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "y = df['year'].astype(int)  # 年份作为连续变量回归\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**18, stop_words='english', alternate_sign=False)\n",
    "    X_train_vec = vectorizer.transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"MAE: {res['MAE']:.4f} | \"\n",
    "        f\"R2: {res['R2']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0799cb16",
   "metadata": {},
   "source": [
    "# Predict title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7f76a",
   "metadata": {},
   "source": [
    "## Fetch titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12388ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying titles: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:00<00:00, 160.05batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1353153</td>\n",
       "      <td>Efficient Generation of a Hepatitis B Virus Cy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1634910</td>\n",
       "      <td>Structure of Hjc, a Holliday junction resolvas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1655469</td>\n",
       "      <td>From Complete Genomes to Measures of Substitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1778349</td>\n",
       "      <td>Regulation of the Proinflammatory Effects of F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2550721</td>\n",
       "      <td>Differential requirement for p19ARF in the p53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28005</th>\n",
       "      <td>83433077</td>\n",
       "      <td>Revisiting IL-2: Biology and therapeutic prosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28006</th>\n",
       "      <td>104021261</td>\n",
       "      <td>Systems-level analysis of mechanisms regulatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28007</th>\n",
       "      <td>104393236</td>\n",
       "      <td>siRNA nanoparticles targeting CaMKIIγ in lesio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28008</th>\n",
       "      <td>123181209</td>\n",
       "      <td>Immunotherapy of autoimmune encephalomyelitis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28009</th>\n",
       "      <td>125333095</td>\n",
       "      <td>RNA components of the spliceosome regulate tis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper_id                                              title\n",
       "0        1353153  Efficient Generation of a Hepatitis B Virus Cy...\n",
       "1        1634910  Structure of Hjc, a Holliday junction resolvas...\n",
       "2        1655469  From Complete Genomes to Measures of Substitut...\n",
       "3        1778349  Regulation of the Proinflammatory Effects of F...\n",
       "4        2550721  Differential requirement for p19ARF in the p53...\n",
       "...          ...                                                ...\n",
       "28005   83433077  Revisiting IL-2: Biology and therapeutic prosp...\n",
       "28006  104021261  Systems-level analysis of mechanisms regulatin...\n",
       "28007  104393236  siRNA nanoparticles targeting CaMKIIγ in lesio...\n",
       "28008  123181209  Immunotherapy of autoimmune encephalomyelitis ...\n",
       "28009  125333095  RNA components of the spliceosome regulate tis...\n",
       "\n",
       "[28010 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "\n",
    "MYSQL_HOST = '144.214.39.113'\n",
    "MYSQL_USER = 'key'\n",
    "MYSQL_PASS = 'Keydge11'\n",
    "MYSQL_DB = 'keydge'\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASS}@{MYSQL_HOST}/{MYSQL_DB}?charset=utf8mb4')\n",
    "\n",
    "paper_ids = df['paper_id'].unique().tolist()\n",
    "BATCH_SIZE = 500  # 每批查多少条，可调大或调小\n",
    "\n",
    "results = []\n",
    "# 用tqdm显示批次进度和预计完成时间\n",
    "for i in tqdm(range(0, len(paper_ids), BATCH_SIZE), desc=\"Querying titles\", unit=\"batch\"):\n",
    "    batch = paper_ids[i:i+BATCH_SIZE]\n",
    "    id_str = ','.join(str(int(pid)) for pid in batch)\n",
    "    sql = f\"SELECT paper_id, title FROM paper_bib WHERE paper_id IN ({id_str})\"\n",
    "    batch_df = pd.read_sql(sql, engine)\n",
    "    results.append(batch_df)\n",
    "\n",
    "# 合并所有批次的查询结果\n",
    "paper_title_df = pd.concat(results, ignore_index=True)\n",
    "display(paper_title_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_title_df.to_parquet(home / 'projects/TLDR/data/paper_title.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402df34b",
   "metadata": {},
   "source": [
    "## Load titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a09c2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Evidence for two independent domestications of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>The Origin of the Domestic Pig: Independent Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Fine-mapping of quantitative trait loci by ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>Extensive Genome-wide Linkage Disequilibrium i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Genetic mapping of quantitative trait loci for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34141</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Expansion of Human Regulatory T-Cells From Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34142</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Selective targeting of engineered T cells usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34143</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Pathogenic CD4 T cells in type 1 diabetes reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34144</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Generation of hypoimmunogenic human pluripoten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34145</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "      <td>CD4+CD25high Regulatory Cells in Human Periphe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34146 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "34141            10.2337/db08-1168    4860455   \n",
       "34142      10.1126/science.aar3246    4860145   \n",
       "34143      10.1126/science.aad2791   62290395   \n",
       "34144      10.1073/pnas.1902566116   82979762   \n",
       "34145  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "34141  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "34142  Engineering cytokine-receptor pairs Interleuki...   \n",
       "34143  T cells target peptide combos One of the endur...   \n",
       "34144  Polymorphic HLAs form the primary immune barri...   \n",
       "34145  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "34141  This article describes the good manufacturing ...   \n",
       "34142  This study reports the generation of an orthog...   \n",
       "34143  This article shows that some diabetogenic T ce...   \n",
       "34144  This article describes the development of gene...   \n",
       "34145  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "34141  This work shows that Tregs from type 1 diabeti...   \n",
       "34142  This study demonstrates that engineered IL-2 r...   \n",
       "34143  This study identified that autoreactive T cell...   \n",
       "34144  This report describes a novel genome editing a...   \n",
       "34145  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \\\n",
       "0      These results provide evidence that modern cat...  2005395185   \n",
       "1      These findings provide evidence for independen...  2110049233   \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742   \n",
       "3      This study is among the first to examine the e...  2103106090   \n",
       "4      This study mapped genetic loci associated with...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "34141  This study highlights the challenges of transl...  2137227986   \n",
       "34142  These findings suggest that engineering cytoki...  2789780246   \n",
       "34143  T cells recognize a unique type of antigen tha...  2266478788   \n",
       "34144  This study demonstrated that human ESCs and iP...  2943378944   \n",
       "34145  These studies identify a population of human C...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "34141  129060628  2009         17   \n",
       "34142    3880285  2018          8   \n",
       "34143    3880285  2016          8   \n",
       "34144  125754415  2019         17   \n",
       "34145   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \\\n",
       "0                                 Multidisciplinary   \n",
       "1      Biochemistry, Genetics and Molecular Biology   \n",
       "2                                 Multidisciplinary   \n",
       "3      Biochemistry, Genetics and Molecular Biology   \n",
       "4                                 Multidisciplinary   \n",
       "...                                             ...   \n",
       "34141                                      Medicine   \n",
       "34142                             Multidisciplinary   \n",
       "34143                             Multidisciplinary   \n",
       "34144                             Multidisciplinary   \n",
       "34145                   Immunology and Microbiology   \n",
       "\n",
       "                                                   title  \n",
       "0      Evidence for two independent domestications of...  \n",
       "1      The Origin of the Domestic Pig: Independent Do...  \n",
       "2      Fine-mapping of quantitative trait loci by ide...  \n",
       "3      Extensive Genome-wide Linkage Disequilibrium i...  \n",
       "4      Genetic mapping of quantitative trait loci for...  \n",
       "...                                                  ...  \n",
       "34141  Expansion of Human Regulatory T-Cells From Pat...  \n",
       "34142  Selective targeting of engineered T cells usin...  \n",
       "34143  Pathogenic CD4 T cells in type 1 diabetes reco...  \n",
       "34144  Generation of hypoimmunogenic human pluripoten...  \n",
       "34145  CD4+CD25high Regulatory Cells in Human Periphe...  \n",
       "\n",
       "[34146 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper_title_df = pd.read_parquet(home / 'projects/TLDR/data/paper_title.parquet')\n",
    "df = df.merge(paper_title_df, on='paper_id', how='left')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e52db",
   "metadata": {},
   "source": [
    "## Generate negative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ac1d8",
   "metadata": {},
   "source": [
    "### Use random title of other papers in same subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9129e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本:   0%|                                                                                                             | 39/34146 [00:00<01:27, 389.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:49<00:00, 686.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "pos_df = df.copy()\n",
    "\n",
    "# 标记正样本\n",
    "pos_df['title_paired'] = True\n",
    "\n",
    "# 收集负样本\n",
    "neg_samples = []\n",
    "rng = np.random.default_rng(42)  # 固定随机种子便于复现\n",
    "\n",
    "for idx, row in tqdm(pos_df.iterrows(), total=len(pos_df), desc=\"生成负样本\"):\n",
    "    # 查找同学科标签但不同paper_id的候选title\n",
    "    candidates = pos_df[(pos_df['p2v_label'] == row['p2v_label']) & (pos_df['paper_id'] != row['paper_id'])]\n",
    "    if not candidates.empty:\n",
    "        neg_title = rng.choice(candidates['title'].values)\n",
    "        neg_row = row.copy()\n",
    "        neg_row['title'] = neg_title\n",
    "        neg_row['title_paired'] = False\n",
    "        neg_samples.append(neg_row)\n",
    "    else:\n",
    "        raise ValueError(f\"没有找到与行 {idx} 同学科但不同paper_id的候选title。\")\n",
    "\n",
    "neg_df = pd.DataFrame(neg_samples)\n",
    "\n",
    "# 合并正负样本\n",
    "title_match_df = pd.concat([pos_df, neg_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "056e5c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Responding to the Impacts of the Climate Crisis on Children and Youth',\n",
       " 'Transgenic Anopheles stephensi coexpressing single-chain antibodies resist Plasmodium falciparum development',\n",
       " 'AG-221, a First-in-Class Therapy Targeting Acute Myeloid Leukemia Harboring Oncogenic IDH2 Mutations',\n",
       " 'Toxin, toxin-coregulated pili, and the toxR regulon are essential for Vibrio cholerae pathogenesis in humans.',\n",
       " 'Defining the origins of Ras/p53-mediated squamous cell carcinoma']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match_df[title_match_df['title_paired'] == False]['title'].sample(5).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5dea7c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23bca6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "      <th>title</th>\n",
       "      <th>title_paired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This reference reports on phylogenetic relatio...</td>\n",
       "      <td>These results provide evidence that modern cat...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Evidence for two independent domestications of...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study demonstrates that European domestic...</td>\n",
       "      <td>These findings provide evidence for independen...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>The Origin of the Domestic Pig: Independent Do...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This reference details a fine-mapping strategy...</td>\n",
       "      <td>The authors fine-map a QTL for milk fat percen...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Fine-mapping of quantitative trait loci by ide...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This paper reports high levels of linkage dise...</td>\n",
       "      <td>This study is among the first to examine the e...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>Extensive Genome-wide Linkage Disequilibrium i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This work describes a QTL mapping study of a w...</td>\n",
       "      <td>This study mapped genetic loci associated with...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Genetic mapping of quantitative trait loci for...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68287</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This work shows that Tregs from type 1 diabeti...</td>\n",
       "      <td>This study highlights the challenges of transl...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Experience and Activity-Dependent Maturation o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68288</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study demonstrates that engineered IL-2 r...</td>\n",
       "      <td>These findings suggest that engineering cytoki...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>A Clonogenic Bone Marrow Progenitor Specific f...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68289</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells recognize a unique type of antigen tha...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Single-cell RNA-seq highlights intratumoral he...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68290</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This report describes a novel genome editing a...</td>\n",
       "      <td>This study demonstrated that human ESCs and iP...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Iterative fractionation of recycling receptors...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68291</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This paper describes the human equivalent of m...</td>\n",
       "      <td>These studies identify a population of human C...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "      <td>Novel Analytic Criteria and Effective Plate De...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68292 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "68287            10.2337/db08-1168    4860455   \n",
       "68288      10.1126/science.aar3246    4860145   \n",
       "68289      10.1126/science.aad2791   62290395   \n",
       "68290      10.1073/pnas.1902566116   82979762   \n",
       "68291  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "68287  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "68288  Engineering cytokine-receptor pairs Interleuki...   \n",
       "68289  T cells target peptide combos One of the endur...   \n",
       "68290  Polymorphic HLAs form the primary immune barri...   \n",
       "68291  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "68287  This article describes the good manufacturing ...   \n",
       "68288  This study reports the generation of an orthog...   \n",
       "68289  This article shows that some diabetogenic T ce...   \n",
       "68290  This article describes the development of gene...   \n",
       "68291  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      This reference reports on phylogenetic relatio...   \n",
       "1      This study demonstrates that European domestic...   \n",
       "2      This reference details a fine-mapping strategy...   \n",
       "3      This paper reports high levels of linkage dise...   \n",
       "4      This work describes a QTL mapping study of a w...   \n",
       "...                                                  ...   \n",
       "68287  This work shows that Tregs from type 1 diabeti...   \n",
       "68288  This study demonstrates that engineered IL-2 r...   \n",
       "68289  This study identified that autoreactive T cell...   \n",
       "68290  This report describes a novel genome editing a...   \n",
       "68291  This paper describes the human equivalent of m...   \n",
       "\n",
       "                                                  llama4     mag_pid  \\\n",
       "0      These results provide evidence that modern cat...  2005395185   \n",
       "1      These findings provide evidence for independen...  2110049233   \n",
       "2      The authors fine-map a QTL for milk fat percen...  2082900742   \n",
       "3      This study is among the first to examine the e...  2103106090   \n",
       "4      This study mapped genetic loci associated with...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "68287  This study highlights the challenges of transl...  2137227986   \n",
       "68288  These findings suggest that engineering cytoki...  2789780246   \n",
       "68289  T cells recognize a unique type of antigen tha...  2266478788   \n",
       "68290  This study demonstrated that human ESCs and iP...  2943378944   \n",
       "68291  These studies identify a population of human C...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "68287  129060628  2009         17   \n",
       "68288    3880285  2018          8   \n",
       "68289    3880285  2016          8   \n",
       "68290  125754415  2019         17   \n",
       "68291   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \\\n",
       "0                                 Multidisciplinary   \n",
       "1      Biochemistry, Genetics and Molecular Biology   \n",
       "2                                 Multidisciplinary   \n",
       "3      Biochemistry, Genetics and Molecular Biology   \n",
       "4                                 Multidisciplinary   \n",
       "...                                             ...   \n",
       "68287                                      Medicine   \n",
       "68288                             Multidisciplinary   \n",
       "68289                             Multidisciplinary   \n",
       "68290                             Multidisciplinary   \n",
       "68291                   Immunology and Microbiology   \n",
       "\n",
       "                                                   title  title_paired  \n",
       "0      Evidence for two independent domestications of...          True  \n",
       "1      The Origin of the Domestic Pig: Independent Do...          True  \n",
       "2      Fine-mapping of quantitative trait loci by ide...          True  \n",
       "3      Extensive Genome-wide Linkage Disequilibrium i...          True  \n",
       "4      Genetic mapping of quantitative trait loci for...          True  \n",
       "...                                                  ...           ...  \n",
       "68287  Experience and Activity-Dependent Maturation o...         False  \n",
       "68288  A Clonogenic Bone Marrow Progenitor Specific f...         False  \n",
       "68289  Single-cell RNA-seq highlights intratumoral he...         False  \n",
       "68290  Iterative fractionation of recycling receptors...         False  \n",
       "68291  Novel Analytic Criteria and Effective Plate De...         False  \n",
       "\n",
       "[68292 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe462cf6",
   "metadata": {},
   "source": [
    "### 10-CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4e904",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3833dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents:   0%|                                                                                                            | 0/68292 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:04<00:00, 15976.39it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.3s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.5499±0.0056 | F1: 0.5498±0.0070\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:00<00:00, 72535.34it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.2s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.6618±0.0051 | F1: 0.6569±0.0062\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 46628.61it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.7557±0.0062 | F1: 0.7537±0.0069\n",
      "Processing feature: qwen3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:02<00:00, 32650.61it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwen3 | Accuracy: 0.7139±0.0055 | F1: 0.7124±0.0040\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 64844.09it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.3s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.7577±0.0038 | F1: 0.7544±0.0045\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 38042.45it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.6843±0.0058 | F1: 0.6779±0.0066\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:02<00:00, 30616.49it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.4s remaining:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.6742±0.0061 | F1: 0.6738±0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.549933</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.549973</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.549904</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.549849</td>\n",
       "      <td>0.006991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.661805</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.666455</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.647740</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.006182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.759852</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.747601</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.753659</td>\n",
       "      <td>0.006902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen3</td>\n",
       "      <td>0.713920</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.716325</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.712379</td>\n",
       "      <td>0.004045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.757658</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.764547</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.744599</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.754423</td>\n",
       "      <td>0.004546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.684282</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.691811</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.664674</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.677939</td>\n",
       "      <td>0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.674222</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.673095</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>0.673829</td>\n",
       "      <td>0.005692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  \\\n",
       "0     abstract       0.549933      0.005592        0.549973       0.007610   \n",
       "1   annotation       0.661805      0.005107        0.666455       0.007536   \n",
       "2  deepseek_v3       0.755682      0.006233        0.759852       0.007990   \n",
       "3        qwen3       0.713920      0.005532        0.716325       0.007133   \n",
       "4       gemma3       0.757658      0.003785        0.764547       0.006018   \n",
       "5       llama4       0.684282      0.005826        0.691811       0.009807   \n",
       "6          qwq       0.674222      0.006091        0.674641       0.006608   \n",
       "\n",
       "   Recall_mean  Recall_std   F1_mean    F1_std  \n",
       "0     0.549904    0.011833  0.549849  0.006991  \n",
       "1     0.647740    0.006525  0.656947  0.006182  \n",
       "2     0.747601    0.007543  0.753659  0.006902  \n",
       "3     0.708609    0.008824  0.712379  0.004045  \n",
       "4     0.744599    0.005684  0.754423  0.004546  \n",
       "5     0.664674    0.006120  0.677939  0.006620  \n",
       "6     0.673095    0.008468  0.673829  0.005692  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "# 评价指标\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'qwen3','gemma3', 'llama4', 'qwq']\n",
    "y = title_match_df['title_paired'].astype(int)  # 1: 匹配，0: 不匹配\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    # 拼接title和对应的feature\n",
    "    X_text = (title_match_df['title'].astype(str).fillna('') + ' [SEP] ' + title_match_df[feat].astype(str).fillna(''))\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**20, stop_words='english', alternate_sign=False)\n",
    "    X = vectorizer.transform(X_text)\n",
    "    model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1, verbose=1, return_train_score=False)\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy_mean': scores['test_Accuracy'].mean(),\n",
    "        'Accuracy_std': scores['test_Accuracy'].std(),\n",
    "        'Precision_mean': scores['test_Precision'].mean(),\n",
    "        'Precision_std': scores['test_Precision'].std(),\n",
    "        'Recall_mean': scores['test_Recall'].mean(),\n",
    "        'Recall_std': scores['test_Recall'].std(),\n",
    "        'F1_mean': scores['test_F1'].mean(),\n",
    "        'F1_std': scores['test_F1'].std(),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy_mean']:.4f}±{res['Accuracy_std']:.4f} | \"\n",
    "        f\"F1: {res['F1_mean']:.4f}±{res['F1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e046c",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a441afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing feature: gemma3\n",
      "  Fold 1/10\n",
      "    No cached model found for gemma3 fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.103381</td>\n",
       "      <td>0.966179</td>\n",
       "      <td>0.968136</td>\n",
       "      <td>0.963259</td>\n",
       "      <td>0.965691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.081765</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>0.981922</td>\n",
       "      <td>0.965630</td>\n",
       "      <td>0.973708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.070657</td>\n",
       "      <td>0.977160</td>\n",
       "      <td>0.973243</td>\n",
       "      <td>0.980741</td>\n",
       "      <td>0.976978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.064772</td>\n",
       "      <td>0.978624</td>\n",
       "      <td>0.981509</td>\n",
       "      <td>0.975111</td>\n",
       "      <td>0.978300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for gemma3 fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.134200</td>\n",
       "      <td>0.098653</td>\n",
       "      <td>0.969253</td>\n",
       "      <td>0.975053</td>\n",
       "      <td>0.962326</td>\n",
       "      <td>0.968647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.085892</td>\n",
       "      <td>0.971889</td>\n",
       "      <td>0.984161</td>\n",
       "      <td>0.958469</td>\n",
       "      <td>0.971145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.089343</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.978998</td>\n",
       "      <td>0.967962</td>\n",
       "      <td>0.973449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.076971</td>\n",
       "      <td>0.975695</td>\n",
       "      <td>0.978501</td>\n",
       "      <td>0.972115</td>\n",
       "      <td>0.975298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for gemma3 fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.129515</td>\n",
       "      <td>0.956802</td>\n",
       "      <td>0.941061</td>\n",
       "      <td>0.975276</td>\n",
       "      <td>0.957863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.092783</td>\n",
       "      <td>0.973495</td>\n",
       "      <td>0.979676</td>\n",
       "      <td>0.967423</td>\n",
       "      <td>0.973511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.080985</td>\n",
       "      <td>0.974374</td>\n",
       "      <td>0.988619</td>\n",
       "      <td>0.960151</td>\n",
       "      <td>0.974177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.071235</td>\n",
       "      <td>0.978474</td>\n",
       "      <td>0.983260</td>\n",
       "      <td>0.973822</td>\n",
       "      <td>0.978518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for gemma3 fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.107400</td>\n",
       "      <td>0.106406</td>\n",
       "      <td>0.966906</td>\n",
       "      <td>0.975893</td>\n",
       "      <td>0.957652</td>\n",
       "      <td>0.966686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.083316</td>\n",
       "      <td>0.971885</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.971698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.973203</td>\n",
       "      <td>0.971761</td>\n",
       "      <td>0.974883</td>\n",
       "      <td>0.973320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.975399</td>\n",
       "      <td>0.975467</td>\n",
       "      <td>0.975467</td>\n",
       "      <td>0.975467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for gemma3 fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.103167</td>\n",
       "      <td>0.967784</td>\n",
       "      <td>0.979780</td>\n",
       "      <td>0.955904</td>\n",
       "      <td>0.967695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.091170</td>\n",
       "      <td>0.970860</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.960836</td>\n",
       "      <td>0.970834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.085089</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979388</td>\n",
       "      <td>0.964897</td>\n",
       "      <td>0.972088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.080177</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.975226</td>\n",
       "      <td>0.970699</td>\n",
       "      <td>0.972957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for gemma3 fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.115611</td>\n",
       "      <td>0.961927</td>\n",
       "      <td>0.948529</td>\n",
       "      <td>0.974320</td>\n",
       "      <td>0.961252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.095700</td>\n",
       "      <td>0.084599</td>\n",
       "      <td>0.973349</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.965559</td>\n",
       "      <td>0.972315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.086963</td>\n",
       "      <td>0.970420</td>\n",
       "      <td>0.979038</td>\n",
       "      <td>0.959517</td>\n",
       "      <td>0.969179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.082031</td>\n",
       "      <td>0.973642</td>\n",
       "      <td>0.983025</td>\n",
       "      <td>0.962236</td>\n",
       "      <td>0.972519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for gemma3 fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.971299</td>\n",
       "      <td>0.981888</td>\n",
       "      <td>0.960779</td>\n",
       "      <td>0.971219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>0.069567</td>\n",
       "      <td>0.977010</td>\n",
       "      <td>0.981248</td>\n",
       "      <td>0.972981</td>\n",
       "      <td>0.977097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.061465</td>\n",
       "      <td>0.979646</td>\n",
       "      <td>0.984453</td>\n",
       "      <td>0.975015</td>\n",
       "      <td>0.979711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.058098</td>\n",
       "      <td>0.980817</td>\n",
       "      <td>0.982231</td>\n",
       "      <td>0.979663</td>\n",
       "      <td>0.980945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for gemma3 fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.109304</td>\n",
       "      <td>0.963684</td>\n",
       "      <td>0.969472</td>\n",
       "      <td>0.957553</td>\n",
       "      <td>0.963476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.092347</td>\n",
       "      <td>0.971152</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.967799</td>\n",
       "      <td>0.971068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.100200</td>\n",
       "      <td>0.073272</td>\n",
       "      <td>0.973935</td>\n",
       "      <td>0.977300</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>0.973854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.077428</td>\n",
       "      <td>0.974813</td>\n",
       "      <td>0.975939</td>\n",
       "      <td>0.973653</td>\n",
       "      <td>0.974795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for gemma3 fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.118700</td>\n",
       "      <td>0.111444</td>\n",
       "      <td>0.962513</td>\n",
       "      <td>0.983651</td>\n",
       "      <td>0.941466</td>\n",
       "      <td>0.962097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.088992</td>\n",
       "      <td>0.969835</td>\n",
       "      <td>0.974832</td>\n",
       "      <td>0.965227</td>\n",
       "      <td>0.970006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.082762</td>\n",
       "      <td>0.972177</td>\n",
       "      <td>0.978293</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.972303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.079324</td>\n",
       "      <td>0.973056</td>\n",
       "      <td>0.980300</td>\n",
       "      <td>0.966097</td>\n",
       "      <td>0.973147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for gemma3 fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.099042</td>\n",
       "      <td>0.967052</td>\n",
       "      <td>0.962141</td>\n",
       "      <td>0.973502</td>\n",
       "      <td>0.967788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>0.082215</td>\n",
       "      <td>0.973203</td>\n",
       "      <td>0.987548</td>\n",
       "      <td>0.959389</td>\n",
       "      <td>0.973265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.074314</td>\n",
       "      <td>0.976278</td>\n",
       "      <td>0.986479</td>\n",
       "      <td>0.966590</td>\n",
       "      <td>0.976433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>0.067655</td>\n",
       "      <td>0.978474</td>\n",
       "      <td>0.985685</td>\n",
       "      <td>0.971774</td>\n",
       "      <td>0.978680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.9761±0.0027 | F1: 0.9760±0.0028\n",
      "\n",
      "Processing feature: llama4\n",
      "  Fold 1/10\n",
      "    No cached model found for llama4 fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.183827</td>\n",
       "      <td>0.932504</td>\n",
       "      <td>0.913451</td>\n",
       "      <td>0.953778</td>\n",
       "      <td>0.933179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.156731</td>\n",
       "      <td>0.943924</td>\n",
       "      <td>0.985399</td>\n",
       "      <td>0.899852</td>\n",
       "      <td>0.940685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.145500</td>\n",
       "      <td>0.123611</td>\n",
       "      <td>0.957833</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.957333</td>\n",
       "      <td>0.957333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.113383</td>\n",
       "      <td>0.962958</td>\n",
       "      <td>0.975046</td>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.962018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for llama4 fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.211000</td>\n",
       "      <td>0.174057</td>\n",
       "      <td>0.937628</td>\n",
       "      <td>0.958009</td>\n",
       "      <td>0.913675</td>\n",
       "      <td>0.935317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.125943</td>\n",
       "      <td>0.954466</td>\n",
       "      <td>0.970191</td>\n",
       "      <td>0.936517</td>\n",
       "      <td>0.953057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>0.115855</td>\n",
       "      <td>0.959297</td>\n",
       "      <td>0.963440</td>\n",
       "      <td>0.953723</td>\n",
       "      <td>0.958557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.130300</td>\n",
       "      <td>0.115767</td>\n",
       "      <td>0.959736</td>\n",
       "      <td>0.964865</td>\n",
       "      <td>0.953130</td>\n",
       "      <td>0.958961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for llama4 fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.180197</td>\n",
       "      <td>0.934690</td>\n",
       "      <td>0.941819</td>\n",
       "      <td>0.927574</td>\n",
       "      <td>0.934642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.148025</td>\n",
       "      <td>0.947284</td>\n",
       "      <td>0.944541</td>\n",
       "      <td>0.951134</td>\n",
       "      <td>0.947826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.129982</td>\n",
       "      <td>0.955191</td>\n",
       "      <td>0.969988</td>\n",
       "      <td>0.940081</td>\n",
       "      <td>0.954801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>0.127838</td>\n",
       "      <td>0.956509</td>\n",
       "      <td>0.977501</td>\n",
       "      <td>0.935137</td>\n",
       "      <td>0.955850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for llama4 fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.179855</td>\n",
       "      <td>0.932933</td>\n",
       "      <td>0.967234</td>\n",
       "      <td>0.896612</td>\n",
       "      <td>0.930585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.948309</td>\n",
       "      <td>0.943914</td>\n",
       "      <td>0.953563</td>\n",
       "      <td>0.948714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.156917</td>\n",
       "      <td>0.945966</td>\n",
       "      <td>0.982013</td>\n",
       "      <td>0.908879</td>\n",
       "      <td>0.944032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.126695</td>\n",
       "      <td>0.954166</td>\n",
       "      <td>0.965301</td>\n",
       "      <td>0.942465</td>\n",
       "      <td>0.953746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for llama4 fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.178019</td>\n",
       "      <td>0.935862</td>\n",
       "      <td>0.923445</td>\n",
       "      <td>0.951842</td>\n",
       "      <td>0.937429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.138071</td>\n",
       "      <td>0.950505</td>\n",
       "      <td>0.968646</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.950030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>0.136102</td>\n",
       "      <td>0.952555</td>\n",
       "      <td>0.976212</td>\n",
       "      <td>0.928634</td>\n",
       "      <td>0.951829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.125708</td>\n",
       "      <td>0.957388</td>\n",
       "      <td>0.973589</td>\n",
       "      <td>0.941108</td>\n",
       "      <td>0.957073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for llama4 fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.176100</td>\n",
       "      <td>0.164689</td>\n",
       "      <td>0.939669</td>\n",
       "      <td>0.971987</td>\n",
       "      <td>0.901511</td>\n",
       "      <td>0.935423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.156600</td>\n",
       "      <td>0.127986</td>\n",
       "      <td>0.955338</td>\n",
       "      <td>0.966181</td>\n",
       "      <td>0.940785</td>\n",
       "      <td>0.953314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.128757</td>\n",
       "      <td>0.956216</td>\n",
       "      <td>0.948199</td>\n",
       "      <td>0.962236</td>\n",
       "      <td>0.955166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.113413</td>\n",
       "      <td>0.959291</td>\n",
       "      <td>0.956077</td>\n",
       "      <td>0.960121</td>\n",
       "      <td>0.958095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for llama4 fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.191200</td>\n",
       "      <td>0.151786</td>\n",
       "      <td>0.945819</td>\n",
       "      <td>0.940115</td>\n",
       "      <td>0.953225</td>\n",
       "      <td>0.946624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.125562</td>\n",
       "      <td>0.959438</td>\n",
       "      <td>0.967228</td>\n",
       "      <td>0.951772</td>\n",
       "      <td>0.959438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.120363</td>\n",
       "      <td>0.957680</td>\n",
       "      <td>0.945465</td>\n",
       "      <td>0.972109</td>\n",
       "      <td>0.958602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.103387</td>\n",
       "      <td>0.967199</td>\n",
       "      <td>0.976882</td>\n",
       "      <td>0.957583</td>\n",
       "      <td>0.967136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for llama4 fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.205100</td>\n",
       "      <td>0.171680</td>\n",
       "      <td>0.940548</td>\n",
       "      <td>0.941349</td>\n",
       "      <td>0.939696</td>\n",
       "      <td>0.940522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.161918</td>\n",
       "      <td>0.944794</td>\n",
       "      <td>0.930088</td>\n",
       "      <td>0.961944</td>\n",
       "      <td>0.945748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.120652</td>\n",
       "      <td>0.959584</td>\n",
       "      <td>0.969498</td>\n",
       "      <td>0.949063</td>\n",
       "      <td>0.959172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>0.115851</td>\n",
       "      <td>0.961634</td>\n",
       "      <td>0.973289</td>\n",
       "      <td>0.949356</td>\n",
       "      <td>0.961174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for llama4 fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.161108</td>\n",
       "      <td>0.943916</td>\n",
       "      <td>0.956548</td>\n",
       "      <td>0.931324</td>\n",
       "      <td>0.943767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.141040</td>\n",
       "      <td>0.950798</td>\n",
       "      <td>0.972399</td>\n",
       "      <td>0.929006</td>\n",
       "      <td>0.950207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.126784</td>\n",
       "      <td>0.954312</td>\n",
       "      <td>0.959590</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.954559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.124174</td>\n",
       "      <td>0.955777</td>\n",
       "      <td>0.968462</td>\n",
       "      <td>0.943205</td>\n",
       "      <td>0.955666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for llama4 fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.176186</td>\n",
       "      <td>0.937033</td>\n",
       "      <td>0.926050</td>\n",
       "      <td>0.952189</td>\n",
       "      <td>0.938938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>0.129936</td>\n",
       "      <td>0.955191</td>\n",
       "      <td>0.967790</td>\n",
       "      <td>0.943260</td>\n",
       "      <td>0.955368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.140600</td>\n",
       "      <td>0.121814</td>\n",
       "      <td>0.958120</td>\n",
       "      <td>0.961204</td>\n",
       "      <td>0.956221</td>\n",
       "      <td>0.958706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.123400</td>\n",
       "      <td>0.114838</td>\n",
       "      <td>0.961634</td>\n",
       "      <td>0.973172</td>\n",
       "      <td>0.950749</td>\n",
       "      <td>0.961830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.9596±0.0037 | F1: 0.9592±0.0038\n",
      "\n",
      "Processing feature: annotation\n",
      "  Fold 1/10\n",
      "    No cached model found for annotation fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.249539</td>\n",
       "      <td>0.909663</td>\n",
       "      <td>0.885411</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>0.911261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.188467</td>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.942814</td>\n",
       "      <td>0.923259</td>\n",
       "      <td>0.932934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.180557</td>\n",
       "      <td>0.930893</td>\n",
       "      <td>0.920847</td>\n",
       "      <td>0.941037</td>\n",
       "      <td>0.930832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.158873</td>\n",
       "      <td>0.940703</td>\n",
       "      <td>0.958616</td>\n",
       "      <td>0.919704</td>\n",
       "      <td>0.938757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for annotation fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.254800</td>\n",
       "      <td>0.231830</td>\n",
       "      <td>0.913470</td>\n",
       "      <td>0.914184</td>\n",
       "      <td>0.910116</td>\n",
       "      <td>0.912145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.219524</td>\n",
       "      <td>0.921083</td>\n",
       "      <td>0.963654</td>\n",
       "      <td>0.873035</td>\n",
       "      <td>0.916109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.191747</td>\n",
       "      <td>0.930454</td>\n",
       "      <td>0.925382</td>\n",
       "      <td>0.934441</td>\n",
       "      <td>0.929889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.179606</td>\n",
       "      <td>0.935578</td>\n",
       "      <td>0.950507</td>\n",
       "      <td>0.917235</td>\n",
       "      <td>0.933575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for annotation fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>0.236020</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.932701</td>\n",
       "      <td>0.886853</td>\n",
       "      <td>0.909199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.196895</td>\n",
       "      <td>0.925611</td>\n",
       "      <td>0.930123</td>\n",
       "      <td>0.921466</td>\n",
       "      <td>0.925774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.173719</td>\n",
       "      <td>0.934983</td>\n",
       "      <td>0.942637</td>\n",
       "      <td>0.927283</td>\n",
       "      <td>0.934897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>0.938937</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.928447</td>\n",
       "      <td>0.938685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for annotation fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.225440</td>\n",
       "      <td>0.916532</td>\n",
       "      <td>0.957079</td>\n",
       "      <td>0.872664</td>\n",
       "      <td>0.912924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.184106</td>\n",
       "      <td>0.930444</td>\n",
       "      <td>0.922614</td>\n",
       "      <td>0.940129</td>\n",
       "      <td>0.931289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.160975</td>\n",
       "      <td>0.940401</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.926110</td>\n",
       "      <td>0.939695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.155825</td>\n",
       "      <td>0.943330</td>\n",
       "      <td>0.948067</td>\n",
       "      <td>0.938376</td>\n",
       "      <td>0.943197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for annotation fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.228900</td>\n",
       "      <td>0.221784</td>\n",
       "      <td>0.917850</td>\n",
       "      <td>0.923664</td>\n",
       "      <td>0.912678</td>\n",
       "      <td>0.918138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.190014</td>\n",
       "      <td>0.930883</td>\n",
       "      <td>0.962100</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.929193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.172308</td>\n",
       "      <td>0.936740</td>\n",
       "      <td>0.958625</td>\n",
       "      <td>0.914128</td>\n",
       "      <td>0.935848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.174760</td>\n",
       "      <td>0.936301</td>\n",
       "      <td>0.973287</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.934379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for annotation fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>0.248560</td>\n",
       "      <td>0.902328</td>\n",
       "      <td>0.909767</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.897934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.197424</td>\n",
       "      <td>0.926636</td>\n",
       "      <td>0.938769</td>\n",
       "      <td>0.907855</td>\n",
       "      <td>0.923053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.180065</td>\n",
       "      <td>0.931322</td>\n",
       "      <td>0.938020</td>\n",
       "      <td>0.919033</td>\n",
       "      <td>0.928430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.171060</td>\n",
       "      <td>0.933958</td>\n",
       "      <td>0.947979</td>\n",
       "      <td>0.913897</td>\n",
       "      <td>0.930626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for annotation fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.228288</td>\n",
       "      <td>0.914482</td>\n",
       "      <td>0.938344</td>\n",
       "      <td>0.888727</td>\n",
       "      <td>0.912862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.197104</td>\n",
       "      <td>0.927954</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.922429</td>\n",
       "      <td>0.928091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.175032</td>\n",
       "      <td>0.935276</td>\n",
       "      <td>0.951264</td>\n",
       "      <td>0.918652</td>\n",
       "      <td>0.934673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.166469</td>\n",
       "      <td>0.939083</td>\n",
       "      <td>0.966687</td>\n",
       "      <td>0.910517</td>\n",
       "      <td>0.937762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for annotation fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>0.238214</td>\n",
       "      <td>0.909943</td>\n",
       "      <td>0.934803</td>\n",
       "      <td>0.881440</td>\n",
       "      <td>0.907338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.196319</td>\n",
       "      <td>0.928979</td>\n",
       "      <td>0.956969</td>\n",
       "      <td>0.898419</td>\n",
       "      <td>0.926770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.175843</td>\n",
       "      <td>0.933519</td>\n",
       "      <td>0.942883</td>\n",
       "      <td>0.923009</td>\n",
       "      <td>0.932840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.167554</td>\n",
       "      <td>0.937326</td>\n",
       "      <td>0.962825</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.935581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for annotation fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.222328</td>\n",
       "      <td>0.916093</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.890177</td>\n",
       "      <td>0.914694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.181193</td>\n",
       "      <td>0.935569</td>\n",
       "      <td>0.939306</td>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.936028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.170431</td>\n",
       "      <td>0.939962</td>\n",
       "      <td>0.966268</td>\n",
       "      <td>0.913069</td>\n",
       "      <td>0.938915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.158092</td>\n",
       "      <td>0.942744</td>\n",
       "      <td>0.961399</td>\n",
       "      <td>0.923790</td>\n",
       "      <td>0.942220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for annotation fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.224705</td>\n",
       "      <td>0.916386</td>\n",
       "      <td>0.932082</td>\n",
       "      <td>0.901210</td>\n",
       "      <td>0.916386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.193702</td>\n",
       "      <td>0.930444</td>\n",
       "      <td>0.952309</td>\n",
       "      <td>0.908698</td>\n",
       "      <td>0.929993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.192400</td>\n",
       "      <td>0.173701</td>\n",
       "      <td>0.937912</td>\n",
       "      <td>0.950888</td>\n",
       "      <td>0.925691</td>\n",
       "      <td>0.938120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.169993</td>\n",
       "      <td>0.937180</td>\n",
       "      <td>0.966575</td>\n",
       "      <td>0.907834</td>\n",
       "      <td>0.936284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.9386±0.0029 | F1: 0.9373±0.0036\n",
      "\n",
      "Processing feature: abstract\n",
      "  Fold 1/10\n",
      "    No cached model found for abstract fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.144475</td>\n",
       "      <td>0.950220</td>\n",
       "      <td>0.920943</td>\n",
       "      <td>0.983704</td>\n",
       "      <td>0.951289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>0.979209</td>\n",
       "      <td>0.980958</td>\n",
       "      <td>0.976889</td>\n",
       "      <td>0.978919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.062204</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.979351</td>\n",
       "      <td>0.983704</td>\n",
       "      <td>0.981523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.055013</td>\n",
       "      <td>0.983163</td>\n",
       "      <td>0.983967</td>\n",
       "      <td>0.981926</td>\n",
       "      <td>0.982945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for abstract fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.114086</td>\n",
       "      <td>0.959590</td>\n",
       "      <td>0.973097</td>\n",
       "      <td>0.944230</td>\n",
       "      <td>0.958446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.076906</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>0.970580</td>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.974594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.063834</td>\n",
       "      <td>0.979941</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.985464</td>\n",
       "      <td>0.979796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.062969</td>\n",
       "      <td>0.981991</td>\n",
       "      <td>0.982185</td>\n",
       "      <td>0.981311</td>\n",
       "      <td>0.981748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for abstract fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.109970</td>\n",
       "      <td>0.962220</td>\n",
       "      <td>0.978916</td>\n",
       "      <td>0.945317</td>\n",
       "      <td>0.961823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.074526</td>\n",
       "      <td>0.973203</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>0.973605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.985503</td>\n",
       "      <td>0.986593</td>\n",
       "      <td>0.984584</td>\n",
       "      <td>0.985587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.043904</td>\n",
       "      <td>0.985357</td>\n",
       "      <td>0.989730</td>\n",
       "      <td>0.981094</td>\n",
       "      <td>0.985393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for abstract fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.100765</td>\n",
       "      <td>0.963538</td>\n",
       "      <td>0.962424</td>\n",
       "      <td>0.964953</td>\n",
       "      <td>0.963687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.073258</td>\n",
       "      <td>0.974228</td>\n",
       "      <td>0.979905</td>\n",
       "      <td>0.968458</td>\n",
       "      <td>0.974148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.061766</td>\n",
       "      <td>0.978913</td>\n",
       "      <td>0.986358</td>\n",
       "      <td>0.971379</td>\n",
       "      <td>0.978811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>0.982721</td>\n",
       "      <td>0.981924</td>\n",
       "      <td>0.983645</td>\n",
       "      <td>0.982784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for abstract fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.111551</td>\n",
       "      <td>0.964124</td>\n",
       "      <td>0.951749</td>\n",
       "      <td>0.978532</td>\n",
       "      <td>0.964955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.089762</td>\n",
       "      <td>0.970860</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.978822</td>\n",
       "      <td>0.971355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.064326</td>\n",
       "      <td>0.979499</td>\n",
       "      <td>0.975827</td>\n",
       "      <td>0.983754</td>\n",
       "      <td>0.979775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.059677</td>\n",
       "      <td>0.983453</td>\n",
       "      <td>0.980681</td>\n",
       "      <td>0.986655</td>\n",
       "      <td>0.983659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for abstract fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.102068</td>\n",
       "      <td>0.962659</td>\n",
       "      <td>0.973057</td>\n",
       "      <td>0.949245</td>\n",
       "      <td>0.961003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.069789</td>\n",
       "      <td>0.977010</td>\n",
       "      <td>0.978452</td>\n",
       "      <td>0.974018</td>\n",
       "      <td>0.976230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.059580</td>\n",
       "      <td>0.980085</td>\n",
       "      <td>0.977724</td>\n",
       "      <td>0.981269</td>\n",
       "      <td>0.979493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.053397</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>0.982743</td>\n",
       "      <td>0.980665</td>\n",
       "      <td>0.981703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for abstract fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.097671</td>\n",
       "      <td>0.965441</td>\n",
       "      <td>0.965447</td>\n",
       "      <td>0.966008</td>\n",
       "      <td>0.965728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.068281</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>0.970807</td>\n",
       "      <td>0.985474</td>\n",
       "      <td>0.978085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.050088</td>\n",
       "      <td>0.984332</td>\n",
       "      <td>0.986293</td>\n",
       "      <td>0.982568</td>\n",
       "      <td>0.984427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.048498</td>\n",
       "      <td>0.986235</td>\n",
       "      <td>0.986345</td>\n",
       "      <td>0.986345</td>\n",
       "      <td>0.986345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for abstract fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.124458</td>\n",
       "      <td>0.954459</td>\n",
       "      <td>0.933054</td>\n",
       "      <td>0.979215</td>\n",
       "      <td>0.955578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.983041</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.975063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.060822</td>\n",
       "      <td>0.980964</td>\n",
       "      <td>0.982384</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.980944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.061258</td>\n",
       "      <td>0.981110</td>\n",
       "      <td>0.988991</td>\n",
       "      <td>0.973068</td>\n",
       "      <td>0.980965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for abstract fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.114516</td>\n",
       "      <td>0.957827</td>\n",
       "      <td>0.962833</td>\n",
       "      <td>0.953347</td>\n",
       "      <td>0.958066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.080973</td>\n",
       "      <td>0.971445</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.975369</td>\n",
       "      <td>0.971849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.085760</td>\n",
       "      <td>0.973788</td>\n",
       "      <td>0.958520</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.974498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>0.982428</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.985801</td>\n",
       "      <td>0.982669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for abstract fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 01:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.959291</td>\n",
       "      <td>0.948092</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.960489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.083727</td>\n",
       "      <td>0.972324</td>\n",
       "      <td>0.971560</td>\n",
       "      <td>0.974078</td>\n",
       "      <td>0.972817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.074588</td>\n",
       "      <td>0.976278</td>\n",
       "      <td>0.965672</td>\n",
       "      <td>0.988479</td>\n",
       "      <td>0.976943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.054834</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>0.983271</td>\n",
       "      <td>0.981855</td>\n",
       "      <td>0.982562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.9831±0.0015 | F1: 0.9831±0.0016\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.976088</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.980250</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.971742</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.975969</td>\n",
       "      <td>0.002796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.959629</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.970418</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>0.948219</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.959155</td>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.938558</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.918376</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.937253</td>\n",
       "      <td>0.003574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.983087</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.983279</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.982880</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.983075</td>\n",
       "      <td>0.001585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  \\\n",
       "0      gemma3       0.976088      0.002677        0.980250       0.003342   \n",
       "1      llama4       0.959629      0.003688        0.970418       0.006370   \n",
       "2  annotation       0.938558      0.002865        0.957043       0.007134   \n",
       "3    abstract       0.983087      0.001509        0.983279       0.002761   \n",
       "\n",
       "   Recall_mean  Recall_std   F1_mean    F1_std  \n",
       "0     0.971742    0.004663  0.975969  0.002796  \n",
       "1     0.948219    0.007364  0.959155  0.003755  \n",
       "2     0.918376    0.009043  0.937253  0.003574  \n",
       "3     0.982880    0.002434  0.983075  0.001585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 设定设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 评价指标\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds),\n",
    "        'recall': recall_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "class TitlePairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, titles, contents, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(\n",
    "            titles, contents,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def get_best_checkpoint_dir(output_dir):\n",
    "    # 查找所有保存的checkpoint目录\n",
    "    checkpoint_dirs = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))\n",
    "    if not checkpoint_dirs:\n",
    "        return None\n",
    "    # 选最大编号的checkpoint（也可以自定义选择策略）\n",
    "    best_ckpt = max(checkpoint_dirs, key=lambda x: int(x.split('-')[-1]))\n",
    "    # 检查里面是否有权重文件\n",
    "    model_files = [\"model.safetensors\", \"pytorch_model.bin\"]\n",
    "    for mf in model_files:\n",
    "        if os.path.exists(os.path.join(best_ckpt, mf)):\n",
    "            return best_ckpt\n",
    "    return None\n",
    "\n",
    "# 配置\n",
    "text_features = models + ['annotation', 'abstract']\n",
    "y = title_match_df['title_paired'].astype(int).values\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "for feat in text_features:\n",
    "    print(f\"\\nProcessing feature: {feat}\")\n",
    "    X_title = title_match_df['title'].astype(str).fillna('').tolist()\n",
    "    X_content = title_match_df[feat].astype(str).fillna('').tolist()\n",
    "    labels = y\n",
    "\n",
    "    fold_metrics = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(X_title)):\n",
    "        print(f\"  Fold {fold+1}/10\")\n",
    "\n",
    "        train_titles = [X_title[i] for i in train_idx]\n",
    "        train_contents = [X_content[i] for i in train_idx]\n",
    "        train_labels = labels[train_idx]\n",
    "\n",
    "        test_titles = [X_title[i] for i in test_idx]\n",
    "        test_contents = [X_content[i] for i in test_idx]\n",
    "        test_labels = labels[test_idx]\n",
    "\n",
    "        train_dataset = TitlePairDataset(train_titles, train_contents, train_labels, tokenizer)\n",
    "        test_dataset = TitlePairDataset(test_titles, test_contents, test_labels, tokenizer)\n",
    "\n",
    "        output_dir = home / f'projects/TLDR/evaluation/predict_task/sent_shuffle/cached_title_distilbert_{feat}' / f'fold_{fold}'\n",
    "        output_dir_str = str(output_dir)\n",
    "        best_ckpt = get_best_checkpoint_dir(output_dir_str)\n",
    "        if best_ckpt is not None:\n",
    "            print(f\"    Cached model detected for {feat} fold {fold} at {best_ckpt}, loading and evaluating...\")\n",
    "            model = DistilBertForSequenceClassification.from_pretrained(best_ckpt, num_labels=2).to(device)\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=TrainingArguments(\n",
    "                    output_dir=output_dir_str,\n",
    "                    per_device_eval_batch_size=32,\n",
    "                    report_to=[],\n",
    "                    seed=42+fold\n",
    "                ),\n",
    "                eval_dataset=test_dataset,\n",
    "                compute_metrics=compute_metrics,\n",
    "            )\n",
    "            eval_result = trainer.evaluate()\n",
    "            fold_metrics.append(eval_result)\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        print(f\"    No cached model found for {feat} fold {fold}, training...\")\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=32,\n",
    "            eval_strategy='steps',\n",
    "            eval_steps=200,\n",
    "            save_strategy='steps',\n",
    "            save_steps=200,\n",
    "            save_total_limit=1,\n",
    "            learning_rate=2e-5,\n",
    "            logging_steps=50,\n",
    "            report_to=[],\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='eval_loss',\n",
    "            greater_is_better=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=test_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        eval_result = trainer.evaluate()\n",
    "        fold_metrics.append(eval_result)\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy_mean': np.mean([m['eval_accuracy'] for m in fold_metrics]),\n",
    "        'Accuracy_std': np.std([m['eval_accuracy'] for m in fold_metrics]),\n",
    "        'Precision_mean': np.mean([m['eval_precision'] for m in fold_metrics]),\n",
    "        'Precision_std': np.std([m['eval_precision'] for m in fold_metrics]),\n",
    "        'Recall_mean': np.mean([m['eval_recall'] for m in fold_metrics]),\n",
    "        'Recall_std': np.std([m['eval_recall'] for m in fold_metrics]),\n",
    "        'F1_mean': np.mean([m['eval_f1'] for m in fold_metrics]),\n",
    "        'F1_std': np.std([m['eval_f1'] for m in fold_metrics]),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy_mean']:.4f}±{res['Accuracy_std']:.4f} | \"\n",
    "        f\"F1: {res['F1_mean']:.4f}±{res['F1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53552de0",
   "metadata": {},
   "source": [
    "### No CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fbaef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 01:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.098041</td>\n",
       "      <td>0.967274</td>\n",
       "      <td>0.978842</td>\n",
       "      <td>0.955191</td>\n",
       "      <td>0.966872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.080129</td>\n",
       "      <td>0.975108</td>\n",
       "      <td>0.981166</td>\n",
       "      <td>0.968809</td>\n",
       "      <td>0.974948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.076666</td>\n",
       "      <td>0.974596</td>\n",
       "      <td>0.973415</td>\n",
       "      <td>0.975838</td>\n",
       "      <td>0.974625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.070916</td>\n",
       "      <td>0.976645</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.976611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.9763 | F1: 0.9762\n",
      "\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 01:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.166034</td>\n",
       "      <td>0.940040</td>\n",
       "      <td>0.955717</td>\n",
       "      <td>0.922829</td>\n",
       "      <td>0.938985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.149244</td>\n",
       "      <td>0.947580</td>\n",
       "      <td>0.941499</td>\n",
       "      <td>0.954459</td>\n",
       "      <td>0.947935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.129424</td>\n",
       "      <td>0.954975</td>\n",
       "      <td>0.954107</td>\n",
       "      <td>0.955923</td>\n",
       "      <td>0.955014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.120594</td>\n",
       "      <td>0.958196</td>\n",
       "      <td>0.963968</td>\n",
       "      <td>0.951970</td>\n",
       "      <td>0.957931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.9581 | F1: 0.9576\n",
      "\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 01:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.217543</td>\n",
       "      <td>0.918222</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.899692</td>\n",
       "      <td>0.916673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.190222</td>\n",
       "      <td>0.928545</td>\n",
       "      <td>0.935686</td>\n",
       "      <td>0.920340</td>\n",
       "      <td>0.927949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.176155</td>\n",
       "      <td>0.935134</td>\n",
       "      <td>0.966410</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.932879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.168881</td>\n",
       "      <td>0.938429</td>\n",
       "      <td>0.953774</td>\n",
       "      <td>0.921511</td>\n",
       "      <td>0.937365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.9393 | F1: 0.9383\n",
      "\n",
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 01:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.963248</td>\n",
       "      <td>0.959611</td>\n",
       "      <td>0.967199</td>\n",
       "      <td>0.963390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.082622</td>\n",
       "      <td>0.974742</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.972910</td>\n",
       "      <td>0.974694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.068250</td>\n",
       "      <td>0.980233</td>\n",
       "      <td>0.984918</td>\n",
       "      <td>0.975399</td>\n",
       "      <td>0.980135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.069009</td>\n",
       "      <td>0.979647</td>\n",
       "      <td>0.972451</td>\n",
       "      <td>0.987260</td>\n",
       "      <td>0.979799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.9813 | F1: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.976279</td>\n",
       "      <td>0.978238</td>\n",
       "      <td>0.974228</td>\n",
       "      <td>0.976229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.958123</td>\n",
       "      <td>0.969815</td>\n",
       "      <td>0.945673</td>\n",
       "      <td>0.957592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.939307</td>\n",
       "      <td>0.954133</td>\n",
       "      <td>0.922976</td>\n",
       "      <td>0.938295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.981331</td>\n",
       "      <td>0.978179</td>\n",
       "      <td>0.984624</td>\n",
       "      <td>0.981391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  Accuracy  Precision    Recall        F1\n",
       "0      gemma3  0.976279   0.978238  0.974228  0.976229\n",
       "1      llama4  0.958123   0.969815  0.945673  0.957592\n",
       "2  annotation  0.939307   0.954133  0.922976  0.938295\n",
       "3    abstract  0.981331   0.978179  0.984624  0.981391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设定设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 评价指标\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds),\n",
    "        'recall': recall_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "class TitlePairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, titles, contents, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(\n",
    "            titles, contents,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "text_features = models + ['annotation', 'abstract']\n",
    "y = title_match_df['title_paired'].astype(int).values\n",
    "results = []\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "for feat in text_features:\n",
    "    print(f\"\\nProcessing feature: {feat}\")\n",
    "    output_dir = home / f'projects/TLDR/evaluation/predict_task/cached_title_distilbert_{feat}' / 'no_cv'\n",
    "    output_dir_str = str(output_dir)\n",
    "    X_title = title_match_df['title'].astype(str).fillna('').tolist()\n",
    "    X_content = title_match_df[feat].astype(str).fillna('').tolist()\n",
    "    labels = y\n",
    "\n",
    "    # dataset split\n",
    "    train_titles, test_titles, train_contents, test_contents, train_labels, test_labels = train_test_split(\n",
    "        X_title, X_content, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    # construct datasets\n",
    "    train_dataset = TitlePairDataset(train_titles, train_contents, train_labels, tokenizer)\n",
    "    test_dataset = TitlePairDataset(test_titles, test_contents, test_labels, tokenizer)\n",
    "\n",
    "    # 新建模型\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir_str,\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        eval_strategy='steps',\n",
    "        eval_steps=200,\n",
    "        save_strategy='no',\n",
    "        learning_rate=2e-5,\n",
    "        logging_steps=50,\n",
    "        report_to=[],\n",
    "        load_best_model_at_end=False,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "\n",
    "    # 汇总\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy': eval_result['eval_accuracy'],\n",
    "        'Precision': eval_result['eval_precision'],\n",
    "        'Recall': eval_result['eval_recall'],\n",
    "        'F1': eval_result['eval_f1'],\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy']:.4f} | \"\n",
    "        f\"F1: {res['F1']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
