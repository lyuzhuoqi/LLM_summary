{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1ac11c",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a395ee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>deepseek_v3</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>qwq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study examines mtDNA sequences from tauri...</td>\n",
       "      <td>Reference 14 reports phylogenetic analysis of ...</td>\n",
       "      <td>These authors investigated the evolutionary hi...</td>\n",
       "      <td>This study uses mitochondrial DNA sequencing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study provides molecular evidence for the...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>These findings indicate that there has been ge...</td>\n",
       "      <td>This study provides molecular evidence for int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This study reports the fine-mapping of a QTL a...</td>\n",
       "      <td>This paper reports the fine-mapping of a QTL a...</td>\n",
       "      <td>Fine mapping a QTL for milk fat percentage on ...</td>\n",
       "      <td>This study refines the mapping of a quantitati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study provides an early genome-wide analy...</td>\n",
       "      <td>This paper reports an extensive LD map in dair...</td>\n",
       "      <td>This study evaluates the potential of LD mappi...</td>\n",
       "      <td>This study investigates linkage disequilibrium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This study reports the mapping of a major quan...</td>\n",
       "      <td>This study identifies a major QTL on chromosom...</td>\n",
       "      <td>This study identifies a major locus on pig chr...</td>\n",
       "      <td>This study identifies a major quantitative tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This study demonstrates the feasibility of iso...</td>\n",
       "      <td>Reference 51 describes an optimized method for...</td>\n",
       "      <td>These studies demonstrate the feasibility of t...</td>\n",
       "      <td>This study evaluates the expansion and functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study describes the engineering of orthog...</td>\n",
       "      <td>Reference 54 reports the successful engineerin...</td>\n",
       "      <td>This study demonstrates that a synthetic IL-2:...</td>\n",
       "      <td>This study introduces engineered synthetic IL-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies hybrid insulin peptides ...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells isolated from the pancreatic islets of...</td>\n",
       "      <td>This study identifies that T cells in type 1 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study describes a multiplex genome-editin...</td>\n",
       "      <td>This work describes a new method to render all...</td>\n",
       "      <td>This study provides evidence for genome-edited...</td>\n",
       "      <td>This study presents a multiplex genome-editing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study identifies and characterizes human ...</td>\n",
       "      <td>References 18 and 19 report the existence of a...</td>\n",
       "      <td>These results identify a population of regulat...</td>\n",
       "      <td>This study identifies human CD4+CD25high regul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35621 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                             deepseek_v3  \\\n",
       "0      This study examines mtDNA sequences from tauri...   \n",
       "1      This study provides molecular evidence for the...   \n",
       "2      This study reports the fine-mapping of a QTL a...   \n",
       "3      This study provides an early genome-wide analy...   \n",
       "4      This study reports the mapping of a major quan...   \n",
       "...                                                  ...   \n",
       "35631  This study demonstrates the feasibility of iso...   \n",
       "35632  This study describes the engineering of orthog...   \n",
       "35633  This study identifies hybrid insulin peptides ...   \n",
       "35634  This study describes a multiplex genome-editin...   \n",
       "35635  This study identifies and characterizes human ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      Reference 14 reports phylogenetic analysis of ...   \n",
       "1      This study demonstrates independent domesticat...   \n",
       "2      This paper reports the fine-mapping of a QTL a...   \n",
       "3      This paper reports an extensive LD map in dair...   \n",
       "4      This study identifies a major QTL on chromosom...   \n",
       "...                                                  ...   \n",
       "35631  Reference 51 describes an optimized method for...   \n",
       "35632  Reference 54 reports the successful engineerin...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This work describes a new method to render all...   \n",
       "35635  References 18 and 19 report the existence of a...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      These authors investigated the evolutionary hi...   \n",
       "1      These findings indicate that there has been ge...   \n",
       "2      Fine mapping a QTL for milk fat percentage on ...   \n",
       "3      This study evaluates the potential of LD mappi...   \n",
       "4      This study identifies a major locus on pig chr...   \n",
       "...                                                  ...   \n",
       "35631  These studies demonstrate the feasibility of t...   \n",
       "35632  This study demonstrates that a synthetic IL-2:...   \n",
       "35633  T cells isolated from the pancreatic islets of...   \n",
       "35634  This study provides evidence for genome-edited...   \n",
       "35635  These results identify a population of regulat...   \n",
       "\n",
       "                                                     qwq  \n",
       "0      This study uses mitochondrial DNA sequencing t...  \n",
       "1      This study provides molecular evidence for int...  \n",
       "2      This study refines the mapping of a quantitati...  \n",
       "3      This study investigates linkage disequilibrium...  \n",
       "4      This study identifies a major quantitative tra...  \n",
       "...                                                  ...  \n",
       "35631  This study evaluates the expansion and functio...  \n",
       "35632  This study introduces engineered synthetic IL-...  \n",
       "35633  This study identifies that T cells in type 1 d...  \n",
       "35634  This study presents a multiplex genome-editing...  \n",
       "35635  This study identifies human CD4+CD25high regul...  \n",
       "\n",
       "[35621 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "home = Path.home()\n",
    "\n",
    "# models = ['deepseek_v3', 'gemma3', 'llama4', 'qwq', 'qwen3']\n",
    "models = ['deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "\n",
    "# suffixes = None\n",
    "suffixes = '_sent_shuffle'\n",
    "# suffixes = '_tail'\n",
    "if suffixes is not None:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}_TLDR{suffixes}.txt' for model in models]\n",
    "else:\n",
    "    csv_files = [home / f'projects/TLDR/data/paper_html_10.1038/abs_annotation/generated_annotations/{model}_TLDR.txt' for model in models]\n",
    "\n",
    "df = pd.read_csv(home / 'projects/TLDR/data/paper_html_10.1038/abs_annotation/test.tsv', sep='\\t')\n",
    "for model, csv_file in zip(models, csv_files):\n",
    "    single_df = pd.read_csv(csv_file, sep='\\t', header=None, names=[model])\n",
    "    df = df.join(single_df)\n",
    "\n",
    "for index in pd.read_csv(home / \"projects/TLDR/description/invalid_entry_in_test.txt\", sep='\\t', header=None).values.flatten().tolist():\n",
    "    df = df.drop(index-2)  # Adjusting for zero-based index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c7b3f",
   "metadata": {},
   "source": [
    "# Load publication venue and year from MAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1b38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading doi_mag_pid_dict...\n",
      "doi_mag_pid_dict loaded.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>deepseek_v3</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>qwq</th>\n",
       "      <th>mag_pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study examines mtDNA sequences from tauri...</td>\n",
       "      <td>Reference 14 reports phylogenetic analysis of ...</td>\n",
       "      <td>These authors investigated the evolutionary hi...</td>\n",
       "      <td>This study uses mitochondrial DNA sequencing t...</td>\n",
       "      <td>2005395185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study provides molecular evidence for the...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>These findings indicate that there has been ge...</td>\n",
       "      <td>This study provides molecular evidence for int...</td>\n",
       "      <td>2110049233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This study reports the fine-mapping of a QTL a...</td>\n",
       "      <td>This paper reports the fine-mapping of a QTL a...</td>\n",
       "      <td>Fine mapping a QTL for milk fat percentage on ...</td>\n",
       "      <td>This study refines the mapping of a quantitati...</td>\n",
       "      <td>2082900742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study provides an early genome-wide analy...</td>\n",
       "      <td>This paper reports an extensive LD map in dair...</td>\n",
       "      <td>This study evaluates the potential of LD mappi...</td>\n",
       "      <td>This study investigates linkage disequilibrium...</td>\n",
       "      <td>2103106090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This study reports the mapping of a major quan...</td>\n",
       "      <td>This study identifies a major QTL on chromosom...</td>\n",
       "      <td>This study identifies a major locus on pig chr...</td>\n",
       "      <td>This study identifies a major quantitative tra...</td>\n",
       "      <td>2045457895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This study demonstrates the feasibility of iso...</td>\n",
       "      <td>Reference 51 describes an optimized method for...</td>\n",
       "      <td>These studies demonstrate the feasibility of t...</td>\n",
       "      <td>This study evaluates the expansion and functio...</td>\n",
       "      <td>2137227986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study describes the engineering of orthog...</td>\n",
       "      <td>Reference 54 reports the successful engineerin...</td>\n",
       "      <td>This study demonstrates that a synthetic IL-2:...</td>\n",
       "      <td>This study introduces engineered synthetic IL-...</td>\n",
       "      <td>2789780246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies hybrid insulin peptides ...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells isolated from the pancreatic islets of...</td>\n",
       "      <td>This study identifies that T cells in type 1 d...</td>\n",
       "      <td>2266478788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study describes a multiplex genome-editin...</td>\n",
       "      <td>This work describes a new method to render all...</td>\n",
       "      <td>This study provides evidence for genome-edited...</td>\n",
       "      <td>This study presents a multiplex genome-editing...</td>\n",
       "      <td>2943378944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study identifies and characterizes human ...</td>\n",
       "      <td>References 18 and 19 report the existence of a...</td>\n",
       "      <td>These results identify a population of regulat...</td>\n",
       "      <td>This study identifies human CD4+CD25high regul...</td>\n",
       "      <td>1560277370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34775 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                             deepseek_v3  \\\n",
       "0      This study examines mtDNA sequences from tauri...   \n",
       "1      This study provides molecular evidence for the...   \n",
       "2      This study reports the fine-mapping of a QTL a...   \n",
       "3      This study provides an early genome-wide analy...   \n",
       "4      This study reports the mapping of a major quan...   \n",
       "...                                                  ...   \n",
       "35631  This study demonstrates the feasibility of iso...   \n",
       "35632  This study describes the engineering of orthog...   \n",
       "35633  This study identifies hybrid insulin peptides ...   \n",
       "35634  This study describes a multiplex genome-editin...   \n",
       "35635  This study identifies and characterizes human ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      Reference 14 reports phylogenetic analysis of ...   \n",
       "1      This study demonstrates independent domesticat...   \n",
       "2      This paper reports the fine-mapping of a QTL a...   \n",
       "3      This paper reports an extensive LD map in dair...   \n",
       "4      This study identifies a major QTL on chromosom...   \n",
       "...                                                  ...   \n",
       "35631  Reference 51 describes an optimized method for...   \n",
       "35632  Reference 54 reports the successful engineerin...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This work describes a new method to render all...   \n",
       "35635  References 18 and 19 report the existence of a...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      These authors investigated the evolutionary hi...   \n",
       "1      These findings indicate that there has been ge...   \n",
       "2      Fine mapping a QTL for milk fat percentage on ...   \n",
       "3      This study evaluates the potential of LD mappi...   \n",
       "4      This study identifies a major locus on pig chr...   \n",
       "...                                                  ...   \n",
       "35631  These studies demonstrate the feasibility of t...   \n",
       "35632  This study demonstrates that a synthetic IL-2:...   \n",
       "35633  T cells isolated from the pancreatic islets of...   \n",
       "35634  This study provides evidence for genome-edited...   \n",
       "35635  These results identify a population of regulat...   \n",
       "\n",
       "                                                     qwq     mag_pid  \n",
       "0      This study uses mitochondrial DNA sequencing t...  2005395185  \n",
       "1      This study provides molecular evidence for int...  2110049233  \n",
       "2      This study refines the mapping of a quantitati...  2082900742  \n",
       "3      This study investigates linkage disequilibrium...  2103106090  \n",
       "4      This study identifies a major quantitative tra...  2045457895  \n",
       "...                                                  ...         ...  \n",
       "35631  This study evaluates the expansion and functio...  2137227986  \n",
       "35632  This study introduces engineered synthetic IL-...  2789780246  \n",
       "35633  This study identifies that T cells in type 1 d...  2266478788  \n",
       "35634  This study presents a multiplex genome-editing...  2943378944  \n",
       "35635  This study identifies human CD4+CD25high regul...  1560277370  \n",
       "\n",
       "[34775 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "print(\"Loading doi_mag_pid_dict...\")\n",
    "with open(home / \"projects/TLDR/data/doi_mag_pid_dict.pkl\", \"rb\") as f:\n",
    "    doi_mag_pid_dict = pickle.load(f)\n",
    "    print(\"doi_mag_pid_dict loaded.\")\n",
    "\n",
    "df['mag_pid'] = df['doi'].map(doi_mag_pid_dict)\n",
    "df = df.dropna(subset=['mag_pid'])\n",
    "df.loc[:, 'mag_pid'] = df['mag_pid'].apply(lambda x: x.split(';')[0] if isinstance(x, str) else x)\n",
    "df.loc[:, 'mag_pid'] = df['mag_pid'].astype(int)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01563aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>deepseek_v3</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>qwq</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study examines mtDNA sequences from tauri...</td>\n",
       "      <td>Reference 14 reports phylogenetic analysis of ...</td>\n",
       "      <td>These authors investigated the evolutionary hi...</td>\n",
       "      <td>This study uses mitochondrial DNA sequencing t...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study provides molecular evidence for the...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>These findings indicate that there has been ge...</td>\n",
       "      <td>This study provides molecular evidence for int...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This study reports the fine-mapping of a QTL a...</td>\n",
       "      <td>This paper reports the fine-mapping of a QTL a...</td>\n",
       "      <td>Fine mapping a QTL for milk fat percentage on ...</td>\n",
       "      <td>This study refines the mapping of a quantitati...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study provides an early genome-wide analy...</td>\n",
       "      <td>This paper reports an extensive LD map in dair...</td>\n",
       "      <td>This study evaluates the potential of LD mappi...</td>\n",
       "      <td>This study investigates linkage disequilibrium...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This study reports the mapping of a major quan...</td>\n",
       "      <td>This study identifies a major QTL on chromosom...</td>\n",
       "      <td>This study identifies a major locus on pig chr...</td>\n",
       "      <td>This study identifies a major quantitative tra...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This study demonstrates the feasibility of iso...</td>\n",
       "      <td>Reference 51 describes an optimized method for...</td>\n",
       "      <td>These studies demonstrate the feasibility of t...</td>\n",
       "      <td>This study evaluates the expansion and functio...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study describes the engineering of orthog...</td>\n",
       "      <td>Reference 54 reports the successful engineerin...</td>\n",
       "      <td>This study demonstrates that a synthetic IL-2:...</td>\n",
       "      <td>This study introduces engineered synthetic IL-...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies hybrid insulin peptides ...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells isolated from the pancreatic islets of...</td>\n",
       "      <td>This study identifies that T cells in type 1 d...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study describes a multiplex genome-editin...</td>\n",
       "      <td>This work describes a new method to render all...</td>\n",
       "      <td>This study provides evidence for genome-edited...</td>\n",
       "      <td>This study presents a multiplex genome-editing...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study identifies and characterizes human ...</td>\n",
       "      <td>References 18 and 19 report the existence of a...</td>\n",
       "      <td>These results identify a population of regulat...</td>\n",
       "      <td>This study identifies human CD4+CD25high regul...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34262 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                             deepseek_v3  \\\n",
       "0      This study examines mtDNA sequences from tauri...   \n",
       "1      This study provides molecular evidence for the...   \n",
       "2      This study reports the fine-mapping of a QTL a...   \n",
       "3      This study provides an early genome-wide analy...   \n",
       "4      This study reports the mapping of a major quan...   \n",
       "...                                                  ...   \n",
       "35631  This study demonstrates the feasibility of iso...   \n",
       "35632  This study describes the engineering of orthog...   \n",
       "35633  This study identifies hybrid insulin peptides ...   \n",
       "35634  This study describes a multiplex genome-editin...   \n",
       "35635  This study identifies and characterizes human ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      Reference 14 reports phylogenetic analysis of ...   \n",
       "1      This study demonstrates independent domesticat...   \n",
       "2      This paper reports the fine-mapping of a QTL a...   \n",
       "3      This paper reports an extensive LD map in dair...   \n",
       "4      This study identifies a major QTL on chromosom...   \n",
       "...                                                  ...   \n",
       "35631  Reference 51 describes an optimized method for...   \n",
       "35632  Reference 54 reports the successful engineerin...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This work describes a new method to render all...   \n",
       "35635  References 18 and 19 report the existence of a...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      These authors investigated the evolutionary hi...   \n",
       "1      These findings indicate that there has been ge...   \n",
       "2      Fine mapping a QTL for milk fat percentage on ...   \n",
       "3      This study evaluates the potential of LD mappi...   \n",
       "4      This study identifies a major locus on pig chr...   \n",
       "...                                                  ...   \n",
       "35631  These studies demonstrate the feasibility of t...   \n",
       "35632  This study demonstrates that a synthetic IL-2:...   \n",
       "35633  T cells isolated from the pancreatic islets of...   \n",
       "35634  This study provides evidence for genome-edited...   \n",
       "35635  These results identify a population of regulat...   \n",
       "\n",
       "                                                     qwq     mag_pid  \\\n",
       "0      This study uses mitochondrial DNA sequencing t...  2005395185   \n",
       "1      This study provides molecular evidence for int...  2110049233   \n",
       "2      This study refines the mapping of a quantitati...  2082900742   \n",
       "3      This study investigates linkage disequilibrium...  2103106090   \n",
       "4      This study identifies a major quantitative tra...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "35631  This study evaluates the expansion and functio...  2137227986   \n",
       "35632  This study introduces engineered synthetic IL-...  2789780246   \n",
       "35633  This study identifies that T cells in type 1 d...  2266478788   \n",
       "35634  This study presents a multiplex genome-editing...  2943378944   \n",
       "35635  This study identifies human CD4+CD25high regul...  1560277370   \n",
       "\n",
       "         mag_vid  year  \n",
       "0      125754415  1994  \n",
       "1       65932378  2000  \n",
       "2      125754415  1999  \n",
       "3       43092948  2000  \n",
       "4        3880285  1994  \n",
       "...          ...   ...  \n",
       "35631  129060628  2009  \n",
       "35632    3880285  2018  \n",
       "35633    3880285  2016  \n",
       "35634  125754415  2019  \n",
       "35635   38008053  2001  \n",
       "\n",
       "[34262 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAG_paper_df = pd.read_parquet(home / 'projects/TLDR/data/MAG_paper.parquet')\n",
    "df = df.merge(MAG_paper_df[['VenueID', 'Year']], left_on='mag_pid', right_index=True, how='inner')\n",
    "df.rename(columns={'VenueID': 'mag_vid', 'Year': 'year'}, inplace=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd1e4d",
   "metadata": {},
   "source": [
    "# Load subject label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc271ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scopus_label</th>\n",
       "      <th>movMF_label</th>\n",
       "      <th>movMF_distance</th>\n",
       "      <th>x_val</th>\n",
       "      <th>y_val</th>\n",
       "      <th>kmeans_label</th>\n",
       "      <th>kmeans_distance</th>\n",
       "      <th>skm_label</th>\n",
       "      <th>skm_distance</th>\n",
       "      <th>spectral_label</th>\n",
       "      <th>n2v_kmeans_label</th>\n",
       "      <th>cm_kmeans_label</th>\n",
       "      <th>gnn_kmeans_label</th>\n",
       "      <th>bert_kmeans_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202381698</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.445886</td>\n",
       "      <td>-67.928200</td>\n",
       "      <td>15.572327</td>\n",
       "      <td>17</td>\n",
       "      <td>0.628846</td>\n",
       "      <td>20</td>\n",
       "      <td>0.444711</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137773608</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>-68.405334</td>\n",
       "      <td>-55.633186</td>\n",
       "      <td>17</td>\n",
       "      <td>0.735654</td>\n",
       "      <td>20</td>\n",
       "      <td>0.559494</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125754415</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>22</td>\n",
       "      <td>0.574571</td>\n",
       "      <td>-68.448853</td>\n",
       "      <td>-55.613579</td>\n",
       "      <td>17</td>\n",
       "      <td>0.705024</td>\n",
       "      <td>20</td>\n",
       "      <td>0.550081</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880285</th>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>23</td>\n",
       "      <td>0.618842</td>\n",
       "      <td>-68.407288</td>\n",
       "      <td>-55.634430</td>\n",
       "      <td>8</td>\n",
       "      <td>0.724859</td>\n",
       "      <td>17</td>\n",
       "      <td>0.610582</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111155417</th>\n",
       "      <td>Chemistry</td>\n",
       "      <td>23</td>\n",
       "      <td>0.220853</td>\n",
       "      <td>-54.506985</td>\n",
       "      <td>-61.217068</td>\n",
       "      <td>11</td>\n",
       "      <td>0.495787</td>\n",
       "      <td>12</td>\n",
       "      <td>0.198758</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2764485818</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>21</td>\n",
       "      <td>0.268070</td>\n",
       "      <td>-28.969574</td>\n",
       "      <td>34.819569</td>\n",
       "      <td>18</td>\n",
       "      <td>0.542531</td>\n",
       "      <td>14</td>\n",
       "      <td>0.251015</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83454320</th>\n",
       "      <td>Arts and Humanities</td>\n",
       "      <td>25</td>\n",
       "      <td>0.034777</td>\n",
       "      <td>78.609909</td>\n",
       "      <td>31.736822</td>\n",
       "      <td>13</td>\n",
       "      <td>0.251599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056642</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16507453</th>\n",
       "      <td>Arts and Humanities</td>\n",
       "      <td>6</td>\n",
       "      <td>0.113656</td>\n",
       "      <td>89.206772</td>\n",
       "      <td>17.625090</td>\n",
       "      <td>13</td>\n",
       "      <td>0.307089</td>\n",
       "      <td>3</td>\n",
       "      <td>0.128660</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121509672</th>\n",
       "      <td>Agricultural and Biological Sciences</td>\n",
       "      <td>5</td>\n",
       "      <td>0.179111</td>\n",
       "      <td>-36.757057</td>\n",
       "      <td>-0.591017</td>\n",
       "      <td>21</td>\n",
       "      <td>0.430040</td>\n",
       "      <td>16</td>\n",
       "      <td>0.207435</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53107364</th>\n",
       "      <td>Medicine</td>\n",
       "      <td>23</td>\n",
       "      <td>0.258839</td>\n",
       "      <td>-46.797390</td>\n",
       "      <td>-55.657715</td>\n",
       "      <td>11</td>\n",
       "      <td>0.494533</td>\n",
       "      <td>12</td>\n",
       "      <td>0.223036</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20038 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Scopus_label  movMF_label  movMF_distance  \\\n",
       "202381698                      Multidisciplinary           22        0.445886   \n",
       "137773608                      Multidisciplinary           22        0.590942   \n",
       "125754415                      Multidisciplinary           22        0.574571   \n",
       "3880285                        Multidisciplinary           23        0.618842   \n",
       "111155417                              Chemistry           23        0.220853   \n",
       "...                                          ...          ...             ...   \n",
       "2764485818                              Medicine           21        0.268070   \n",
       "83454320                     Arts and Humanities           25        0.034777   \n",
       "16507453                     Arts and Humanities            6        0.113656   \n",
       "121509672   Agricultural and Biological Sciences            5        0.179111   \n",
       "53107364                                Medicine           23        0.258839   \n",
       "\n",
       "                x_val      y_val  kmeans_label  kmeans_distance  skm_label  \\\n",
       "202381698  -67.928200  15.572327            17         0.628846         20   \n",
       "137773608  -68.405334 -55.633186            17         0.735654         20   \n",
       "125754415  -68.448853 -55.613579            17         0.705024         20   \n",
       "3880285    -68.407288 -55.634430             8         0.724859         17   \n",
       "111155417  -54.506985 -61.217068            11         0.495787         12   \n",
       "...               ...        ...           ...              ...        ...   \n",
       "2764485818 -28.969574  34.819569            18         0.542531         14   \n",
       "83454320    78.609909  31.736822            13         0.251599          3   \n",
       "16507453    89.206772  17.625090            13         0.307089          3   \n",
       "121509672  -36.757057  -0.591017            21         0.430040         16   \n",
       "53107364   -46.797390 -55.657715            11         0.494533         12   \n",
       "\n",
       "            skm_distance  spectral_label  n2v_kmeans_label  cm_kmeans_label  \\\n",
       "202381698       0.444711              24                 3               21   \n",
       "137773608       0.559494              24                20               21   \n",
       "125754415       0.550081              24                20               21   \n",
       "3880285         0.610582              24                20               21   \n",
       "111155417       0.198758              14                 4               24   \n",
       "...                  ...             ...               ...              ...   \n",
       "2764485818      0.251015               8                18                1   \n",
       "83454320        0.056642              21                 5                1   \n",
       "16507453        0.128660              21                 5                1   \n",
       "121509672       0.207435              10                 5                1   \n",
       "53107364        0.223036              14                 0               24   \n",
       "\n",
       "            gnn_kmeans_label  bert_kmeans_label  \n",
       "202381698                  0                  0  \n",
       "137773608                  0                  3  \n",
       "125754415                  0                  0  \n",
       "3880285                    0                  3  \n",
       "111155417                 21                  0  \n",
       "...                      ...                ...  \n",
       "2764485818                19                  1  \n",
       "83454320                  14                  1  \n",
       "16507453                  14                  1  \n",
       "121509672                 10                  1  \n",
       "53107364                  22                  1  \n",
       "\n",
       "[20038 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_parquet(home / 'projects/TLDR/data/cluster_df.parquet')\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0971ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>deepseek_v3</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>qwq</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study examines mtDNA sequences from tauri...</td>\n",
       "      <td>Reference 14 reports phylogenetic analysis of ...</td>\n",
       "      <td>These authors investigated the evolutionary hi...</td>\n",
       "      <td>This study uses mitochondrial DNA sequencing t...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study provides molecular evidence for the...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>These findings indicate that there has been ge...</td>\n",
       "      <td>This study provides molecular evidence for int...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This study reports the fine-mapping of a QTL a...</td>\n",
       "      <td>This paper reports the fine-mapping of a QTL a...</td>\n",
       "      <td>Fine mapping a QTL for milk fat percentage on ...</td>\n",
       "      <td>This study refines the mapping of a quantitati...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study provides an early genome-wide analy...</td>\n",
       "      <td>This paper reports an extensive LD map in dair...</td>\n",
       "      <td>This study evaluates the potential of LD mappi...</td>\n",
       "      <td>This study investigates linkage disequilibrium...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This study reports the mapping of a major quan...</td>\n",
       "      <td>This study identifies a major QTL on chromosom...</td>\n",
       "      <td>This study identifies a major locus on pig chr...</td>\n",
       "      <td>This study identifies a major quantitative tra...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35631</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This study demonstrates the feasibility of iso...</td>\n",
       "      <td>Reference 51 describes an optimized method for...</td>\n",
       "      <td>These studies demonstrate the feasibility of t...</td>\n",
       "      <td>This study evaluates the expansion and functio...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35632</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study describes the engineering of orthog...</td>\n",
       "      <td>Reference 54 reports the successful engineerin...</td>\n",
       "      <td>This study demonstrates that a synthetic IL-2:...</td>\n",
       "      <td>This study introduces engineered synthetic IL-...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35633</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies hybrid insulin peptides ...</td>\n",
       "      <td>This study identified that autoreactive T cell...</td>\n",
       "      <td>T cells isolated from the pancreatic islets of...</td>\n",
       "      <td>This study identifies that T cells in type 1 d...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35634</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study describes a multiplex genome-editin...</td>\n",
       "      <td>This work describes a new method to render all...</td>\n",
       "      <td>This study provides evidence for genome-edited...</td>\n",
       "      <td>This study presents a multiplex genome-editing...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35635</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study identifies and characterizes human ...</td>\n",
       "      <td>References 18 and 19 report the existence of a...</td>\n",
       "      <td>These results identify a population of regulat...</td>\n",
       "      <td>This study identifies human CD4+CD25high regul...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34146 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "35631            10.2337/db08-1168    4860455   \n",
       "35632      10.1126/science.aar3246    4860145   \n",
       "35633      10.1126/science.aad2791   62290395   \n",
       "35634      10.1073/pnas.1902566116   82979762   \n",
       "35635  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "35631  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "35632  Engineering cytokine-receptor pairs Interleuki...   \n",
       "35633  T cells target peptide combos One of the endur...   \n",
       "35634  Polymorphic HLAs form the primary immune barri...   \n",
       "35635  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "35631  This article describes the good manufacturing ...   \n",
       "35632  This study reports the generation of an orthog...   \n",
       "35633  This article shows that some diabetogenic T ce...   \n",
       "35634  This article describes the development of gene...   \n",
       "35635  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                             deepseek_v3  \\\n",
       "0      This study examines mtDNA sequences from tauri...   \n",
       "1      This study provides molecular evidence for the...   \n",
       "2      This study reports the fine-mapping of a QTL a...   \n",
       "3      This study provides an early genome-wide analy...   \n",
       "4      This study reports the mapping of a major quan...   \n",
       "...                                                  ...   \n",
       "35631  This study demonstrates the feasibility of iso...   \n",
       "35632  This study describes the engineering of orthog...   \n",
       "35633  This study identifies hybrid insulin peptides ...   \n",
       "35634  This study describes a multiplex genome-editin...   \n",
       "35635  This study identifies and characterizes human ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      Reference 14 reports phylogenetic analysis of ...   \n",
       "1      This study demonstrates independent domesticat...   \n",
       "2      This paper reports the fine-mapping of a QTL a...   \n",
       "3      This paper reports an extensive LD map in dair...   \n",
       "4      This study identifies a major QTL on chromosom...   \n",
       "...                                                  ...   \n",
       "35631  Reference 51 describes an optimized method for...   \n",
       "35632  Reference 54 reports the successful engineerin...   \n",
       "35633  This study identified that autoreactive T cell...   \n",
       "35634  This work describes a new method to render all...   \n",
       "35635  References 18 and 19 report the existence of a...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      These authors investigated the evolutionary hi...   \n",
       "1      These findings indicate that there has been ge...   \n",
       "2      Fine mapping a QTL for milk fat percentage on ...   \n",
       "3      This study evaluates the potential of LD mappi...   \n",
       "4      This study identifies a major locus on pig chr...   \n",
       "...                                                  ...   \n",
       "35631  These studies demonstrate the feasibility of t...   \n",
       "35632  This study demonstrates that a synthetic IL-2:...   \n",
       "35633  T cells isolated from the pancreatic islets of...   \n",
       "35634  This study provides evidence for genome-edited...   \n",
       "35635  These results identify a population of regulat...   \n",
       "\n",
       "                                                     qwq     mag_pid  \\\n",
       "0      This study uses mitochondrial DNA sequencing t...  2005395185   \n",
       "1      This study provides molecular evidence for int...  2110049233   \n",
       "2      This study refines the mapping of a quantitati...  2082900742   \n",
       "3      This study investigates linkage disequilibrium...  2103106090   \n",
       "4      This study identifies a major quantitative tra...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "35631  This study evaluates the expansion and functio...  2137227986   \n",
       "35632  This study introduces engineered synthetic IL-...  2789780246   \n",
       "35633  This study identifies that T cells in type 1 d...  2266478788   \n",
       "35634  This study presents a multiplex genome-editing...  2943378944   \n",
       "35635  This study identifies human CD4+CD25high regul...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "35631  129060628  2009         17   \n",
       "35632    3880285  2018          8   \n",
       "35633    3880285  2016          8   \n",
       "35634  125754415  2019         17   \n",
       "35635   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \n",
       "0                                 Multidisciplinary  \n",
       "1      Biochemistry, Genetics and Molecular Biology  \n",
       "2                                 Multidisciplinary  \n",
       "3      Biochemistry, Genetics and Molecular Biology  \n",
       "4                                 Multidisciplinary  \n",
       "...                                             ...  \n",
       "35631                                      Medicine  \n",
       "35632                             Multidisciplinary  \n",
       "35633                             Multidisciplinary  \n",
       "35634                             Multidisciplinary  \n",
       "35635                   Immunology and Microbiology  \n",
       "\n",
       "[34146 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(label_df[['kmeans_label', 'Scopus_label']], left_on='mag_vid', right_index=True, how='inner')\n",
    "df.rename(columns={'kmeans_label': 'p2v_label', 'Scopus_label': 'scopus_label'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "226296ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p2v_label\n",
       "17    18439\n",
       "8      9625\n",
       "6      1457\n",
       "7      1028\n",
       "4       627\n",
       "9       611\n",
       "11      580\n",
       "22      404\n",
       "18      363\n",
       "21      319\n",
       "12      292\n",
       "20      121\n",
       "1        60\n",
       "3        49\n",
       "14       32\n",
       "5        25\n",
       "24       21\n",
       "16       21\n",
       "15       17\n",
       "2        16\n",
       "23       16\n",
       "0        10\n",
       "19        6\n",
       "13        5\n",
       "25        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['p2v_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcc140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scopus_label\n",
       "Multidisciplinary                               15639\n",
       "Medicine                                         5262\n",
       "Immunology and Microbiology                      4146\n",
       "Biochemistry, Genetics and Molecular Biology     4116\n",
       "Chemistry                                        1285\n",
       "Neuroscience                                     1211\n",
       "Agricultural and Biological Sciences              704\n",
       "Social Sciences                                   608\n",
       "Earth and Planetary Sciences                      235\n",
       "Materials Science                                 179\n",
       "Psychology                                        156\n",
       "Physics and Astronomy                             139\n",
       "Pharmacology, Toxicology and Pharmaceutics        128\n",
       "Environmental Science                             119\n",
       "Energy                                             39\n",
       "Mathematics                                        30\n",
       "Engineering                                        28\n",
       "Computer Science                                   24\n",
       "Nursing                                            24\n",
       "Economics, Econometrics and Finance                21\n",
       "Dentistry                                          16\n",
       "Chemical Engineering                               13\n",
       "Business, Management and Accounting                 8\n",
       "Health Professions                                  6\n",
       "Arts and Humanities                                 6\n",
       "Veterinary                                          3\n",
       "Decision Sciences                                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['scopus_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbda26a",
   "metadata": {},
   "source": [
    "# Predict subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd843a0",
   "metadata": {},
   "source": [
    "## 10-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "590f6dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:02<00:00, 16823.73it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Acc: 0.6962±0.0039 | Precision: 0.6544±0.0022 | Recall: 0.9270±0.0074 | F1: 0.7672±0.0035\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 96090.98it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Acc: 0.6411±0.0043 | Precision: 0.6133±0.0028 | Recall: 0.9076±0.0078 | F1: 0.7320±0.0036\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 52099.23it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Acc: 0.6631±0.0038 | Precision: 0.6313±0.0026 | Recall: 0.9043±0.0067 | F1: 0.7435±0.0032\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 82126.75it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Acc: 0.6622±0.0079 | Precision: 0.6313±0.0055 | Recall: 0.8999±0.0089 | F1: 0.7421±0.0059\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:00<00:00, 41301.66it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.5s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Acc: 0.6516±0.0055 | Precision: 0.6242±0.0042 | Recall: 0.8921±0.0056 | F1: 0.7344±0.0036\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [00:01<00:00, 32375.28it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.6s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Acc: 0.6636±0.0039 | Precision: 0.6330±0.0028 | Recall: 0.8973±0.0077 | F1: 0.7423±0.0033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.696246</td>\n",
       "      <td>0.003894</td>\n",
       "      <td>0.654427</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.927002</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.767215</td>\n",
       "      <td>0.003539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.641100</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.613316</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.907641</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>0.731988</td>\n",
       "      <td>0.003620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.663065</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.631253</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.904333</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.743501</td>\n",
       "      <td>0.003178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.662157</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.631344</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.899886</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>0.742050</td>\n",
       "      <td>0.005874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.651614</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.624158</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.892076</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.734433</td>\n",
       "      <td>0.003638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.663592</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.632998</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.897282</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.742303</td>\n",
       "      <td>0.003312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  accuracy_mean  accuracy_std  precision_mean  precision_std  \\\n",
       "0     abstract       0.696246      0.003894        0.654427       0.002232   \n",
       "1   annotation       0.641100      0.004256        0.613316       0.002769   \n",
       "2  deepseek_v3       0.663065      0.003774        0.631253       0.002584   \n",
       "3       gemma3       0.662157      0.007899        0.631344       0.005537   \n",
       "4       llama4       0.651614      0.005473        0.624158       0.004231   \n",
       "5          qwq       0.663592      0.003870        0.632998       0.002816   \n",
       "\n",
       "   recall_mean  recall_std   f1_mean    f1_std  \n",
       "0     0.927002    0.007353  0.767215  0.003539  \n",
       "1     0.907641    0.007798  0.731988  0.003620  \n",
       "2     0.904333    0.006696  0.743501  0.003178  \n",
       "3     0.899886    0.008865  0.742050  0.005874  \n",
       "4     0.892076    0.005578  0.734433  0.003638  \n",
       "5     0.897282    0.007682  0.742303  0.003312  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "# text_features = ['abstract', 'annotation', 'deepseek_v3', 'qwen3','gemma3', 'llama4', 'qwq']\n",
    "text_features = ['abstract', 'annotation'] + models\n",
    "y = (df['p2v_label'] == 17).astype(int)  # 17为1，否则为0\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**18, stop_words='english', alternate_sign=False)\n",
    "    X = vectorizer.transform(X_text)\n",
    "    clf = MultinomialNB()\n",
    "    scores = cross_validate(clf, X, y, cv=cv, scoring=scoring, n_jobs=-1, verbose=1)\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'accuracy_mean': scores['test_accuracy'].mean(),\n",
    "        'accuracy_std': scores['test_accuracy'].std(),\n",
    "        'precision_mean': scores['test_precision'].mean(),\n",
    "        'precision_std': scores['test_precision'].std(),\n",
    "        'recall_mean': scores['test_recall'].mean(),\n",
    "        'recall_std': scores['test_recall'].std(),\n",
    "        'f1_mean': scores['test_f1'].mean(),\n",
    "        'f1_std': scores['test_f1'].std(),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Acc: {res['accuracy_mean']:.4f}±{res['accuracy_std']:.4f} | \"\n",
    "        f\"Precision: {res['precision_mean']:.4f}±{res['precision_std']:.4f} | \"\n",
    "        f\"Recall: {res['recall_mean']:.4f}±{res['recall_std']:.4f} | \"\n",
    "        f\"F1: {res['f1_mean']:.4f}±{res['f1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a2558",
   "metadata": {},
   "source": [
    "## no cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e71fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:01<00:00, 21263.68it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 21465.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.6972 | Precision: 0.6540 | Recall: 0.9328 | F1: 0.7689\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 138569.82it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 137783.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.6442 | Precision: 0.6150 | Recall: 0.9121 | F1: 0.7347\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 75092.37it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 73381.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.6656 | Precision: 0.6333 | Recall: 0.9046 | F1: 0.7450\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 118969.75it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 110159.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.6723 | Precision: 0.6389 | Recall: 0.9040 | F1: 0.7487\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 57141.27it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 84019.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.6624 | Precision: 0.6299 | Recall: 0.9084 | F1: 0.7439\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 43916.52it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 44519.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.6685 | Precision: 0.6364 | Recall: 0.9008 | F1: 0.7458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.697218</td>\n",
       "      <td>0.653992</td>\n",
       "      <td>0.932755</td>\n",
       "      <td>0.768887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.644217</td>\n",
       "      <td>0.614991</td>\n",
       "      <td>0.912148</td>\n",
       "      <td>0.734658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.665593</td>\n",
       "      <td>0.633257</td>\n",
       "      <td>0.904555</td>\n",
       "      <td>0.744975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.672328</td>\n",
       "      <td>0.638942</td>\n",
       "      <td>0.904013</td>\n",
       "      <td>0.748709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.662372</td>\n",
       "      <td>0.629936</td>\n",
       "      <td>0.908351</td>\n",
       "      <td>0.743948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.668521</td>\n",
       "      <td>0.636398</td>\n",
       "      <td>0.900759</td>\n",
       "      <td>0.745846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  accuracy  precision    recall        f1\n",
       "0     abstract  0.697218   0.653992  0.932755  0.768887\n",
       "1   annotation  0.644217   0.614991  0.912148  0.734658\n",
       "2  deepseek_v3  0.665593   0.633257  0.904555  0.744975\n",
       "3       gemma3  0.672328   0.638942  0.904013  0.748709\n",
       "4       llama4  0.662372   0.629936  0.908351  0.743948\n",
       "5          qwq  0.668521   0.636398  0.900759  0.745846"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "# 二分类标签：是否为17\n",
    "y = (df['p2v_label'] == 17).astype(int)  # 17为1，否则为0\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.1, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**18, stop_words='english', alternate_sign=False)\n",
    "    X_train_vec = vectorizer.transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['accuracy']:.4f} | \"\n",
    "        f\"Precision: {res['precision']:.4f} | \"\n",
    "        f\"Recall: {res['recall']:.4f} | \"\n",
    "        f\"F1: {res['f1']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762be464",
   "metadata": {},
   "source": [
    "# Predict year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40795c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    34146.000000\n",
       "mean      2006.680724\n",
       "std          9.105688\n",
       "min       1887.000000\n",
       "25%       2001.000000\n",
       "50%       2007.000000\n",
       "75%       2014.000000\n",
       "max       2022.000000\n",
       "Name: year, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8fb2f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.histplot(df, x='year', stat='count', discrete=True)\n",
    "plt.xlabel('Publication year')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5fa53",
   "metadata": {},
   "source": [
    "## 10-fold cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580439a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|████████████████████████████████████████████| 34146/34146 [00:01<00:00, 20368.95it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    4.3s remaining:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.7542±0.0080 | F1: 0.7063±0.0094\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 34146/34146 [00:00<00:00, 133230.67it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.7161±0.0090 | F1: 0.6678±0.0120\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|████████████████████████████████████████████| 34146/34146 [00:00<00:00, 72311.64it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.7172±0.0093 | F1: 0.6544±0.0113\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 34146/34146 [00:00<00:00, 112990.21it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.7114±0.0076 | F1: 0.6574±0.0114\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|████████████████████████████████████████████| 34146/34146 [00:00<00:00, 56922.13it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.7082±0.0107 | F1: 0.6682±0.0141\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|████████████████████████████████████████████| 34146/34146 [00:00<00:00, 41747.87it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    0.1s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.7116±0.0098 | F1: 0.6457±0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.754203</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.836492</td>\n",
       "      <td>0.011048</td>\n",
       "      <td>0.611367</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.706276</td>\n",
       "      <td>0.009402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.716131</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>0.768938</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>0.590483</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.667834</td>\n",
       "      <td>0.011960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.717215</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.799932</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.553913</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>0.654393</td>\n",
       "      <td>0.011265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.711416</td>\n",
       "      <td>0.007554</td>\n",
       "      <td>0.771602</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>0.573048</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.657395</td>\n",
       "      <td>0.011420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.708195</td>\n",
       "      <td>0.010678</td>\n",
       "      <td>0.741881</td>\n",
       "      <td>0.013607</td>\n",
       "      <td>0.607991</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>0.668183</td>\n",
       "      <td>0.014121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.711563</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.794972</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>0.543872</td>\n",
       "      <td>0.016115</td>\n",
       "      <td>0.645722</td>\n",
       "      <td>0.012464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  \\\n",
       "0     abstract       0.754203      0.008020        0.836492       0.011048   \n",
       "1   annotation       0.716131      0.009039        0.768938       0.013663   \n",
       "2  deepseek_v3       0.717215      0.009269        0.799932       0.011445   \n",
       "3       gemma3       0.711416      0.007554        0.771602       0.010839   \n",
       "4       llama4       0.708195      0.010678        0.741881       0.013607   \n",
       "5          qwq       0.711563      0.009785        0.794972       0.012332   \n",
       "\n",
       "   Recall_mean  Recall_std   F1_mean    F1_std  \n",
       "0     0.611367    0.014414  0.706276  0.009402  \n",
       "1     0.590483    0.016425  0.667834  0.011960  \n",
       "2     0.553913    0.015737  0.654393  0.011265  \n",
       "3     0.573048    0.019053  0.657395  0.011420  \n",
       "4     0.607991    0.017708  0.668183  0.014121  \n",
       "5     0.543872    0.016115  0.645722  0.012464  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "# 指标: Accuracy, Precision, Recall, F1\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "y = (df['year'] >= 2008).astype(int)\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**20, stop_words='english', alternate_sign=False)\n",
    "    X = vectorizer.transform(X_text)\n",
    "    model = MultinomialNB()\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1, verbose=1, return_train_score=False)\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy_mean': scores['test_Accuracy'].mean(),\n",
    "        'Accuracy_std': scores['test_Accuracy'].std(),\n",
    "        'Precision_mean': scores['test_Precision'].mean(),\n",
    "        'Precision_std': scores['test_Precision'].std(),\n",
    "        'Recall_mean': scores['test_Recall'].mean(),\n",
    "        'Recall_std': scores['test_Recall'].std(),\n",
    "        'F1_mean': scores['test_F1'].mean(),\n",
    "        'F1_std': scores['test_F1'].std(),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy_mean']:.4f}±{res['Accuracy_std']:.4f} | \"\n",
    "        f\"F1: {res['F1_mean']:.4f}±{res['F1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f2c119",
   "metadata": {},
   "source": [
    "## no cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:01<00:00, 21330.43it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 22020.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | MAE: 4.2865 | R2: 0.5755\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|██████████████████████████████████████████| 30731/30731 [00:00<00:00, 110815.97it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 130228.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | MAE: 5.5461 | R2: 0.3061\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 67192.84it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 77554.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | MAE: 5.0521 | R2: 0.4281\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 99404.52it/s]\n",
      "Vectorizing documents: 100%|████████████████████████████████████████████| 3415/3415 [00:00<00:00, 120217.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | MAE: 5.5035 | R2: 0.3244\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 55302.63it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 54197.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | MAE: 5.5231 | R2: 0.3139\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|███████████████████████████████████████████| 30731/30731 [00:00<00:00, 40333.08it/s]\n",
      "Vectorizing documents: 100%|█████████████████████████████████████████████| 3415/3415 [00:00<00:00, 44297.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | MAE: 5.0755 | R2: 0.4131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>4.286524</td>\n",
       "      <td>34.042876</td>\n",
       "      <td>0.575475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>5.546063</td>\n",
       "      <td>55.646234</td>\n",
       "      <td>0.306074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>5.052078</td>\n",
       "      <td>45.857851</td>\n",
       "      <td>0.428139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>5.503463</td>\n",
       "      <td>54.177417</td>\n",
       "      <td>0.324391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama4</td>\n",
       "      <td>5.523119</td>\n",
       "      <td>55.020432</td>\n",
       "      <td>0.313878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>qwq</td>\n",
       "      <td>5.075490</td>\n",
       "      <td>47.060866</td>\n",
       "      <td>0.413137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature       MAE        MSE        R2\n",
       "0     abstract  4.286524  34.042876  0.575475\n",
       "1   annotation  5.546063  55.646234  0.306074\n",
       "2  deepseek_v3  5.052078  45.857851  0.428139\n",
       "3       gemma3  5.503463  54.177417  0.324391\n",
       "4       llama4  5.523119  55.020432  0.313878\n",
       "5          qwq  5.075490  47.060866  0.413137"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'gemma3', 'llama4', 'qwq']\n",
    "y = df['year'].astype(int)  # 年份作为连续变量回归\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    X_text = df[feat].astype(str).fillna('')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_text, y, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**18, stop_words='english', alternate_sign=False)\n",
    "    X_train_vec = vectorizer.transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    y_pred = model.predict(X_test_vec)\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'MAE': mean_absolute_error(y_test, y_pred),\n",
    "        'MSE': mean_squared_error(y_test, y_pred),\n",
    "        'R2': r2_score(y_test, y_pred),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"MAE: {res['MAE']:.4f} | \"\n",
    "        f\"R2: {res['R2']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0799cb16",
   "metadata": {},
   "source": [
    "# Predict title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7f76a",
   "metadata": {},
   "source": [
    "## Fetch titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12388ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying titles: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:00<00:00, 129.12batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1353153</td>\n",
       "      <td>Efficient Generation of a Hepatitis B Virus Cy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1634910</td>\n",
       "      <td>Structure of Hjc, a Holliday junction resolvas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1655469</td>\n",
       "      <td>From Complete Genomes to Measures of Substitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1778349</td>\n",
       "      <td>Regulation of the Proinflammatory Effects of F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2550721</td>\n",
       "      <td>Differential requirement for p19ARF in the p53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28005</th>\n",
       "      <td>83433077</td>\n",
       "      <td>Revisiting IL-2: Biology and therapeutic prosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28006</th>\n",
       "      <td>104021261</td>\n",
       "      <td>Systems-level analysis of mechanisms regulatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28007</th>\n",
       "      <td>104393236</td>\n",
       "      <td>siRNA nanoparticles targeting CaMKIIγ in lesio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28008</th>\n",
       "      <td>123181209</td>\n",
       "      <td>Immunotherapy of autoimmune encephalomyelitis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28009</th>\n",
       "      <td>125333095</td>\n",
       "      <td>RNA components of the spliceosome regulate tis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper_id                                              title\n",
       "0        1353153  Efficient Generation of a Hepatitis B Virus Cy...\n",
       "1        1634910  Structure of Hjc, a Holliday junction resolvas...\n",
       "2        1655469  From Complete Genomes to Measures of Substitut...\n",
       "3        1778349  Regulation of the Proinflammatory Effects of F...\n",
       "4        2550721  Differential requirement for p19ARF in the p53...\n",
       "...          ...                                                ...\n",
       "28005   83433077  Revisiting IL-2: Biology and therapeutic prosp...\n",
       "28006  104021261  Systems-level analysis of mechanisms regulatin...\n",
       "28007  104393236  siRNA nanoparticles targeting CaMKIIγ in lesio...\n",
       "28008  123181209  Immunotherapy of autoimmune encephalomyelitis ...\n",
       "28009  125333095  RNA components of the spliceosome regulate tis...\n",
       "\n",
       "[28010 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm import tqdm\n",
    "\n",
    "MYSQL_HOST = '144.214.39.113'\n",
    "MYSQL_USER = 'key'\n",
    "MYSQL_PASS = 'Keydge11'\n",
    "MYSQL_DB = 'keydge'\n",
    "\n",
    "engine = create_engine(f'mysql+pymysql://{MYSQL_USER}:{MYSQL_PASS}@{MYSQL_HOST}/{MYSQL_DB}?charset=utf8mb4')\n",
    "\n",
    "paper_ids = df['paper_id'].unique().tolist()\n",
    "BATCH_SIZE = 500  # 每批查多少条，可调大或调小\n",
    "\n",
    "results = []\n",
    "# 用tqdm显示批次进度和预计完成时间\n",
    "for i in tqdm(range(0, len(paper_ids), BATCH_SIZE), desc=\"Querying titles\", unit=\"batch\"):\n",
    "    batch = paper_ids[i:i+BATCH_SIZE]\n",
    "    id_str = ','.join(str(int(pid)) for pid in batch)\n",
    "    sql = f\"SELECT paper_id, title FROM paper_bib WHERE paper_id IN ({id_str})\"\n",
    "    batch_df = pd.read_sql(sql, engine)\n",
    "    results.append(batch_df)\n",
    "\n",
    "# 合并所有批次的查询结果\n",
    "paper_title_df = pd.concat(results, ignore_index=True)\n",
    "display(paper_title_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_title_df.to_parquet(home / 'projects/TLDR/data/paper_title.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a09c2ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>deepseek_v3</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>qwq</th>\n",
       "      <th>qwen3</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study provides genetic evidence for two i...</td>\n",
       "      <td>Reference 16 provides a molecular phylogeny of...</td>\n",
       "      <td>This study proposes that zebu and taurine catt...</td>\n",
       "      <td>This study uses mitochondrial DNA analysis to ...</td>\n",
       "      <td>This study analyzes mitochondrial DNA diversit...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Evidence for two independent domestications of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study provides genetic evidence for indep...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>This study reports the origin of European and ...</td>\n",
       "      <td>This study uses mitochondrial and nuclear DNA ...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>The Origin of the Domestic Pig: Independent Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This study reports the fine-mapping of a QTL f...</td>\n",
       "      <td>Reference 53 reports fine-mapping of a QTL for...</td>\n",
       "      <td>The QTL was fine-mapped to a 5 cM region on BT...</td>\n",
       "      <td>This study uses high-density marker genotyping...</td>\n",
       "      <td>This study fine-maps a milk production QTL on ...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Fine-mapping of quantitative trait loci by ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study provides the first genome-wide LD m...</td>\n",
       "      <td>This study documents an unusually strong and l...</td>\n",
       "      <td>The authors provide evidence that linkage dise...</td>\n",
       "      <td>This study generates a genome-wide linkage dis...</td>\n",
       "      <td>This study reports high levels of both synteni...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>Extensive Genome-wide Linkage Disequilibrium i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This study identifies a major QTL on chromosom...</td>\n",
       "      <td>This study identifies a major QTL on pig chrom...</td>\n",
       "      <td>This study reports a major QTL on SSC4 for fat...</td>\n",
       "      <td>This study identifies a major quantitative tra...</td>\n",
       "      <td>This study identifies quantitative trait loci ...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Genetic mapping of quantitative trait loci for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34141</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This study demonstrates that CD4+CD127lo/−CD25...</td>\n",
       "      <td>This study provides a method for isolation and...</td>\n",
       "      <td>This study demonstrates that Tregs can be expa...</td>\n",
       "      <td>This study evaluates methods for isolating and...</td>\n",
       "      <td>This study demonstrates that CD4+CD127lo/−CD25...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Expansion of Human Regulatory T-Cells From Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34142</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study reports the engineering of orthogon...</td>\n",
       "      <td>This study describes an engineered IL-2/IL-2R ...</td>\n",
       "      <td>This study presents an engineered IL-2 partial...</td>\n",
       "      <td>This study engineers synthetic IL-2–receptor p...</td>\n",
       "      <td>This study describes engineered orthogonal IL-...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Selective targeting of engineered T cells usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34143</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies hybrid insulin peptides ...</td>\n",
       "      <td>This study reports the identification of hybri...</td>\n",
       "      <td>This study highlights the potential importance...</td>\n",
       "      <td>This study identifies hybrid peptides—covalent...</td>\n",
       "      <td>This study identifies hybrid peptides formed b...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Pathogenic CD4 T cells in type 1 diabetes reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34144</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study demonstrates a multiplex genome-edi...</td>\n",
       "      <td>This work reports on a cell engineering strate...</td>\n",
       "      <td>This study identifies a strategy for broad imm...</td>\n",
       "      <td>This study describes a dual strategy to engine...</td>\n",
       "      <td>This work describes a multiplex genome editing...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Generation of hypoimmunogenic human pluripoten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34145</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study identifies and characterizes human ...</td>\n",
       "      <td>This study identifies and characterizes a popu...</td>\n",
       "      <td>This study identified a population of CD4+ T c...</td>\n",
       "      <td>This study identifies CD4+CD25high regulatory ...</td>\n",
       "      <td>This study identifies CD4+CD25high regulatory ...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "      <td>CD4+CD25high Regulatory Cells in Human Periphe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34146 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "34141            10.2337/db08-1168    4860455   \n",
       "34142      10.1126/science.aar3246    4860145   \n",
       "34143      10.1126/science.aad2791   62290395   \n",
       "34144      10.1073/pnas.1902566116   82979762   \n",
       "34145  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "34141  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "34142  Engineering cytokine-receptor pairs Interleuki...   \n",
       "34143  T cells target peptide combos One of the endur...   \n",
       "34144  Polymorphic HLAs form the primary immune barri...   \n",
       "34145  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "34141  This article describes the good manufacturing ...   \n",
       "34142  This study reports the generation of an orthog...   \n",
       "34143  This article shows that some diabetogenic T ce...   \n",
       "34144  This article describes the development of gene...   \n",
       "34145  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                             deepseek_v3  \\\n",
       "0      This study provides genetic evidence for two i...   \n",
       "1      This study provides genetic evidence for indep...   \n",
       "2      This study reports the fine-mapping of a QTL f...   \n",
       "3      This study provides the first genome-wide LD m...   \n",
       "4      This study identifies a major QTL on chromosom...   \n",
       "...                                                  ...   \n",
       "34141  This study demonstrates that CD4+CD127lo/−CD25...   \n",
       "34142  This study reports the engineering of orthogon...   \n",
       "34143  This study identifies hybrid insulin peptides ...   \n",
       "34144  This study demonstrates a multiplex genome-edi...   \n",
       "34145  This study identifies and characterizes human ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      Reference 16 provides a molecular phylogeny of...   \n",
       "1      This study demonstrates independent domesticat...   \n",
       "2      Reference 53 reports fine-mapping of a QTL for...   \n",
       "3      This study documents an unusually strong and l...   \n",
       "4      This study identifies a major QTL on pig chrom...   \n",
       "...                                                  ...   \n",
       "34141  This study provides a method for isolation and...   \n",
       "34142  This study describes an engineered IL-2/IL-2R ...   \n",
       "34143  This study reports the identification of hybri...   \n",
       "34144  This work reports on a cell engineering strate...   \n",
       "34145  This study identifies and characterizes a popu...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      This study proposes that zebu and taurine catt...   \n",
       "1      This study reports the origin of European and ...   \n",
       "2      The QTL was fine-mapped to a 5 cM region on BT...   \n",
       "3      The authors provide evidence that linkage dise...   \n",
       "4      This study reports a major QTL on SSC4 for fat...   \n",
       "...                                                  ...   \n",
       "34141  This study demonstrates that Tregs can be expa...   \n",
       "34142  This study presents an engineered IL-2 partial...   \n",
       "34143  This study highlights the potential importance...   \n",
       "34144  This study identifies a strategy for broad imm...   \n",
       "34145  This study identified a population of CD4+ T c...   \n",
       "\n",
       "                                                     qwq  \\\n",
       "0      This study uses mitochondrial DNA analysis to ...   \n",
       "1      This study uses mitochondrial and nuclear DNA ...   \n",
       "2      This study uses high-density marker genotyping...   \n",
       "3      This study generates a genome-wide linkage dis...   \n",
       "4      This study identifies a major quantitative tra...   \n",
       "...                                                  ...   \n",
       "34141  This study evaluates methods for isolating and...   \n",
       "34142  This study engineers synthetic IL-2–receptor p...   \n",
       "34143  This study identifies hybrid peptides—covalent...   \n",
       "34144  This study describes a dual strategy to engine...   \n",
       "34145  This study identifies CD4+CD25high regulatory ...   \n",
       "\n",
       "                                                   qwen3     mag_pid  \\\n",
       "0      This study analyzes mitochondrial DNA diversit...  2005395185   \n",
       "1      This study demonstrates independent domesticat...  2110049233   \n",
       "2      This study fine-maps a milk production QTL on ...  2082900742   \n",
       "3      This study reports high levels of both synteni...  2103106090   \n",
       "4      This study identifies quantitative trait loci ...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "34141  This study demonstrates that CD4+CD127lo/−CD25...  2137227986   \n",
       "34142  This study describes engineered orthogonal IL-...  2789780246   \n",
       "34143  This study identifies hybrid peptides formed b...  2266478788   \n",
       "34144  This work describes a multiplex genome editing...  2943378944   \n",
       "34145  This study identifies CD4+CD25high regulatory ...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "34141  129060628  2009         17   \n",
       "34142    3880285  2018          8   \n",
       "34143    3880285  2016          8   \n",
       "34144  125754415  2019         17   \n",
       "34145   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \\\n",
       "0                                 Multidisciplinary   \n",
       "1      Biochemistry, Genetics and Molecular Biology   \n",
       "2                                 Multidisciplinary   \n",
       "3      Biochemistry, Genetics and Molecular Biology   \n",
       "4                                 Multidisciplinary   \n",
       "...                                             ...   \n",
       "34141                                      Medicine   \n",
       "34142                             Multidisciplinary   \n",
       "34143                             Multidisciplinary   \n",
       "34144                             Multidisciplinary   \n",
       "34145                   Immunology and Microbiology   \n",
       "\n",
       "                                                   title  \n",
       "0      Evidence for two independent domestications of...  \n",
       "1      The Origin of the Domestic Pig: Independent Do...  \n",
       "2      Fine-mapping of quantitative trait loci by ide...  \n",
       "3      Extensive Genome-wide Linkage Disequilibrium i...  \n",
       "4      Genetic mapping of quantitative trait loci for...  \n",
       "...                                                  ...  \n",
       "34141  Expansion of Human Regulatory T-Cells From Pat...  \n",
       "34142  Selective targeting of engineered T cells usin...  \n",
       "34143  Pathogenic CD4 T cells in type 1 diabetes reco...  \n",
       "34144  Generation of hypoimmunogenic human pluripoten...  \n",
       "34145  CD4+CD25high Regulatory Cells in Human Periphe...  \n",
       "\n",
       "[34146 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.merge(paper_title_df, on='paper_id', how='left')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e52db",
   "metadata": {},
   "source": [
    "## Generate negative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6082a346",
   "metadata": {},
   "source": [
    "### Use 'we sentence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "358f961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from typing import Optional, List, Tuple\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "\n",
    "def find_first_we_sentence(abstract: str) -> Optional[str]:\n",
    "    \"\"\"找到abstract中第一个包含'we'的句子，并去除其中的we后返回\"\"\"\n",
    "    if pd.isna(abstract) or not isinstance(abstract, str):\n",
    "        return None\n",
    "    sentences = re.split(r'[.!?]+', abstract)\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if not sentence:\n",
    "            continue\n",
    "        if re.search(r'\\bwe\\b', sentence, re.IGNORECASE):\n",
    "            # 去除所有\"we\"（不区分大小写，单词边界）\n",
    "            cleaned_sentence = re.sub(r'\\bwe\\b', '', sentence, flags=re.IGNORECASE)\n",
    "            cleaned_sentence = re.sub(r'\\s+', ' ', cleaned_sentence).strip()\n",
    "            return cleaned_sentence\n",
    "    return None\n",
    "\n",
    "def get_random_title(abstract: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    当没有包含'we'的句子时，使用随机句子生成负样本标题\n",
    "    Args:\n",
    "        abstract: 摘要文本\n",
    "    Returns:\n",
    "        生成的标题文本\n",
    "    \"\"\"\n",
    "    if pd.isna(abstract) or not isinstance(abstract, str):\n",
    "        return None\n",
    "    # 使用NLTK的句子分词器\n",
    "    sentences = nltk.sent_tokenize(abstract)\n",
    "    sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 10]\n",
    "    if not sentences:\n",
    "        return None\n",
    "    else:\n",
    "        selected = random.choice(sentences)\n",
    "        return re.sub(r'\\s+', ' ', selected).strip()\n",
    "\n",
    "def generate_balanced_negative_samples(df: pd.DataFrame, random_seed: int = 42) -> Tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    生成与正样本数量相同的负样本\n",
    "    Args:\n",
    "        df: 原始dataframe\n",
    "        random_seed: 随机种子\n",
    "    Returns:\n",
    "        (enhanced_dataframe, statistics_dict)\n",
    "    \"\"\"\n",
    "    random.seed(random_seed)\n",
    "    # 下载必要的数据（第一次使用时需要）\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    # 正样本\n",
    "    positive_samples = df.copy()\n",
    "    positive_samples['title_paired'] = True\n",
    "    negative_samples_list = []\n",
    "\n",
    "    we_sentence_count = 0\n",
    "    random_sentence_count = 0\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"生成负样本\"):\n",
    "        negative_sample = row.copy()\n",
    "        negative_sample['title_paired'] = False\n",
    "        generated_title = None\n",
    "        \n",
    "        # 策略1: 尝试找包含'we'的句子\n",
    "        we_sentence = find_first_we_sentence(row['abstract'])\n",
    "        if we_sentence is not None:\n",
    "            generated_title = we_sentence\n",
    "            we_sentence_count += 1\n",
    "        # 策略2: 使用随机句子\n",
    "        else:\n",
    "            random_title = get_random_title(row['abstract'])\n",
    "            if random_title is not None:\n",
    "                generated_title = random_title\n",
    "                random_sentence_count += 1\n",
    "            else:\n",
    "                raise ValueError(f\"无法为行 {idx} 生成负样本标题，摘要内容可能过短或格式不正确。\")\n",
    "\n",
    "        # 记录\n",
    "        negative_sample['title'] = generated_title\n",
    "        negative_samples_list.append(negative_sample)\n",
    "    print(f\"包含'we'的句子数量: {we_sentence_count}, 随机句子数量: {random_sentence_count}\")\n",
    "    # 创建负样本DataFrame\n",
    "    negative_samples = pd.DataFrame(negative_samples_list)\n",
    "    # 合并正负样本\n",
    "    combined_df = pd.concat([positive_samples, negative_samples], ignore_index=True)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a1bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zqlyu2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "生成负样本: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 35621/35621 [00:10<00:00, 3428.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "包含'we'的句子数量: 23745, 随机句子数量: 11876\n"
     ]
    }
   ],
   "source": [
    "pos_df = generate_balanced_negative_samples(df, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ac1d8",
   "metadata": {},
   "source": [
    "### Use random title of other papers in same subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9129e0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成负样本: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 34146/34146 [01:19<00:00, 429.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "pos_df = df.copy()\n",
    "\n",
    "# 标记正样本\n",
    "pos_df['title_paired'] = True\n",
    "\n",
    "# 收集负样本\n",
    "neg_samples = []\n",
    "rng = np.random.default_rng(42)  # 固定随机种子便于复现\n",
    "\n",
    "for idx, row in tqdm(pos_df.iterrows(), total=len(pos_df), desc=\"生成负样本\"):\n",
    "    # 查找同学科标签但不同paper_id的候选title\n",
    "    candidates = pos_df[(pos_df['p2v_label'] == row['p2v_label']) & (pos_df['paper_id'] != row['paper_id'])]\n",
    "    if not candidates.empty:\n",
    "        neg_title = rng.choice(candidates['title'].values)\n",
    "        neg_row = row.copy()\n",
    "        neg_row['title'] = neg_title\n",
    "        neg_row['title_paired'] = False\n",
    "        neg_samples.append(neg_row)\n",
    "    else:\n",
    "        # 如果没有同学科不同paper的title可选，可以跳过或从全局采样（这里选择跳过）\n",
    "        raise ValueError(f\"没有找到与行 {idx} 同学科但不同paper_id的候选title。\")\n",
    "\n",
    "neg_df = pd.DataFrame(neg_samples)\n",
    "\n",
    "# 合并正负样本\n",
    "title_match_df = pd.concat([pos_df, neg_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "056e5c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Regulated MIP-3α/CCL20 production by human intestinal epithelium: mechanism for modulating mucosal immunity',\n",
       " 'IL-4 induces cathepsin protease activity in tumor-associated macrophages to promote cancer growth and invasion',\n",
       " 'mTOR-Dependent Synapse Formation Underlies the Rapid Antidepressant Effects of NMDA Antagonists',\n",
       " 'Large-scale chromatin organization of the major histocompatibility complex and other regions of human chromosome 6 and its response to interferon in interphase nuclei',\n",
       " 'Spatially resolved, highly multiplexed RNA profiling in single cells']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match_df[title_match_df['title_paired'] == False]['title'].sample(5).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5dea7c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23bca6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>annotation</th>\n",
       "      <th>deepseek_v3</th>\n",
       "      <th>gemma3</th>\n",
       "      <th>llama4</th>\n",
       "      <th>qwq</th>\n",
       "      <th>qwen3</th>\n",
       "      <th>mag_pid</th>\n",
       "      <th>mag_vid</th>\n",
       "      <th>year</th>\n",
       "      <th>p2v_label</th>\n",
       "      <th>scopus_label</th>\n",
       "      <th>title</th>\n",
       "      <th>title_paired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1073/pnas.91.7.2757</td>\n",
       "      <td>107202074</td>\n",
       "      <td>The origin and taxonomic status of domesticate...</td>\n",
       "      <td>A demonstration that cattle have been domestic...</td>\n",
       "      <td>This study provides genetic evidence for two i...</td>\n",
       "      <td>Reference 16 provides a molecular phylogeny of...</td>\n",
       "      <td>This study proposes that zebu and taurine catt...</td>\n",
       "      <td>This study uses mitochondrial DNA analysis to ...</td>\n",
       "      <td>This study analyzes mitochondrial DNA diversit...</td>\n",
       "      <td>2005395185</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1994</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Evidence for two independent domestications of...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1093/genetics/154.4.1785</td>\n",
       "      <td>83366887</td>\n",
       "      <td>Abstract The domestic pig originates from the ...</td>\n",
       "      <td>Evidence is presented for independent domestic...</td>\n",
       "      <td>This study provides genetic evidence for indep...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>This study reports the origin of European and ...</td>\n",
       "      <td>This study uses mitochondrial and nuclear DNA ...</td>\n",
       "      <td>This study demonstrates independent domesticat...</td>\n",
       "      <td>2110049233</td>\n",
       "      <td>65932378</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>The Origin of the Domestic Pig: Independent Do...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1073/pnas.96.16.9252</td>\n",
       "      <td>122095374</td>\n",
       "      <td>We previously mapped a quantitative trait locu...</td>\n",
       "      <td>This paper shows how the identity-by-descent a...</td>\n",
       "      <td>This study reports the fine-mapping of a QTL f...</td>\n",
       "      <td>Reference 53 reports fine-mapping of a QTL for...</td>\n",
       "      <td>The QTL was fine-mapped to a 5 cM region on BT...</td>\n",
       "      <td>This study uses high-density marker genotyping...</td>\n",
       "      <td>This study fine-maps a milk production QTL on ...</td>\n",
       "      <td>2082900742</td>\n",
       "      <td>125754415</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Fine-mapping of quantitative trait loci by ide...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1101/gr.10.2.220</td>\n",
       "      <td>100831446</td>\n",
       "      <td>A genome-wide linkage disequilibrium (LD) map ...</td>\n",
       "      <td>The pattern of linkage disequilibrium (LD) acr...</td>\n",
       "      <td>This study provides the first genome-wide LD m...</td>\n",
       "      <td>This study documents an unusually strong and l...</td>\n",
       "      <td>The authors provide evidence that linkage dise...</td>\n",
       "      <td>This study generates a genome-wide linkage dis...</td>\n",
       "      <td>This study reports high levels of both synteni...</td>\n",
       "      <td>2103106090</td>\n",
       "      <td>43092948</td>\n",
       "      <td>2000</td>\n",
       "      <td>17</td>\n",
       "      <td>Biochemistry, Genetics and Molecular Biology</td>\n",
       "      <td>Extensive Genome-wide Linkage Disequilibrium i...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1126/science.8134840</td>\n",
       "      <td>17452622</td>\n",
       "      <td>The European wild boar was crossed with the do...</td>\n",
       "      <td>The first paper to show the use of divergent i...</td>\n",
       "      <td>This study identifies a major QTL on chromosom...</td>\n",
       "      <td>This study identifies a major QTL on pig chrom...</td>\n",
       "      <td>This study reports a major QTL on SSC4 for fat...</td>\n",
       "      <td>This study identifies a major quantitative tra...</td>\n",
       "      <td>This study identifies quantitative trait loci ...</td>\n",
       "      <td>2045457895</td>\n",
       "      <td>3880285</td>\n",
       "      <td>1994</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Genetic mapping of quantitative trait loci for...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68287</th>\n",
       "      <td>10.2337/db08-1168</td>\n",
       "      <td>4860455</td>\n",
       "      <td>OBJECTIVE—Regulatory T-cells (Tregs) have cata...</td>\n",
       "      <td>This article describes the good manufacturing ...</td>\n",
       "      <td>This study demonstrates that CD4+CD127lo/−CD25...</td>\n",
       "      <td>This study provides a method for isolation and...</td>\n",
       "      <td>This study demonstrates that Tregs can be expa...</td>\n",
       "      <td>This study evaluates methods for isolating and...</td>\n",
       "      <td>This study demonstrates that CD4+CD127lo/−CD25...</td>\n",
       "      <td>2137227986</td>\n",
       "      <td>129060628</td>\n",
       "      <td>2009</td>\n",
       "      <td>17</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>Experience and Activity-Dependent Maturation o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68288</th>\n",
       "      <td>10.1126/science.aar3246</td>\n",
       "      <td>4860145</td>\n",
       "      <td>Engineering cytokine-receptor pairs Interleuki...</td>\n",
       "      <td>This study reports the generation of an orthog...</td>\n",
       "      <td>This study reports the engineering of orthogon...</td>\n",
       "      <td>This study describes an engineered IL-2/IL-2R ...</td>\n",
       "      <td>This study presents an engineered IL-2 partial...</td>\n",
       "      <td>This study engineers synthetic IL-2–receptor p...</td>\n",
       "      <td>This study describes engineered orthogonal IL-...</td>\n",
       "      <td>2789780246</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>A Clonogenic Bone Marrow Progenitor Specific f...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68289</th>\n",
       "      <td>10.1126/science.aad2791</td>\n",
       "      <td>62290395</td>\n",
       "      <td>T cells target peptide combos One of the endur...</td>\n",
       "      <td>This article shows that some diabetogenic T ce...</td>\n",
       "      <td>This study identifies hybrid insulin peptides ...</td>\n",
       "      <td>This study reports the identification of hybri...</td>\n",
       "      <td>This study highlights the potential importance...</td>\n",
       "      <td>This study identifies hybrid peptides—covalent...</td>\n",
       "      <td>This study identifies hybrid peptides formed b...</td>\n",
       "      <td>2266478788</td>\n",
       "      <td>3880285</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Single-cell RNA-seq highlights intratumoral he...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68290</th>\n",
       "      <td>10.1073/pnas.1902566116</td>\n",
       "      <td>82979762</td>\n",
       "      <td>Polymorphic HLAs form the primary immune barri...</td>\n",
       "      <td>This article describes the development of gene...</td>\n",
       "      <td>This study demonstrates a multiplex genome-edi...</td>\n",
       "      <td>This work reports on a cell engineering strate...</td>\n",
       "      <td>This study identifies a strategy for broad imm...</td>\n",
       "      <td>This study describes a dual strategy to engine...</td>\n",
       "      <td>This work describes a multiplex genome editing...</td>\n",
       "      <td>2943378944</td>\n",
       "      <td>125754415</td>\n",
       "      <td>2019</td>\n",
       "      <td>17</td>\n",
       "      <td>Multidisciplinary</td>\n",
       "      <td>Iterative fractionation of recycling receptors...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68291</th>\n",
       "      <td>10.4049/jimmunol.167.3.1245</td>\n",
       "      <td>20436631</td>\n",
       "      <td>Abstract Thymectomy in mice on neonatal day 3 ...</td>\n",
       "      <td>Together with Levings et al. (2001), Jonuleit ...</td>\n",
       "      <td>This study identifies and characterizes human ...</td>\n",
       "      <td>This study identifies and characterizes a popu...</td>\n",
       "      <td>This study identified a population of CD4+ T c...</td>\n",
       "      <td>This study identifies CD4+CD25high regulatory ...</td>\n",
       "      <td>This study identifies CD4+CD25high regulatory ...</td>\n",
       "      <td>1560277370</td>\n",
       "      <td>38008053</td>\n",
       "      <td>2001</td>\n",
       "      <td>17</td>\n",
       "      <td>Immunology and Microbiology</td>\n",
       "      <td>Novel Analytic Criteria and Effective Plate De...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68292 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi   paper_id  \\\n",
       "0           10.1073/pnas.91.7.2757  107202074   \n",
       "1      10.1093/genetics/154.4.1785   83366887   \n",
       "2          10.1073/pnas.96.16.9252  122095374   \n",
       "3              10.1101/gr.10.2.220  100831446   \n",
       "4          10.1126/science.8134840   17452622   \n",
       "...                            ...        ...   \n",
       "68287            10.2337/db08-1168    4860455   \n",
       "68288      10.1126/science.aar3246    4860145   \n",
       "68289      10.1126/science.aad2791   62290395   \n",
       "68290      10.1073/pnas.1902566116   82979762   \n",
       "68291  10.4049/jimmunol.167.3.1245   20436631   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      The origin and taxonomic status of domesticate...   \n",
       "1      Abstract The domestic pig originates from the ...   \n",
       "2      We previously mapped a quantitative trait locu...   \n",
       "3      A genome-wide linkage disequilibrium (LD) map ...   \n",
       "4      The European wild boar was crossed with the do...   \n",
       "...                                                  ...   \n",
       "68287  OBJECTIVE—Regulatory T-cells (Tregs) have cata...   \n",
       "68288  Engineering cytokine-receptor pairs Interleuki...   \n",
       "68289  T cells target peptide combos One of the endur...   \n",
       "68290  Polymorphic HLAs form the primary immune barri...   \n",
       "68291  Abstract Thymectomy in mice on neonatal day 3 ...   \n",
       "\n",
       "                                              annotation  \\\n",
       "0      A demonstration that cattle have been domestic...   \n",
       "1      Evidence is presented for independent domestic...   \n",
       "2      This paper shows how the identity-by-descent a...   \n",
       "3      The pattern of linkage disequilibrium (LD) acr...   \n",
       "4      The first paper to show the use of divergent i...   \n",
       "...                                                  ...   \n",
       "68287  This article describes the good manufacturing ...   \n",
       "68288  This study reports the generation of an orthog...   \n",
       "68289  This article shows that some diabetogenic T ce...   \n",
       "68290  This article describes the development of gene...   \n",
       "68291  Together with Levings et al. (2001), Jonuleit ...   \n",
       "\n",
       "                                             deepseek_v3  \\\n",
       "0      This study provides genetic evidence for two i...   \n",
       "1      This study provides genetic evidence for indep...   \n",
       "2      This study reports the fine-mapping of a QTL f...   \n",
       "3      This study provides the first genome-wide LD m...   \n",
       "4      This study identifies a major QTL on chromosom...   \n",
       "...                                                  ...   \n",
       "68287  This study demonstrates that CD4+CD127lo/−CD25...   \n",
       "68288  This study reports the engineering of orthogon...   \n",
       "68289  This study identifies hybrid insulin peptides ...   \n",
       "68290  This study demonstrates a multiplex genome-edi...   \n",
       "68291  This study identifies and characterizes human ...   \n",
       "\n",
       "                                                  gemma3  \\\n",
       "0      Reference 16 provides a molecular phylogeny of...   \n",
       "1      This study demonstrates independent domesticat...   \n",
       "2      Reference 53 reports fine-mapping of a QTL for...   \n",
       "3      This study documents an unusually strong and l...   \n",
       "4      This study identifies a major QTL on pig chrom...   \n",
       "...                                                  ...   \n",
       "68287  This study provides a method for isolation and...   \n",
       "68288  This study describes an engineered IL-2/IL-2R ...   \n",
       "68289  This study reports the identification of hybri...   \n",
       "68290  This work reports on a cell engineering strate...   \n",
       "68291  This study identifies and characterizes a popu...   \n",
       "\n",
       "                                                  llama4  \\\n",
       "0      This study proposes that zebu and taurine catt...   \n",
       "1      This study reports the origin of European and ...   \n",
       "2      The QTL was fine-mapped to a 5 cM region on BT...   \n",
       "3      The authors provide evidence that linkage dise...   \n",
       "4      This study reports a major QTL on SSC4 for fat...   \n",
       "...                                                  ...   \n",
       "68287  This study demonstrates that Tregs can be expa...   \n",
       "68288  This study presents an engineered IL-2 partial...   \n",
       "68289  This study highlights the potential importance...   \n",
       "68290  This study identifies a strategy for broad imm...   \n",
       "68291  This study identified a population of CD4+ T c...   \n",
       "\n",
       "                                                     qwq  \\\n",
       "0      This study uses mitochondrial DNA analysis to ...   \n",
       "1      This study uses mitochondrial and nuclear DNA ...   \n",
       "2      This study uses high-density marker genotyping...   \n",
       "3      This study generates a genome-wide linkage dis...   \n",
       "4      This study identifies a major quantitative tra...   \n",
       "...                                                  ...   \n",
       "68287  This study evaluates methods for isolating and...   \n",
       "68288  This study engineers synthetic IL-2–receptor p...   \n",
       "68289  This study identifies hybrid peptides—covalent...   \n",
       "68290  This study describes a dual strategy to engine...   \n",
       "68291  This study identifies CD4+CD25high regulatory ...   \n",
       "\n",
       "                                                   qwen3     mag_pid  \\\n",
       "0      This study analyzes mitochondrial DNA diversit...  2005395185   \n",
       "1      This study demonstrates independent domesticat...  2110049233   \n",
       "2      This study fine-maps a milk production QTL on ...  2082900742   \n",
       "3      This study reports high levels of both synteni...  2103106090   \n",
       "4      This study identifies quantitative trait loci ...  2045457895   \n",
       "...                                                  ...         ...   \n",
       "68287  This study demonstrates that CD4+CD127lo/−CD25...  2137227986   \n",
       "68288  This study describes engineered orthogonal IL-...  2789780246   \n",
       "68289  This study identifies hybrid peptides formed b...  2266478788   \n",
       "68290  This work describes a multiplex genome editing...  2943378944   \n",
       "68291  This study identifies CD4+CD25high regulatory ...  1560277370   \n",
       "\n",
       "         mag_vid  year  p2v_label  \\\n",
       "0      125754415  1994         17   \n",
       "1       65932378  2000         17   \n",
       "2      125754415  1999         17   \n",
       "3       43092948  2000         17   \n",
       "4        3880285  1994          8   \n",
       "...          ...   ...        ...   \n",
       "68287  129060628  2009         17   \n",
       "68288    3880285  2018          8   \n",
       "68289    3880285  2016          8   \n",
       "68290  125754415  2019         17   \n",
       "68291   38008053  2001         17   \n",
       "\n",
       "                                       scopus_label  \\\n",
       "0                                 Multidisciplinary   \n",
       "1      Biochemistry, Genetics and Molecular Biology   \n",
       "2                                 Multidisciplinary   \n",
       "3      Biochemistry, Genetics and Molecular Biology   \n",
       "4                                 Multidisciplinary   \n",
       "...                                             ...   \n",
       "68287                                      Medicine   \n",
       "68288                             Multidisciplinary   \n",
       "68289                             Multidisciplinary   \n",
       "68290                             Multidisciplinary   \n",
       "68291                   Immunology and Microbiology   \n",
       "\n",
       "                                                   title  title_paired  \n",
       "0      Evidence for two independent domestications of...          True  \n",
       "1      The Origin of the Domestic Pig: Independent Do...          True  \n",
       "2      Fine-mapping of quantitative trait loci by ide...          True  \n",
       "3      Extensive Genome-wide Linkage Disequilibrium i...          True  \n",
       "4      Genetic mapping of quantitative trait loci for...          True  \n",
       "...                                                  ...           ...  \n",
       "68287  Experience and Activity-Dependent Maturation o...         False  \n",
       "68288  A Clonogenic Bone Marrow Progenitor Specific f...         False  \n",
       "68289  Single-cell RNA-seq highlights intratumoral he...         False  \n",
       "68290  Iterative fractionation of recycling receptors...         False  \n",
       "68291  Novel Analytic Criteria and Effective Plate De...         False  \n",
       "\n",
       "[68292 rows x 16 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_match_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe462cf6",
   "metadata": {},
   "source": [
    "### 10-CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4e904",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3833dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents:   0%|                                                                                                            | 0/68292 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:04<00:00, 15976.39it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    5.3s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.5499±0.0056 | F1: 0.5498±0.0070\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:00<00:00, 72535.34it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.2s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.6618±0.0051 | F1: 0.6569±0.0062\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 46628.61it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.7557±0.0062 | F1: 0.7537±0.0069\n",
      "Processing feature: qwen3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:02<00:00, 32650.61it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwen3 | Accuracy: 0.7139±0.0055 | F1: 0.7124±0.0040\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 64844.09it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.3s remaining:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.7577±0.0038 | F1: 0.7544±0.0045\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:01<00:00, 38042.45it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    4.6s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.6843±0.0058 | F1: 0.6779±0.0066\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing documents: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 68292/68292 [00:02<00:00, 30616.49it/s]\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 256 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    3.4s remaining:    3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.6742±0.0061 | F1: 0.6738±0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.549933</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.549973</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.549904</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.549849</td>\n",
       "      <td>0.006991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.661805</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.666455</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.647740</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.006182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.759852</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.747601</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.753659</td>\n",
       "      <td>0.006902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen3</td>\n",
       "      <td>0.713920</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.716325</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.712379</td>\n",
       "      <td>0.004045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.757658</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.764547</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.744599</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.754423</td>\n",
       "      <td>0.004546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.684282</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.691811</td>\n",
       "      <td>0.009807</td>\n",
       "      <td>0.664674</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>0.677939</td>\n",
       "      <td>0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.674222</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.674641</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.673095</td>\n",
       "      <td>0.008468</td>\n",
       "      <td>0.673829</td>\n",
       "      <td>0.005692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  \\\n",
       "0     abstract       0.549933      0.005592        0.549973       0.007610   \n",
       "1   annotation       0.661805      0.005107        0.666455       0.007536   \n",
       "2  deepseek_v3       0.755682      0.006233        0.759852       0.007990   \n",
       "3        qwen3       0.713920      0.005532        0.716325       0.007133   \n",
       "4       gemma3       0.757658      0.003785        0.764547       0.006018   \n",
       "5       llama4       0.684282      0.005826        0.691811       0.009807   \n",
       "6          qwq       0.674222      0.006091        0.674641       0.006608   \n",
       "\n",
       "   Recall_mean  Recall_std   F1_mean    F1_std  \n",
       "0     0.549904    0.011833  0.549849  0.006991  \n",
       "1     0.647740    0.006525  0.656947  0.006182  \n",
       "2     0.747601    0.007543  0.753659  0.006902  \n",
       "3     0.708609    0.008824  0.712379  0.004045  \n",
       "4     0.744599    0.005684  0.754423  0.004546  \n",
       "5     0.664674    0.006120  0.677939  0.006620  \n",
       "6     0.673095    0.008468  0.673829  0.005692  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ProgressHashingVectorizer(HashingVectorizer):\n",
    "    \"\"\"带进度条的HashingVectorizer\"\"\"\n",
    "    def transform(self, X):\n",
    "        if hasattr(X, '__len__'):\n",
    "            self.n_samples_ = len(X)\n",
    "            wrapped_X = tqdm(X, desc=\"Vectorizing documents\", total=self.n_samples_)\n",
    "            return super().transform(wrapped_X)\n",
    "        return super().transform(X)\n",
    "\n",
    "# 评价指标\n",
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'qwen3','gemma3', 'llama4', 'qwq']\n",
    "y = title_match_df['title_paired'].astype(int)  # 1: 匹配，0: 不匹配\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "for feat in text_features:\n",
    "    print(f\"Processing feature: {feat}\")\n",
    "    # 拼接title和对应的feature\n",
    "    X_text = (title_match_df['title'].astype(str).fillna('') + ' [SEP] ' + title_match_df[feat].astype(str).fillna(''))\n",
    "    vectorizer = ProgressHashingVectorizer(n_features=2**20, stop_words='english', alternate_sign=False)\n",
    "    X = vectorizer.transform(X_text)\n",
    "    model = LogisticRegression(max_iter=2000, random_state=42)\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring, n_jobs=-1, verbose=1, return_train_score=False)\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy_mean': scores['test_Accuracy'].mean(),\n",
    "        'Accuracy_std': scores['test_Accuracy'].std(),\n",
    "        'Precision_mean': scores['test_Precision'].mean(),\n",
    "        'Precision_std': scores['test_Precision'].std(),\n",
    "        'Recall_mean': scores['test_Recall'].mean(),\n",
    "        'Recall_std': scores['test_Recall'].std(),\n",
    "        'F1_mean': scores['test_F1'].mean(),\n",
    "        'F1_std': scores['test_F1'].std(),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy_mean']:.4f}±{res['Accuracy_std']:.4f} | \"\n",
    "        f\"F1: {res['F1_mean']:.4f}±{res['F1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e046c",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a441afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing feature: abstract\n",
      "  Fold 1/10\n",
      "    No cached model found for abstract fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.144475</td>\n",
       "      <td>0.950220</td>\n",
       "      <td>0.920943</td>\n",
       "      <td>0.983704</td>\n",
       "      <td>0.951289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>0.979209</td>\n",
       "      <td>0.980958</td>\n",
       "      <td>0.976889</td>\n",
       "      <td>0.978919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.062204</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.979351</td>\n",
       "      <td>0.983704</td>\n",
       "      <td>0.981523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.055013</td>\n",
       "      <td>0.983163</td>\n",
       "      <td>0.983967</td>\n",
       "      <td>0.981926</td>\n",
       "      <td>0.982945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for abstract fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.114086</td>\n",
       "      <td>0.959590</td>\n",
       "      <td>0.973097</td>\n",
       "      <td>0.944230</td>\n",
       "      <td>0.958446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.076906</td>\n",
       "      <td>0.974817</td>\n",
       "      <td>0.970580</td>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.974594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.063834</td>\n",
       "      <td>0.979941</td>\n",
       "      <td>0.974194</td>\n",
       "      <td>0.985464</td>\n",
       "      <td>0.979796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.062969</td>\n",
       "      <td>0.981991</td>\n",
       "      <td>0.982185</td>\n",
       "      <td>0.981311</td>\n",
       "      <td>0.981748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for abstract fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.109970</td>\n",
       "      <td>0.962220</td>\n",
       "      <td>0.978916</td>\n",
       "      <td>0.945317</td>\n",
       "      <td>0.961823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.074526</td>\n",
       "      <td>0.973203</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.981675</td>\n",
       "      <td>0.973605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.077600</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.985503</td>\n",
       "      <td>0.986593</td>\n",
       "      <td>0.984584</td>\n",
       "      <td>0.985587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.043904</td>\n",
       "      <td>0.985357</td>\n",
       "      <td>0.989730</td>\n",
       "      <td>0.981094</td>\n",
       "      <td>0.985393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for abstract fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.100765</td>\n",
       "      <td>0.963538</td>\n",
       "      <td>0.962424</td>\n",
       "      <td>0.964953</td>\n",
       "      <td>0.963687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.073258</td>\n",
       "      <td>0.974228</td>\n",
       "      <td>0.979905</td>\n",
       "      <td>0.968458</td>\n",
       "      <td>0.974148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.077700</td>\n",
       "      <td>0.061766</td>\n",
       "      <td>0.978913</td>\n",
       "      <td>0.986358</td>\n",
       "      <td>0.971379</td>\n",
       "      <td>0.978811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.052882</td>\n",
       "      <td>0.982721</td>\n",
       "      <td>0.981924</td>\n",
       "      <td>0.983645</td>\n",
       "      <td>0.982784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for abstract fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.111551</td>\n",
       "      <td>0.964124</td>\n",
       "      <td>0.951749</td>\n",
       "      <td>0.978532</td>\n",
       "      <td>0.964955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.089762</td>\n",
       "      <td>0.970860</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.978822</td>\n",
       "      <td>0.971355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.064326</td>\n",
       "      <td>0.979499</td>\n",
       "      <td>0.975827</td>\n",
       "      <td>0.983754</td>\n",
       "      <td>0.979775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.059677</td>\n",
       "      <td>0.983453</td>\n",
       "      <td>0.980681</td>\n",
       "      <td>0.986655</td>\n",
       "      <td>0.983659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for abstract fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.102068</td>\n",
       "      <td>0.962659</td>\n",
       "      <td>0.973057</td>\n",
       "      <td>0.949245</td>\n",
       "      <td>0.961003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.069789</td>\n",
       "      <td>0.977010</td>\n",
       "      <td>0.978452</td>\n",
       "      <td>0.974018</td>\n",
       "      <td>0.976230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.059580</td>\n",
       "      <td>0.980085</td>\n",
       "      <td>0.977724</td>\n",
       "      <td>0.981269</td>\n",
       "      <td>0.979493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.053397</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>0.982743</td>\n",
       "      <td>0.980665</td>\n",
       "      <td>0.981703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for abstract fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.097671</td>\n",
       "      <td>0.965441</td>\n",
       "      <td>0.965447</td>\n",
       "      <td>0.966008</td>\n",
       "      <td>0.965728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.068281</td>\n",
       "      <td>0.977742</td>\n",
       "      <td>0.970807</td>\n",
       "      <td>0.985474</td>\n",
       "      <td>0.978085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.050088</td>\n",
       "      <td>0.984332</td>\n",
       "      <td>0.986293</td>\n",
       "      <td>0.982568</td>\n",
       "      <td>0.984427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.048498</td>\n",
       "      <td>0.986235</td>\n",
       "      <td>0.986345</td>\n",
       "      <td>0.986345</td>\n",
       "      <td>0.986345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for abstract fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.124458</td>\n",
       "      <td>0.954459</td>\n",
       "      <td>0.933054</td>\n",
       "      <td>0.979215</td>\n",
       "      <td>0.955578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.983041</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.975063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.060822</td>\n",
       "      <td>0.980964</td>\n",
       "      <td>0.982384</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.980944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.061258</td>\n",
       "      <td>0.981110</td>\n",
       "      <td>0.988991</td>\n",
       "      <td>0.973068</td>\n",
       "      <td>0.980965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for abstract fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.114516</td>\n",
       "      <td>0.957827</td>\n",
       "      <td>0.962833</td>\n",
       "      <td>0.953347</td>\n",
       "      <td>0.958066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.080973</td>\n",
       "      <td>0.971445</td>\n",
       "      <td>0.968354</td>\n",
       "      <td>0.975369</td>\n",
       "      <td>0.971849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.085760</td>\n",
       "      <td>0.973788</td>\n",
       "      <td>0.958520</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.974498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>0.982428</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.985801</td>\n",
       "      <td>0.982669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for abstract fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.959291</td>\n",
       "      <td>0.948092</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.960489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.083727</td>\n",
       "      <td>0.972324</td>\n",
       "      <td>0.971560</td>\n",
       "      <td>0.974078</td>\n",
       "      <td>0.972817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.074588</td>\n",
       "      <td>0.976278</td>\n",
       "      <td>0.965672</td>\n",
       "      <td>0.988479</td>\n",
       "      <td>0.976943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.054834</td>\n",
       "      <td>0.982281</td>\n",
       "      <td>0.983271</td>\n",
       "      <td>0.981855</td>\n",
       "      <td>0.982562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.9831±0.0015 | F1: 0.9831±0.0016\n",
      "\n",
      "Processing feature: annotation\n",
      "  Fold 1/10\n",
      "    No cached model found for annotation fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.249539</td>\n",
       "      <td>0.909663</td>\n",
       "      <td>0.885411</td>\n",
       "      <td>0.938667</td>\n",
       "      <td>0.911261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.188467</td>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.942814</td>\n",
       "      <td>0.923259</td>\n",
       "      <td>0.932934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.180557</td>\n",
       "      <td>0.930893</td>\n",
       "      <td>0.920847</td>\n",
       "      <td>0.941037</td>\n",
       "      <td>0.930832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.158873</td>\n",
       "      <td>0.940703</td>\n",
       "      <td>0.958616</td>\n",
       "      <td>0.919704</td>\n",
       "      <td>0.938757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for annotation fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.254800</td>\n",
       "      <td>0.231830</td>\n",
       "      <td>0.913470</td>\n",
       "      <td>0.914184</td>\n",
       "      <td>0.910116</td>\n",
       "      <td>0.912145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.219524</td>\n",
       "      <td>0.921083</td>\n",
       "      <td>0.963654</td>\n",
       "      <td>0.873035</td>\n",
       "      <td>0.916109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.191400</td>\n",
       "      <td>0.191747</td>\n",
       "      <td>0.930454</td>\n",
       "      <td>0.925382</td>\n",
       "      <td>0.934441</td>\n",
       "      <td>0.929889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.179606</td>\n",
       "      <td>0.935578</td>\n",
       "      <td>0.950507</td>\n",
       "      <td>0.917235</td>\n",
       "      <td>0.933575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for annotation fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>0.236020</td>\n",
       "      <td>0.910821</td>\n",
       "      <td>0.932701</td>\n",
       "      <td>0.886853</td>\n",
       "      <td>0.909199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.196895</td>\n",
       "      <td>0.925611</td>\n",
       "      <td>0.930123</td>\n",
       "      <td>0.921466</td>\n",
       "      <td>0.925774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.173719</td>\n",
       "      <td>0.934983</td>\n",
       "      <td>0.942637</td>\n",
       "      <td>0.927283</td>\n",
       "      <td>0.934897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.163054</td>\n",
       "      <td>0.938937</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.928447</td>\n",
       "      <td>0.938685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for annotation fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.262800</td>\n",
       "      <td>0.225440</td>\n",
       "      <td>0.916532</td>\n",
       "      <td>0.957079</td>\n",
       "      <td>0.872664</td>\n",
       "      <td>0.912924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.184106</td>\n",
       "      <td>0.930444</td>\n",
       "      <td>0.922614</td>\n",
       "      <td>0.940129</td>\n",
       "      <td>0.931289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.160975</td>\n",
       "      <td>0.940401</td>\n",
       "      <td>0.953684</td>\n",
       "      <td>0.926110</td>\n",
       "      <td>0.939695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.155825</td>\n",
       "      <td>0.943330</td>\n",
       "      <td>0.948067</td>\n",
       "      <td>0.938376</td>\n",
       "      <td>0.943197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for annotation fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.228900</td>\n",
       "      <td>0.221784</td>\n",
       "      <td>0.917850</td>\n",
       "      <td>0.923664</td>\n",
       "      <td>0.912678</td>\n",
       "      <td>0.918138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.190014</td>\n",
       "      <td>0.930883</td>\n",
       "      <td>0.962100</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.929193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.172308</td>\n",
       "      <td>0.936740</td>\n",
       "      <td>0.958625</td>\n",
       "      <td>0.914128</td>\n",
       "      <td>0.935848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.174760</td>\n",
       "      <td>0.936301</td>\n",
       "      <td>0.973287</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.934379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for annotation fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>0.248560</td>\n",
       "      <td>0.902328</td>\n",
       "      <td>0.909767</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.897934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.197424</td>\n",
       "      <td>0.926636</td>\n",
       "      <td>0.938769</td>\n",
       "      <td>0.907855</td>\n",
       "      <td>0.923053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.180065</td>\n",
       "      <td>0.931322</td>\n",
       "      <td>0.938020</td>\n",
       "      <td>0.919033</td>\n",
       "      <td>0.928430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.171060</td>\n",
       "      <td>0.933958</td>\n",
       "      <td>0.947979</td>\n",
       "      <td>0.913897</td>\n",
       "      <td>0.930626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for annotation fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.228288</td>\n",
       "      <td>0.914482</td>\n",
       "      <td>0.938344</td>\n",
       "      <td>0.888727</td>\n",
       "      <td>0.912862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.197104</td>\n",
       "      <td>0.927954</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.922429</td>\n",
       "      <td>0.928091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.175032</td>\n",
       "      <td>0.935276</td>\n",
       "      <td>0.951264</td>\n",
       "      <td>0.918652</td>\n",
       "      <td>0.934673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.166469</td>\n",
       "      <td>0.939083</td>\n",
       "      <td>0.966687</td>\n",
       "      <td>0.910517</td>\n",
       "      <td>0.937762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for annotation fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>0.238214</td>\n",
       "      <td>0.909943</td>\n",
       "      <td>0.934803</td>\n",
       "      <td>0.881440</td>\n",
       "      <td>0.907338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.196319</td>\n",
       "      <td>0.928979</td>\n",
       "      <td>0.956969</td>\n",
       "      <td>0.898419</td>\n",
       "      <td>0.926770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.175843</td>\n",
       "      <td>0.933519</td>\n",
       "      <td>0.942883</td>\n",
       "      <td>0.923009</td>\n",
       "      <td>0.932840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.188400</td>\n",
       "      <td>0.167554</td>\n",
       "      <td>0.937326</td>\n",
       "      <td>0.962825</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.935581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for annotation fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.222328</td>\n",
       "      <td>0.916093</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.890177</td>\n",
       "      <td>0.914694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.216800</td>\n",
       "      <td>0.181193</td>\n",
       "      <td>0.935569</td>\n",
       "      <td>0.939306</td>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.936028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.170431</td>\n",
       "      <td>0.939962</td>\n",
       "      <td>0.966268</td>\n",
       "      <td>0.913069</td>\n",
       "      <td>0.938915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.158092</td>\n",
       "      <td>0.942744</td>\n",
       "      <td>0.961399</td>\n",
       "      <td>0.923790</td>\n",
       "      <td>0.942220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for annotation fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.224705</td>\n",
       "      <td>0.916386</td>\n",
       "      <td>0.932082</td>\n",
       "      <td>0.901210</td>\n",
       "      <td>0.916386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.193702</td>\n",
       "      <td>0.930444</td>\n",
       "      <td>0.952309</td>\n",
       "      <td>0.908698</td>\n",
       "      <td>0.929993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.192400</td>\n",
       "      <td>0.173701</td>\n",
       "      <td>0.937912</td>\n",
       "      <td>0.950888</td>\n",
       "      <td>0.925691</td>\n",
       "      <td>0.938120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.169993</td>\n",
       "      <td>0.937180</td>\n",
       "      <td>0.966575</td>\n",
       "      <td>0.907834</td>\n",
       "      <td>0.936284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.9386±0.0029 | F1: 0.9373±0.0036\n",
      "\n",
      "Processing feature: deepseek_v3\n",
      "  Fold 1/10\n",
      "    No cached model found for deepseek_v3 fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.089100</td>\n",
       "      <td>0.095076</td>\n",
       "      <td>0.967204</td>\n",
       "      <td>0.946697</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.967546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>0.984627</td>\n",
       "      <td>0.990696</td>\n",
       "      <td>0.978074</td>\n",
       "      <td>0.984345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.057711</td>\n",
       "      <td>0.983309</td>\n",
       "      <td>0.976615</td>\n",
       "      <td>0.989926</td>\n",
       "      <td>0.983225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.041484</td>\n",
       "      <td>0.988873</td>\n",
       "      <td>0.991654</td>\n",
       "      <td>0.985778</td>\n",
       "      <td>0.988707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for deepseek_v3 fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.065569</td>\n",
       "      <td>0.979649</td>\n",
       "      <td>0.983254</td>\n",
       "      <td>0.975378</td>\n",
       "      <td>0.979300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.068965</td>\n",
       "      <td>0.981113</td>\n",
       "      <td>0.971769</td>\n",
       "      <td>0.990507</td>\n",
       "      <td>0.981049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>0.985359</td>\n",
       "      <td>0.993363</td>\n",
       "      <td>0.976861</td>\n",
       "      <td>0.985043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.043716</td>\n",
       "      <td>0.987262</td>\n",
       "      <td>0.988400</td>\n",
       "      <td>0.985761</td>\n",
       "      <td>0.987079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for deepseek_v3 fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.062119</td>\n",
       "      <td>0.980231</td>\n",
       "      <td>0.977174</td>\n",
       "      <td>0.983711</td>\n",
       "      <td>0.980432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.052886</td>\n",
       "      <td>0.984771</td>\n",
       "      <td>0.980958</td>\n",
       "      <td>0.988947</td>\n",
       "      <td>0.984936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.049870</td>\n",
       "      <td>0.986089</td>\n",
       "      <td>0.994380</td>\n",
       "      <td>0.977894</td>\n",
       "      <td>0.986068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.038202</td>\n",
       "      <td>0.987846</td>\n",
       "      <td>0.987787</td>\n",
       "      <td>0.988074</td>\n",
       "      <td>0.987931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for deepseek_v3 fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>0.069905</td>\n",
       "      <td>0.981110</td>\n",
       "      <td>0.976018</td>\n",
       "      <td>0.986565</td>\n",
       "      <td>0.981264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.056958</td>\n",
       "      <td>0.985064</td>\n",
       "      <td>0.988817</td>\n",
       "      <td>0.981308</td>\n",
       "      <td>0.985048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.057262</td>\n",
       "      <td>0.984478</td>\n",
       "      <td>0.981428</td>\n",
       "      <td>0.987734</td>\n",
       "      <td>0.984571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.059822</td>\n",
       "      <td>0.982574</td>\n",
       "      <td>0.975813</td>\n",
       "      <td>0.989778</td>\n",
       "      <td>0.982746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for deepseek_v3 fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.070344</td>\n",
       "      <td>0.978181</td>\n",
       "      <td>0.975490</td>\n",
       "      <td>0.981433</td>\n",
       "      <td>0.978453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.053628</td>\n",
       "      <td>0.984624</td>\n",
       "      <td>0.985474</td>\n",
       "      <td>0.984044</td>\n",
       "      <td>0.984758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>0.986235</td>\n",
       "      <td>0.987213</td>\n",
       "      <td>0.985495</td>\n",
       "      <td>0.986353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.040800</td>\n",
       "      <td>0.047822</td>\n",
       "      <td>0.986674</td>\n",
       "      <td>0.987507</td>\n",
       "      <td>0.986075</td>\n",
       "      <td>0.986791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for deepseek_v3 fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.069922</td>\n",
       "      <td>0.977156</td>\n",
       "      <td>0.966017</td>\n",
       "      <td>0.987613</td>\n",
       "      <td>0.976696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.055947</td>\n",
       "      <td>0.984478</td>\n",
       "      <td>0.977924</td>\n",
       "      <td>0.990332</td>\n",
       "      <td>0.984089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.042921</td>\n",
       "      <td>0.986674</td>\n",
       "      <td>0.988171</td>\n",
       "      <td>0.984290</td>\n",
       "      <td>0.986227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.043106</td>\n",
       "      <td>0.986235</td>\n",
       "      <td>0.985801</td>\n",
       "      <td>0.985801</td>\n",
       "      <td>0.985801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for deepseek_v3 fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.059986</td>\n",
       "      <td>0.978767</td>\n",
       "      <td>0.968723</td>\n",
       "      <td>0.989831</td>\n",
       "      <td>0.979164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.050398</td>\n",
       "      <td>0.983453</td>\n",
       "      <td>0.973812</td>\n",
       "      <td>0.993899</td>\n",
       "      <td>0.983753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.031169</td>\n",
       "      <td>0.990775</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.988960</td>\n",
       "      <td>0.990831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.030314</td>\n",
       "      <td>0.991214</td>\n",
       "      <td>0.990429</td>\n",
       "      <td>0.992156</td>\n",
       "      <td>0.991292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for deepseek_v3 fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.089700</td>\n",
       "      <td>0.069417</td>\n",
       "      <td>0.978474</td>\n",
       "      <td>0.969549</td>\n",
       "      <td>0.987998</td>\n",
       "      <td>0.978686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>0.046525</td>\n",
       "      <td>0.986235</td>\n",
       "      <td>0.987383</td>\n",
       "      <td>0.985070</td>\n",
       "      <td>0.986225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.042950</td>\n",
       "      <td>0.985942</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.980094</td>\n",
       "      <td>0.985866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>0.042215</td>\n",
       "      <td>0.987260</td>\n",
       "      <td>0.987980</td>\n",
       "      <td>0.986534</td>\n",
       "      <td>0.987256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for deepseek_v3 fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.066226</td>\n",
       "      <td>0.979060</td>\n",
       "      <td>0.973926</td>\n",
       "      <td>0.984932</td>\n",
       "      <td>0.979398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.049372</td>\n",
       "      <td>0.984624</td>\n",
       "      <td>0.988895</td>\n",
       "      <td>0.980585</td>\n",
       "      <td>0.984723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.053215</td>\n",
       "      <td>0.984771</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.992466</td>\n",
       "      <td>0.985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.042367</td>\n",
       "      <td>0.985796</td>\n",
       "      <td>0.990925</td>\n",
       "      <td>0.980875</td>\n",
       "      <td>0.985874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for deepseek_v3 fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.073852</td>\n",
       "      <td>0.975985</td>\n",
       "      <td>0.963565</td>\n",
       "      <td>0.990207</td>\n",
       "      <td>0.976705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.043983</td>\n",
       "      <td>0.986967</td>\n",
       "      <td>0.987043</td>\n",
       "      <td>0.987327</td>\n",
       "      <td>0.987185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.048968</td>\n",
       "      <td>0.985503</td>\n",
       "      <td>0.980621</td>\n",
       "      <td>0.991071</td>\n",
       "      <td>0.985819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.041335</td>\n",
       "      <td>0.987407</td>\n",
       "      <td>0.983714</td>\n",
       "      <td>0.991647</td>\n",
       "      <td>0.987665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.9874±0.0016 | F1: 0.9874±0.0016\n",
      "\n",
      "Processing feature: qwen3\n",
      "  Fold 1/10\n",
      "    No cached model found for qwen3 fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.088100</td>\n",
       "      <td>0.057291</td>\n",
       "      <td>0.982430</td>\n",
       "      <td>0.976574</td>\n",
       "      <td>0.988148</td>\n",
       "      <td>0.982327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.042756</td>\n",
       "      <td>0.986823</td>\n",
       "      <td>0.993391</td>\n",
       "      <td>0.979852</td>\n",
       "      <td>0.986575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.043925</td>\n",
       "      <td>0.987555</td>\n",
       "      <td>0.994886</td>\n",
       "      <td>0.979852</td>\n",
       "      <td>0.987312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.037516</td>\n",
       "      <td>0.989458</td>\n",
       "      <td>0.993722</td>\n",
       "      <td>0.984889</td>\n",
       "      <td>0.989286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for qwen3 fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.060876</td>\n",
       "      <td>0.980966</td>\n",
       "      <td>0.982723</td>\n",
       "      <td>0.978641</td>\n",
       "      <td>0.980678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.048268</td>\n",
       "      <td>0.985505</td>\n",
       "      <td>0.983452</td>\n",
       "      <td>0.987244</td>\n",
       "      <td>0.985344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.049779</td>\n",
       "      <td>0.985505</td>\n",
       "      <td>0.993366</td>\n",
       "      <td>0.977158</td>\n",
       "      <td>0.985195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.039760</td>\n",
       "      <td>0.986969</td>\n",
       "      <td>0.985503</td>\n",
       "      <td>0.988134</td>\n",
       "      <td>0.986817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for qwen3 fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.094545</td>\n",
       "      <td>0.968663</td>\n",
       "      <td>0.949777</td>\n",
       "      <td>0.990111</td>\n",
       "      <td>0.969524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.053806</td>\n",
       "      <td>0.983014</td>\n",
       "      <td>0.986526</td>\n",
       "      <td>0.979639</td>\n",
       "      <td>0.983071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.051899</td>\n",
       "      <td>0.984332</td>\n",
       "      <td>0.992606</td>\n",
       "      <td>0.976149</td>\n",
       "      <td>0.984309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.043382</td>\n",
       "      <td>0.986821</td>\n",
       "      <td>0.985781</td>\n",
       "      <td>0.988074</td>\n",
       "      <td>0.986926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for qwen3 fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.070223</td>\n",
       "      <td>0.977596</td>\n",
       "      <td>0.992472</td>\n",
       "      <td>0.962617</td>\n",
       "      <td>0.977317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.067400</td>\n",
       "      <td>0.046171</td>\n",
       "      <td>0.985503</td>\n",
       "      <td>0.983144</td>\n",
       "      <td>0.988026</td>\n",
       "      <td>0.985579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.041859</td>\n",
       "      <td>0.986967</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.985981</td>\n",
       "      <td>0.986990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.053845</td>\n",
       "      <td>0.985503</td>\n",
       "      <td>0.978969</td>\n",
       "      <td>0.992407</td>\n",
       "      <td>0.985642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for qwen3 fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.103846</td>\n",
       "      <td>0.968956</td>\n",
       "      <td>0.945470</td>\n",
       "      <td>0.995938</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.049796</td>\n",
       "      <td>0.983453</td>\n",
       "      <td>0.983188</td>\n",
       "      <td>0.984044</td>\n",
       "      <td>0.983616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.052472</td>\n",
       "      <td>0.984771</td>\n",
       "      <td>0.992052</td>\n",
       "      <td>0.977662</td>\n",
       "      <td>0.984804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.045150</td>\n",
       "      <td>0.986674</td>\n",
       "      <td>0.989784</td>\n",
       "      <td>0.983754</td>\n",
       "      <td>0.986760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for qwen3 fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.064974</td>\n",
       "      <td>0.979206</td>\n",
       "      <td>0.976248</td>\n",
       "      <td>0.980967</td>\n",
       "      <td>0.978602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.053540</td>\n",
       "      <td>0.983306</td>\n",
       "      <td>0.990786</td>\n",
       "      <td>0.974622</td>\n",
       "      <td>0.982638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.984771</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>0.976435</td>\n",
       "      <td>0.984166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.039817</td>\n",
       "      <td>0.986674</td>\n",
       "      <td>0.993863</td>\n",
       "      <td>0.978550</td>\n",
       "      <td>0.986147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for qwen3 fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.068667</td>\n",
       "      <td>0.976278</td>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.987798</td>\n",
       "      <td>0.976731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.042322</td>\n",
       "      <td>0.987700</td>\n",
       "      <td>0.984980</td>\n",
       "      <td>0.990703</td>\n",
       "      <td>0.987833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.061400</td>\n",
       "      <td>0.034819</td>\n",
       "      <td>0.989164</td>\n",
       "      <td>0.993842</td>\n",
       "      <td>0.984602</td>\n",
       "      <td>0.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.036273</td>\n",
       "      <td>0.989896</td>\n",
       "      <td>0.990404</td>\n",
       "      <td>0.989541</td>\n",
       "      <td>0.989972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for qwen3 fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.062164</td>\n",
       "      <td>0.980231</td>\n",
       "      <td>0.979819</td>\n",
       "      <td>0.980679</td>\n",
       "      <td>0.980249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.089011</td>\n",
       "      <td>0.977449</td>\n",
       "      <td>0.995745</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.977035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.043324</td>\n",
       "      <td>0.987407</td>\n",
       "      <td>0.987984</td>\n",
       "      <td>0.986827</td>\n",
       "      <td>0.987405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.051600</td>\n",
       "      <td>0.043388</td>\n",
       "      <td>0.987553</td>\n",
       "      <td>0.986561</td>\n",
       "      <td>0.988583</td>\n",
       "      <td>0.987571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for qwen3 fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.076343</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.961430</td>\n",
       "      <td>0.989568</td>\n",
       "      <td>0.975296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.044916</td>\n",
       "      <td>0.986382</td>\n",
       "      <td>0.986949</td>\n",
       "      <td>0.986091</td>\n",
       "      <td>0.986520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.039042</td>\n",
       "      <td>0.987846</td>\n",
       "      <td>0.985303</td>\n",
       "      <td>0.990727</td>\n",
       "      <td>0.988008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.042088</td>\n",
       "      <td>0.986089</td>\n",
       "      <td>0.980527</td>\n",
       "      <td>0.992176</td>\n",
       "      <td>0.986317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for qwen3 fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.071567</td>\n",
       "      <td>0.977888</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>0.989631</td>\n",
       "      <td>0.978499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.050248</td>\n",
       "      <td>0.985357</td>\n",
       "      <td>0.987847</td>\n",
       "      <td>0.983295</td>\n",
       "      <td>0.985566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.044750</td>\n",
       "      <td>0.986382</td>\n",
       "      <td>0.986467</td>\n",
       "      <td>0.986751</td>\n",
       "      <td>0.986609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.988139</td>\n",
       "      <td>0.988758</td>\n",
       "      <td>0.987903</td>\n",
       "      <td>0.988330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwen3 | Accuracy: 0.9876±0.0010 | F1: 0.9876±0.0010\n",
      "\n",
      "Processing feature: gemma3\n",
      "  Fold 1/10\n",
      "    No cached model found for gemma3 fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>0.106268</td>\n",
       "      <td>0.963836</td>\n",
       "      <td>0.967983</td>\n",
       "      <td>0.958519</td>\n",
       "      <td>0.963228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.083955</td>\n",
       "      <td>0.972328</td>\n",
       "      <td>0.973262</td>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.971963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.070907</td>\n",
       "      <td>0.973939</td>\n",
       "      <td>0.981621</td>\n",
       "      <td>0.965333</td>\n",
       "      <td>0.973409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.069024</td>\n",
       "      <td>0.976574</td>\n",
       "      <td>0.978565</td>\n",
       "      <td>0.973926</td>\n",
       "      <td>0.976240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for gemma3 fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.102080</td>\n",
       "      <td>0.968082</td>\n",
       "      <td>0.983144</td>\n",
       "      <td>0.951646</td>\n",
       "      <td>0.967139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.104100</td>\n",
       "      <td>0.097617</td>\n",
       "      <td>0.969253</td>\n",
       "      <td>0.960653</td>\n",
       "      <td>0.977751</td>\n",
       "      <td>0.969127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.079118</td>\n",
       "      <td>0.976135</td>\n",
       "      <td>0.976247</td>\n",
       "      <td>0.975378</td>\n",
       "      <td>0.975812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.975695</td>\n",
       "      <td>0.981087</td>\n",
       "      <td>0.969445</td>\n",
       "      <td>0.975231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for gemma3 fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.106120</td>\n",
       "      <td>0.966320</td>\n",
       "      <td>0.969830</td>\n",
       "      <td>0.963060</td>\n",
       "      <td>0.966433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.085888</td>\n",
       "      <td>0.972910</td>\n",
       "      <td>0.973508</td>\n",
       "      <td>0.972659</td>\n",
       "      <td>0.973083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.089611</td>\n",
       "      <td>0.971445</td>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.951716</td>\n",
       "      <td>0.971064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.074491</td>\n",
       "      <td>0.975545</td>\n",
       "      <td>0.977518</td>\n",
       "      <td>0.973822</td>\n",
       "      <td>0.975667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for gemma3 fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.094214</td>\n",
       "      <td>0.970860</td>\n",
       "      <td>0.973568</td>\n",
       "      <td>0.968166</td>\n",
       "      <td>0.970860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.085688</td>\n",
       "      <td>0.973203</td>\n",
       "      <td>0.985616</td>\n",
       "      <td>0.960572</td>\n",
       "      <td>0.972933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.079309</td>\n",
       "      <td>0.973788</td>\n",
       "      <td>0.970154</td>\n",
       "      <td>0.977804</td>\n",
       "      <td>0.973964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.077231</td>\n",
       "      <td>0.977010</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.963785</td>\n",
       "      <td>0.976765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for gemma3 fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.131263</td>\n",
       "      <td>0.961488</td>\n",
       "      <td>0.952273</td>\n",
       "      <td>0.972440</td>\n",
       "      <td>0.962251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.095449</td>\n",
       "      <td>0.971152</td>\n",
       "      <td>0.978222</td>\n",
       "      <td>0.964317</td>\n",
       "      <td>0.971220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.088326</td>\n",
       "      <td>0.973495</td>\n",
       "      <td>0.977485</td>\n",
       "      <td>0.969829</td>\n",
       "      <td>0.973642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.080611</td>\n",
       "      <td>0.974813</td>\n",
       "      <td>0.984611</td>\n",
       "      <td>0.965187</td>\n",
       "      <td>0.974802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for gemma3 fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.102881</td>\n",
       "      <td>0.966613</td>\n",
       "      <td>0.973280</td>\n",
       "      <td>0.957402</td>\n",
       "      <td>0.965276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.080426</td>\n",
       "      <td>0.972910</td>\n",
       "      <td>0.979442</td>\n",
       "      <td>0.964350</td>\n",
       "      <td>0.971837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.073606</td>\n",
       "      <td>0.975106</td>\n",
       "      <td>0.973462</td>\n",
       "      <td>0.975227</td>\n",
       "      <td>0.974343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.094500</td>\n",
       "      <td>0.067661</td>\n",
       "      <td>0.977888</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.970695</td>\n",
       "      <td>0.977041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for gemma3 fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.088609</td>\n",
       "      <td>0.972470</td>\n",
       "      <td>0.982503</td>\n",
       "      <td>0.962522</td>\n",
       "      <td>0.972410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.100800</td>\n",
       "      <td>0.071097</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.976239</td>\n",
       "      <td>0.978791</td>\n",
       "      <td>0.977513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.065315</td>\n",
       "      <td>0.979060</td>\n",
       "      <td>0.978255</td>\n",
       "      <td>0.980244</td>\n",
       "      <td>0.979248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.060073</td>\n",
       "      <td>0.980231</td>\n",
       "      <td>0.983338</td>\n",
       "      <td>0.977339</td>\n",
       "      <td>0.980329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for gemma3 fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.129100</td>\n",
       "      <td>0.099186</td>\n",
       "      <td>0.966320</td>\n",
       "      <td>0.966882</td>\n",
       "      <td>0.965749</td>\n",
       "      <td>0.966315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.084868</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.969706</td>\n",
       "      <td>0.974532</td>\n",
       "      <td>0.972113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.070976</td>\n",
       "      <td>0.977156</td>\n",
       "      <td>0.983967</td>\n",
       "      <td>0.970141</td>\n",
       "      <td>0.977005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.077090</td>\n",
       "      <td>0.975985</td>\n",
       "      <td>0.972125</td>\n",
       "      <td>0.980094</td>\n",
       "      <td>0.976093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for gemma3 fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.106377</td>\n",
       "      <td>0.962659</td>\n",
       "      <td>0.964265</td>\n",
       "      <td>0.961750</td>\n",
       "      <td>0.963006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.087595</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.974665</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>0.972259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.084719</td>\n",
       "      <td>0.973056</td>\n",
       "      <td>0.976656</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>0.973248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.077334</td>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.985503</td>\n",
       "      <td>0.965227</td>\n",
       "      <td>0.975260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for gemma3 fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>0.107066</td>\n",
       "      <td>0.965295</td>\n",
       "      <td>0.961747</td>\n",
       "      <td>0.970334</td>\n",
       "      <td>0.966022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.087795</td>\n",
       "      <td>0.972177</td>\n",
       "      <td>0.980386</td>\n",
       "      <td>0.964574</td>\n",
       "      <td>0.972416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>0.081058</td>\n",
       "      <td>0.972324</td>\n",
       "      <td>0.970479</td>\n",
       "      <td>0.975230</td>\n",
       "      <td>0.972849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.086100</td>\n",
       "      <td>0.075343</td>\n",
       "      <td>0.977449</td>\n",
       "      <td>0.986510</td>\n",
       "      <td>0.968894</td>\n",
       "      <td>0.977623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.9768±0.0015 | F1: 0.9766±0.0015\n",
      "\n",
      "Processing feature: llama4\n",
      "  Fold 1/10\n",
      "    No cached model found for llama4 fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.192800</td>\n",
       "      <td>0.174189</td>\n",
       "      <td>0.939385</td>\n",
       "      <td>0.926534</td>\n",
       "      <td>0.952889</td>\n",
       "      <td>0.939527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.952269</td>\n",
       "      <td>0.971252</td>\n",
       "      <td>0.930963</td>\n",
       "      <td>0.950681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.127798</td>\n",
       "      <td>0.957394</td>\n",
       "      <td>0.963620</td>\n",
       "      <td>0.949630</td>\n",
       "      <td>0.956574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.959151</td>\n",
       "      <td>0.976601</td>\n",
       "      <td>0.939852</td>\n",
       "      <td>0.957874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for llama4 fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>0.181506</td>\n",
       "      <td>0.934553</td>\n",
       "      <td>0.929495</td>\n",
       "      <td>0.938594</td>\n",
       "      <td>0.934022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.144344</td>\n",
       "      <td>0.949634</td>\n",
       "      <td>0.944232</td>\n",
       "      <td>0.954316</td>\n",
       "      <td>0.949248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.130375</td>\n",
       "      <td>0.955051</td>\n",
       "      <td>0.972840</td>\n",
       "      <td>0.935034</td>\n",
       "      <td>0.953562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.126329</td>\n",
       "      <td>0.956662</td>\n",
       "      <td>0.963521</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>0.955742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for llama4 fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>0.942598</td>\n",
       "      <td>0.948205</td>\n",
       "      <td>0.937173</td>\n",
       "      <td>0.942657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.155800</td>\n",
       "      <td>0.143828</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>0.947140</td>\n",
       "      <td>0.953752</td>\n",
       "      <td>0.950435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.131519</td>\n",
       "      <td>0.956802</td>\n",
       "      <td>0.976935</td>\n",
       "      <td>0.936300</td>\n",
       "      <td>0.956186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.121690</td>\n",
       "      <td>0.960609</td>\n",
       "      <td>0.971999</td>\n",
       "      <td>0.949098</td>\n",
       "      <td>0.960412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for llama4 fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.198200</td>\n",
       "      <td>0.165421</td>\n",
       "      <td>0.941719</td>\n",
       "      <td>0.971340</td>\n",
       "      <td>0.910631</td>\n",
       "      <td>0.940006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>0.141644</td>\n",
       "      <td>0.955484</td>\n",
       "      <td>0.974164</td>\n",
       "      <td>0.936040</td>\n",
       "      <td>0.954721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.126498</td>\n",
       "      <td>0.958852</td>\n",
       "      <td>0.963159</td>\n",
       "      <td>0.954439</td>\n",
       "      <td>0.958780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.120732</td>\n",
       "      <td>0.960023</td>\n",
       "      <td>0.959196</td>\n",
       "      <td>0.961157</td>\n",
       "      <td>0.960175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for llama4 fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.175468</td>\n",
       "      <td>0.935276</td>\n",
       "      <td>0.934877</td>\n",
       "      <td>0.937047</td>\n",
       "      <td>0.935961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>0.146035</td>\n",
       "      <td>0.950212</td>\n",
       "      <td>0.968063</td>\n",
       "      <td>0.932115</td>\n",
       "      <td>0.949749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.125575</td>\n",
       "      <td>0.956655</td>\n",
       "      <td>0.966262</td>\n",
       "      <td>0.947200</td>\n",
       "      <td>0.956636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.122503</td>\n",
       "      <td>0.956363</td>\n",
       "      <td>0.972114</td>\n",
       "      <td>0.940528</td>\n",
       "      <td>0.956060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for llama4 fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.233728</td>\n",
       "      <td>0.913750</td>\n",
       "      <td>0.868200</td>\n",
       "      <td>0.969184</td>\n",
       "      <td>0.915917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.140274</td>\n",
       "      <td>0.951823</td>\n",
       "      <td>0.956788</td>\n",
       "      <td>0.943202</td>\n",
       "      <td>0.949947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.127282</td>\n",
       "      <td>0.958413</td>\n",
       "      <td>0.966687</td>\n",
       "      <td>0.946828</td>\n",
       "      <td>0.956654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.122193</td>\n",
       "      <td>0.959145</td>\n",
       "      <td>0.961339</td>\n",
       "      <td>0.954079</td>\n",
       "      <td>0.957695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for llama4 fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.163813</td>\n",
       "      <td>0.938351</td>\n",
       "      <td>0.933180</td>\n",
       "      <td>0.945381</td>\n",
       "      <td>0.939241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.127480</td>\n",
       "      <td>0.954605</td>\n",
       "      <td>0.961131</td>\n",
       "      <td>0.948286</td>\n",
       "      <td>0.954665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.138500</td>\n",
       "      <td>0.116746</td>\n",
       "      <td>0.959438</td>\n",
       "      <td>0.969724</td>\n",
       "      <td>0.949157</td>\n",
       "      <td>0.959330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.113649</td>\n",
       "      <td>0.959731</td>\n",
       "      <td>0.979413</td>\n",
       "      <td>0.939861</td>\n",
       "      <td>0.959229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for llama4 fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.180987</td>\n",
       "      <td>0.935569</td>\n",
       "      <td>0.960681</td>\n",
       "      <td>0.908372</td>\n",
       "      <td>0.933795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.147760</td>\n",
       "      <td>0.948016</td>\n",
       "      <td>0.944783</td>\n",
       "      <td>0.951698</td>\n",
       "      <td>0.948228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.125634</td>\n",
       "      <td>0.955777</td>\n",
       "      <td>0.970393</td>\n",
       "      <td>0.940281</td>\n",
       "      <td>0.955100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.123750</td>\n",
       "      <td>0.955777</td>\n",
       "      <td>0.969542</td>\n",
       "      <td>0.941159</td>\n",
       "      <td>0.955140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for llama4 fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.185940</td>\n",
       "      <td>0.933812</td>\n",
       "      <td>0.941419</td>\n",
       "      <td>0.926688</td>\n",
       "      <td>0.933995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.164700</td>\n",
       "      <td>0.148056</td>\n",
       "      <td>0.948894</td>\n",
       "      <td>0.955640</td>\n",
       "      <td>0.942625</td>\n",
       "      <td>0.949088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>0.131469</td>\n",
       "      <td>0.954312</td>\n",
       "      <td>0.961482</td>\n",
       "      <td>0.947551</td>\n",
       "      <td>0.954466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.124492</td>\n",
       "      <td>0.956363</td>\n",
       "      <td>0.969896</td>\n",
       "      <td>0.942915</td>\n",
       "      <td>0.956215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for llama4 fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.164137</td>\n",
       "      <td>0.940841</td>\n",
       "      <td>0.946709</td>\n",
       "      <td>0.936348</td>\n",
       "      <td>0.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.145200</td>\n",
       "      <td>0.135275</td>\n",
       "      <td>0.951091</td>\n",
       "      <td>0.959040</td>\n",
       "      <td>0.944124</td>\n",
       "      <td>0.951524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>0.132423</td>\n",
       "      <td>0.954605</td>\n",
       "      <td>0.951714</td>\n",
       "      <td>0.959389</td>\n",
       "      <td>0.955536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.119322</td>\n",
       "      <td>0.957680</td>\n",
       "      <td>0.972676</td>\n",
       "      <td>0.943260</td>\n",
       "      <td>0.957742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.9582±0.0017 | F1: 0.9576±0.0018\n",
      "\n",
      "Processing feature: qwq\n",
      "  Fold 1/10\n",
      "    No cached model found for qwq fold 0, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.052173</td>\n",
       "      <td>0.984187</td>\n",
       "      <td>0.980018</td>\n",
       "      <td>0.988148</td>\n",
       "      <td>0.984066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.045795</td>\n",
       "      <td>0.986969</td>\n",
       "      <td>0.993393</td>\n",
       "      <td>0.980148</td>\n",
       "      <td>0.986726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.988287</td>\n",
       "      <td>0.990181</td>\n",
       "      <td>0.986074</td>\n",
       "      <td>0.988124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.037739</td>\n",
       "      <td>0.989312</td>\n",
       "      <td>0.991955</td>\n",
       "      <td>0.986370</td>\n",
       "      <td>0.989155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2/10\n",
      "    No cached model found for qwq fold 1, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.054543</td>\n",
       "      <td>0.983895</td>\n",
       "      <td>0.985991</td>\n",
       "      <td>0.981311</td>\n",
       "      <td>0.983646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.045700</td>\n",
       "      <td>0.051791</td>\n",
       "      <td>0.987116</td>\n",
       "      <td>0.987526</td>\n",
       "      <td>0.986354</td>\n",
       "      <td>0.986940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.042994</td>\n",
       "      <td>0.988580</td>\n",
       "      <td>0.987852</td>\n",
       "      <td>0.989024</td>\n",
       "      <td>0.988438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.044420</td>\n",
       "      <td>0.988433</td>\n",
       "      <td>0.986119</td>\n",
       "      <td>0.990507</td>\n",
       "      <td>0.988308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3/10\n",
      "    No cached model found for qwq fold 2, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.073552</td>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.963425</td>\n",
       "      <td>0.988365</td>\n",
       "      <td>0.975736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.055150</td>\n",
       "      <td>0.984332</td>\n",
       "      <td>0.980664</td>\n",
       "      <td>0.988365</td>\n",
       "      <td>0.984499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.040506</td>\n",
       "      <td>0.987260</td>\n",
       "      <td>0.993229</td>\n",
       "      <td>0.981385</td>\n",
       "      <td>0.987271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.035541</td>\n",
       "      <td>0.989457</td>\n",
       "      <td>0.992105</td>\n",
       "      <td>0.986911</td>\n",
       "      <td>0.989501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4/10\n",
      "    No cached model found for qwq fold 3, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.057339</td>\n",
       "      <td>0.982574</td>\n",
       "      <td>0.988761</td>\n",
       "      <td>0.976343</td>\n",
       "      <td>0.982513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.041459</td>\n",
       "      <td>0.987992</td>\n",
       "      <td>0.993794</td>\n",
       "      <td>0.982185</td>\n",
       "      <td>0.987955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.038660</td>\n",
       "      <td>0.989164</td>\n",
       "      <td>0.986919</td>\n",
       "      <td>0.991530</td>\n",
       "      <td>0.989219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.047053</td>\n",
       "      <td>0.986674</td>\n",
       "      <td>0.979568</td>\n",
       "      <td>0.994159</td>\n",
       "      <td>0.986810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5/10\n",
      "    No cached model found for qwq fold 4, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.083092</td>\n",
       "      <td>0.977010</td>\n",
       "      <td>0.963903</td>\n",
       "      <td>0.991587</td>\n",
       "      <td>0.977549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.049309</td>\n",
       "      <td>0.984771</td>\n",
       "      <td>0.986325</td>\n",
       "      <td>0.983464</td>\n",
       "      <td>0.984893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.054415</td>\n",
       "      <td>0.981989</td>\n",
       "      <td>0.993468</td>\n",
       "      <td>0.970699</td>\n",
       "      <td>0.981952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.043294</td>\n",
       "      <td>0.988139</td>\n",
       "      <td>0.985574</td>\n",
       "      <td>0.991007</td>\n",
       "      <td>0.988283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 6/10\n",
      "    No cached model found for qwq fold 5, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.058120</td>\n",
       "      <td>0.980524</td>\n",
       "      <td>0.974321</td>\n",
       "      <td>0.985801</td>\n",
       "      <td>0.980027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.047190</td>\n",
       "      <td>0.984771</td>\n",
       "      <td>0.992624</td>\n",
       "      <td>0.975831</td>\n",
       "      <td>0.984156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.042944</td>\n",
       "      <td>0.985796</td>\n",
       "      <td>0.993852</td>\n",
       "      <td>0.976737</td>\n",
       "      <td>0.985220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.035607</td>\n",
       "      <td>0.988871</td>\n",
       "      <td>0.988815</td>\n",
       "      <td>0.988218</td>\n",
       "      <td>0.988516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 7/10\n",
      "    No cached model found for qwq fold 6, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.079800</td>\n",
       "      <td>0.093003</td>\n",
       "      <td>0.969249</td>\n",
       "      <td>0.946656</td>\n",
       "      <td>0.995061</td>\n",
       "      <td>0.970255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.986674</td>\n",
       "      <td>0.980224</td>\n",
       "      <td>0.993608</td>\n",
       "      <td>0.986871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.029064</td>\n",
       "      <td>0.991946</td>\n",
       "      <td>0.993300</td>\n",
       "      <td>0.990703</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.030087</td>\n",
       "      <td>0.992093</td>\n",
       "      <td>0.995032</td>\n",
       "      <td>0.989250</td>\n",
       "      <td>0.992133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 8/10\n",
      "    No cached model found for qwq fold 7, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.082783</td>\n",
       "      <td>0.973788</td>\n",
       "      <td>0.956559</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.974285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.051733</td>\n",
       "      <td>0.984624</td>\n",
       "      <td>0.985057</td>\n",
       "      <td>0.984192</td>\n",
       "      <td>0.984624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.044440</td>\n",
       "      <td>0.987114</td>\n",
       "      <td>0.983721</td>\n",
       "      <td>0.990632</td>\n",
       "      <td>0.987165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.044212</td>\n",
       "      <td>0.987846</td>\n",
       "      <td>0.987994</td>\n",
       "      <td>0.987705</td>\n",
       "      <td>0.987850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 9/10\n",
      "    No cached model found for qwq fold 8, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.078749</td>\n",
       "      <td>0.974081</td>\n",
       "      <td>0.957007</td>\n",
       "      <td>0.993335</td>\n",
       "      <td>0.974833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.047158</td>\n",
       "      <td>0.986089</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>0.982324</td>\n",
       "      <td>0.986182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.051695</td>\n",
       "      <td>0.984917</td>\n",
       "      <td>0.976923</td>\n",
       "      <td>0.993625</td>\n",
       "      <td>0.985203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.035451</td>\n",
       "      <td>0.990042</td>\n",
       "      <td>0.990432</td>\n",
       "      <td>0.989858</td>\n",
       "      <td>0.990145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 10/10\n",
      "    No cached model found for qwq fold 9, training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='961' max='961' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [961/961 02:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.070921</td>\n",
       "      <td>0.977596</td>\n",
       "      <td>0.966283</td>\n",
       "      <td>0.990495</td>\n",
       "      <td>0.978239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.050026</td>\n",
       "      <td>0.985796</td>\n",
       "      <td>0.987858</td>\n",
       "      <td>0.984159</td>\n",
       "      <td>0.986005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.039950</td>\n",
       "      <td>0.987992</td>\n",
       "      <td>0.986510</td>\n",
       "      <td>0.989919</td>\n",
       "      <td>0.988212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.037911</td>\n",
       "      <td>0.989017</td>\n",
       "      <td>0.989058</td>\n",
       "      <td>0.989343</td>\n",
       "      <td>0.989201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [54/54 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.9892±0.0011 | F1: 0.9892±0.0011\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>Precision_mean</th>\n",
       "      <th>Precision_std</th>\n",
       "      <th>Recall_mean</th>\n",
       "      <th>Recall_std</th>\n",
       "      <th>F1_mean</th>\n",
       "      <th>F1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.983087</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.983279</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.982880</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.983075</td>\n",
       "      <td>0.001585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.938558</td>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.957043</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.918376</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.937253</td>\n",
       "      <td>0.003574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.987407</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.988539</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.986250</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.987387</td>\n",
       "      <td>0.001641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen3</td>\n",
       "      <td>0.987612</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.989254</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.985944</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.987587</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.976762</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.983467</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.969846</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.976596</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.958150</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.969630</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.946000</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.957628</td>\n",
       "      <td>0.001763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.989237</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.989400</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.989067</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.989231</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  \\\n",
       "0     abstract       0.983087      0.001509        0.983279       0.002761   \n",
       "1   annotation       0.938558      0.002865        0.957043       0.007134   \n",
       "2  deepseek_v3       0.987407      0.001614        0.988539       0.002108   \n",
       "3        qwen3       0.987612      0.000970        0.989254       0.003282   \n",
       "4       gemma3       0.976762      0.001507        0.983467       0.003522   \n",
       "5       llama4       0.958150      0.001688        0.969630       0.006167   \n",
       "6          qwq       0.989237      0.001086        0.989400       0.002361   \n",
       "\n",
       "   Recall_mean  Recall_std   F1_mean    F1_std  \n",
       "0     0.982880    0.002434  0.983075  0.001585  \n",
       "1     0.918376    0.009043  0.937253  0.003574  \n",
       "2     0.986250    0.003536  0.987387  0.001641  \n",
       "3     0.985944    0.003150  0.987587  0.001020  \n",
       "4     0.969846    0.004126  0.976596  0.001525  \n",
       "5     0.946000    0.006744  0.957628  0.001763  \n",
       "6     0.989067    0.001665  0.989231  0.001119  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 设定设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 评价指标\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds),\n",
    "        'recall': recall_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "class TitlePairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, titles, contents, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(\n",
    "            titles, contents,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def get_best_checkpoint_dir(output_dir):\n",
    "    # 查找所有保存的checkpoint目录\n",
    "    checkpoint_dirs = glob.glob(os.path.join(output_dir, \"checkpoint-*\"))\n",
    "    if not checkpoint_dirs:\n",
    "        return None\n",
    "    # 选最大编号的checkpoint（也可以自定义选择策略）\n",
    "    best_ckpt = max(checkpoint_dirs, key=lambda x: int(x.split('-')[-1]))\n",
    "    # 检查里面是否有权重文件\n",
    "    model_files = [\"model.safetensors\", \"pytorch_model.bin\"]\n",
    "    for mf in model_files:\n",
    "        if os.path.exists(os.path.join(best_ckpt, mf)):\n",
    "            return best_ckpt\n",
    "    return None\n",
    "\n",
    "# 配置\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'qwen3', 'gemma3', 'llama4', 'qwq']\n",
    "y = title_match_df['title_paired'].astype(int).values\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "for feat in text_features:\n",
    "    print(f\"\\nProcessing feature: {feat}\")\n",
    "    X_title = title_match_df['title'].astype(str).fillna('').tolist()\n",
    "    X_content = title_match_df[feat].astype(str).fillna('').tolist()\n",
    "    labels = y\n",
    "\n",
    "    fold_metrics = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(X_title)):\n",
    "        print(f\"  Fold {fold+1}/10\")\n",
    "\n",
    "        train_titles = [X_title[i] for i in train_idx]\n",
    "        train_contents = [X_content[i] for i in train_idx]\n",
    "        train_labels = labels[train_idx]\n",
    "\n",
    "        test_titles = [X_title[i] for i in test_idx]\n",
    "        test_contents = [X_content[i] for i in test_idx]\n",
    "        test_labels = labels[test_idx]\n",
    "\n",
    "        train_dataset = TitlePairDataset(train_titles, train_contents, train_labels, tokenizer)\n",
    "        test_dataset = TitlePairDataset(test_titles, test_contents, test_labels, tokenizer)\n",
    "\n",
    "        output_dir = home / f'projects/TLDR/evaluation/predict_task/cached_title_distilbert_{feat}' / f'fold_{fold}'\n",
    "        output_dir_str = str(output_dir)\n",
    "        best_ckpt = get_best_checkpoint_dir(output_dir_str)\n",
    "        if best_ckpt is not None:\n",
    "            print(f\"    Cached model detected for {feat} fold {fold} at {best_ckpt}, loading and evaluating...\")\n",
    "            model = DistilBertForSequenceClassification.from_pretrained(best_ckpt, num_labels=2).to(device)\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=TrainingArguments(\n",
    "                    output_dir=output_dir_str,\n",
    "                    per_device_eval_batch_size=32,\n",
    "                    report_to=[],\n",
    "                    seed=42+fold\n",
    "                ),\n",
    "                eval_dataset=test_dataset,\n",
    "                compute_metrics=compute_metrics,\n",
    "            )\n",
    "            eval_result = trainer.evaluate()\n",
    "            fold_metrics.append(eval_result)\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "        print(f\"    No cached model found for {feat} fold {fold}, training...\")\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=32,\n",
    "            eval_strategy='steps',\n",
    "            eval_steps=200,\n",
    "            save_strategy='steps',\n",
    "            save_steps=200,\n",
    "            save_total_limit=1,\n",
    "            learning_rate=2e-5,\n",
    "            logging_steps=50,\n",
    "            report_to=[],\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='eval_loss',\n",
    "            greater_is_better=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=test_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        eval_result = trainer.evaluate()\n",
    "        fold_metrics.append(eval_result)\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy_mean': np.mean([m['eval_accuracy'] for m in fold_metrics]),\n",
    "        'Accuracy_std': np.std([m['eval_accuracy'] for m in fold_metrics]),\n",
    "        'Precision_mean': np.mean([m['eval_precision'] for m in fold_metrics]),\n",
    "        'Precision_std': np.std([m['eval_precision'] for m in fold_metrics]),\n",
    "        'Recall_mean': np.mean([m['eval_recall'] for m in fold_metrics]),\n",
    "        'Recall_std': np.std([m['eval_recall'] for m in fold_metrics]),\n",
    "        'F1_mean': np.mean([m['eval_f1'] for m in fold_metrics]),\n",
    "        'F1_std': np.std([m['eval_f1'] for m in fold_metrics]),\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy_mean']:.4f}±{res['Accuracy_std']:.4f} | \"\n",
    "        f\"F1: {res['F1_mean']:.4f}±{res['F1_std']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53552de0",
   "metadata": {},
   "source": [
    "### No CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbaef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing feature: abstract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 02:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.963248</td>\n",
       "      <td>0.959611</td>\n",
       "      <td>0.967199</td>\n",
       "      <td>0.963390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.082622</td>\n",
       "      <td>0.974742</td>\n",
       "      <td>0.976484</td>\n",
       "      <td>0.972910</td>\n",
       "      <td>0.974694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.068250</td>\n",
       "      <td>0.980233</td>\n",
       "      <td>0.984918</td>\n",
       "      <td>0.975399</td>\n",
       "      <td>0.980135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>0.069009</td>\n",
       "      <td>0.979647</td>\n",
       "      <td>0.972451</td>\n",
       "      <td>0.987260</td>\n",
       "      <td>0.979799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: abstract | Accuracy: 0.9813 | F1: 0.9814\n",
      "\n",
      "Processing feature: annotation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 02:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.217543</td>\n",
       "      <td>0.918222</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.899692</td>\n",
       "      <td>0.916673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.190222</td>\n",
       "      <td>0.928545</td>\n",
       "      <td>0.935686</td>\n",
       "      <td>0.920340</td>\n",
       "      <td>0.927949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.176155</td>\n",
       "      <td>0.935134</td>\n",
       "      <td>0.966410</td>\n",
       "      <td>0.901596</td>\n",
       "      <td>0.932879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.168881</td>\n",
       "      <td>0.938429</td>\n",
       "      <td>0.953774</td>\n",
       "      <td>0.921511</td>\n",
       "      <td>0.937365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: annotation | Accuracy: 0.9393 | F1: 0.9383\n",
      "\n",
      "Processing feature: deepseek_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 02:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.061284</td>\n",
       "      <td>0.980819</td>\n",
       "      <td>0.973468</td>\n",
       "      <td>0.988578</td>\n",
       "      <td>0.980965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.046406</td>\n",
       "      <td>0.985650</td>\n",
       "      <td>0.984656</td>\n",
       "      <td>0.986674</td>\n",
       "      <td>0.985664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.056997</td>\n",
       "      <td>0.982868</td>\n",
       "      <td>0.974119</td>\n",
       "      <td>0.992093</td>\n",
       "      <td>0.983024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.044345</td>\n",
       "      <td>0.986309</td>\n",
       "      <td>0.983970</td>\n",
       "      <td>0.988725</td>\n",
       "      <td>0.986341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: deepseek_v3 | Accuracy: 0.9865 | F1: 0.9866\n",
      "\n",
      "Processing feature: qwen3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 02:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.066448</td>\n",
       "      <td>0.980452</td>\n",
       "      <td>0.986651</td>\n",
       "      <td>0.974081</td>\n",
       "      <td>0.980326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.049063</td>\n",
       "      <td>0.983967</td>\n",
       "      <td>0.980518</td>\n",
       "      <td>0.987553</td>\n",
       "      <td>0.984023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.053199</td>\n",
       "      <td>0.983015</td>\n",
       "      <td>0.976318</td>\n",
       "      <td>0.990042</td>\n",
       "      <td>0.983132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.040217</td>\n",
       "      <td>0.987408</td>\n",
       "      <td>0.989269</td>\n",
       "      <td>0.985503</td>\n",
       "      <td>0.987383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwen3 | Accuracy: 0.9870 | F1: 0.9870\n",
      "\n",
      "Processing feature: gemma3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 02:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.101715</td>\n",
       "      <td>0.966615</td>\n",
       "      <td>0.978238</td>\n",
       "      <td>0.954459</td>\n",
       "      <td>0.966202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.096120</td>\n",
       "      <td>0.971008</td>\n",
       "      <td>0.983757</td>\n",
       "      <td>0.957827</td>\n",
       "      <td>0.970619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.969837</td>\n",
       "      <td>0.962920</td>\n",
       "      <td>0.977303</td>\n",
       "      <td>0.970058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.075945</td>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.978783</td>\n",
       "      <td>0.972763</td>\n",
       "      <td>0.975764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: gemma3 | Accuracy: 0.9751 | F1: 0.9751\n",
      "\n",
      "Processing feature: llama4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 02:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.176764</td>\n",
       "      <td>0.935793</td>\n",
       "      <td>0.948733</td>\n",
       "      <td>0.921365</td>\n",
       "      <td>0.934849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.153100</td>\n",
       "      <td>0.146055</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.963114</td>\n",
       "      <td>0.936740</td>\n",
       "      <td>0.949744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.149800</td>\n",
       "      <td>0.131362</td>\n",
       "      <td>0.953291</td>\n",
       "      <td>0.972668</td>\n",
       "      <td>0.932787</td>\n",
       "      <td>0.952310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.123196</td>\n",
       "      <td>0.956366</td>\n",
       "      <td>0.966891</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.955865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: llama4 | Accuracy: 0.9572 | F1: 0.9568\n",
      "\n",
      "Processing feature: qwq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='854' max='854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [854/854 02:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.055245</td>\n",
       "      <td>0.980965</td>\n",
       "      <td>0.978163</td>\n",
       "      <td>0.983892</td>\n",
       "      <td>0.981019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.046989</td>\n",
       "      <td>0.985284</td>\n",
       "      <td>0.983372</td>\n",
       "      <td>0.987260</td>\n",
       "      <td>0.985312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.042530</td>\n",
       "      <td>0.986895</td>\n",
       "      <td>0.984411</td>\n",
       "      <td>0.989457</td>\n",
       "      <td>0.986928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.040154</td>\n",
       "      <td>0.988433</td>\n",
       "      <td>0.991454</td>\n",
       "      <td>0.985357</td>\n",
       "      <td>0.988396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/zqlyuTLDR/lib/python3.13/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='107' max='107' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [107/107 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: qwq | Accuracy: 0.9887 | F1: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.981331</td>\n",
       "      <td>0.978179</td>\n",
       "      <td>0.984624</td>\n",
       "      <td>0.981391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annotation</td>\n",
       "      <td>0.939307</td>\n",
       "      <td>0.954133</td>\n",
       "      <td>0.922976</td>\n",
       "      <td>0.938295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek_v3</td>\n",
       "      <td>0.986529</td>\n",
       "      <td>0.984400</td>\n",
       "      <td>0.988725</td>\n",
       "      <td>0.986558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen3</td>\n",
       "      <td>0.986968</td>\n",
       "      <td>0.987538</td>\n",
       "      <td>0.986382</td>\n",
       "      <td>0.986960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemma3</td>\n",
       "      <td>0.975108</td>\n",
       "      <td>0.975942</td>\n",
       "      <td>0.974228</td>\n",
       "      <td>0.975084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama4</td>\n",
       "      <td>0.957244</td>\n",
       "      <td>0.966393</td>\n",
       "      <td>0.947430</td>\n",
       "      <td>0.956818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qwq</td>\n",
       "      <td>0.988652</td>\n",
       "      <td>0.989153</td>\n",
       "      <td>0.988139</td>\n",
       "      <td>0.988646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  Accuracy  Precision    Recall        F1\n",
       "0     abstract  0.981331   0.978179  0.984624  0.981391\n",
       "1   annotation  0.939307   0.954133  0.922976  0.938295\n",
       "2  deepseek_v3  0.986529   0.984400  0.988725  0.986558\n",
       "3        qwen3  0.986968   0.987538  0.986382  0.986960\n",
       "4       gemma3  0.975108   0.975942  0.974228  0.975084\n",
       "5       llama4  0.957244   0.966393  0.947430  0.956818\n",
       "6          qwq  0.988652   0.989153  0.988139  0.988646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设定设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 评价指标\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds),\n",
    "        'recall': recall_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }\n",
    "\n",
    "class TitlePairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, titles, contents, labels, tokenizer, max_length=128):\n",
    "        self.encodings = tokenizer(\n",
    "            titles, contents,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 配置\n",
    "text_features = ['abstract', 'annotation', 'deepseek_v3', 'qwen3','gemma3', 'llama4', 'qwq']\n",
    "y = title_match_df['title_paired'].astype(int).values\n",
    "results = []\n",
    "\n",
    "# tokenizer和model（可选用其它bert变体）\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "for feat in text_features:\n",
    "    print(f\"\\nProcessing feature: {feat}\")\n",
    "    X_title = title_match_df['title'].astype(str).fillna('').tolist()\n",
    "    X_content = title_match_df[feat].astype(str).fillna('').tolist()\n",
    "    labels = y\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    train_titles, test_titles, train_contents, test_contents, train_labels, test_labels = train_test_split(\n",
    "        X_title, X_content, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    # 构造Dataset\n",
    "    train_dataset = TitlePairDataset(train_titles, train_contents, train_labels, tokenizer)\n",
    "    test_dataset = TitlePairDataset(test_titles, test_contents, test_labels, tokenizer)\n",
    "\n",
    "    # 新建模型\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"title_tmp_distilbert_single_split\",\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        eval_strategy='steps',\n",
    "        eval_steps=200,\n",
    "        save_strategy='no',\n",
    "        learning_rate=2e-5,\n",
    "        logging_steps=50,\n",
    "        report_to=[],\n",
    "        load_best_model_at_end=False,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "\n",
    "    # 汇总\n",
    "    res = {\n",
    "        'feature': feat,\n",
    "        'Accuracy': eval_result['eval_accuracy'],\n",
    "        'Precision': eval_result['eval_precision'],\n",
    "        'Recall': eval_result['eval_recall'],\n",
    "        'F1': eval_result['eval_f1'],\n",
    "    }\n",
    "    print(\n",
    "        f\"Feature: {feat} | \"\n",
    "        f\"Accuracy: {res['Accuracy']:.4f} | \"\n",
    "        f\"F1: {res['F1']:.4f}\"\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
